{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                                Text                 Category\n",
      "0              স্টাফ কিন্তু, আমাদের জন্য ভয়ঙ্কর ছিল।                  service\n",
      "1  শুধুমাত্র,রিডামিং ফ্যাক্টর খাদ্য ছিল,পুরোপুরি ...                     food\n",
      "2  শুধুমাত্র,রিডামিং ফ্যাক্টর খাদ্য ছিল,পুরোপুরি ...  anecdotes/miscellaneous\n",
      "3  খাবার একদমই ব্যতিক্রমী, একটি খুব সক্ষম রান্নাঘ...                     food\n",
      "4  যেখানে গাব্রিয়েলা লোকালি আপনাকে শুভেচ্ছা জানা...                  service\n",
      "Initial Data Shape: (2059, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after text cleaning:\n",
      "                                                Text                 Category\n",
      "0                                       স্টাফ ভয়ঙ্কর                  service\n",
      "1  শুধুমাত্ররিডামিং ফ্যাক্টর খাদ্য ছিলপুরোপুরি ন্...                     food\n",
      "2  শুধুমাত্ররিডামিং ফ্যাক্টর খাদ্য ছিলপুরোপুরি ন্...  anecdotes/miscellaneous\n",
      "3  খাবার একদমই ব্যতিক্রমী সক্ষম রান্নাঘর গর্বের খ...                     food\n",
      "4  গাব্রিয়েলা লোকালি আপনাকে শুভেচ্ছা আপনাকে খেতে...                  service\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 111/111 [00:01<00:00, 65.47it/s] \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"F:\\Context-Resonance Transformer\\Restuarant\\Restaurant - Sheet1.csv\")  # Replace with your dataset path\n",
    "df = df[['Text', 'Category']]  # Focus on only one task: Category classification\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Initialize Bengali stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Bengali stopwords\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Remove non-Bengali characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = text.split()\n",
    "    if stop_words:\n",
    "        words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Upsampling to Balance Classes\n",
    "# -------------------------------\n",
    "\n",
    "def upsample(df, target_column):\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        df_label = df[df[target_column] == label]\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,\n",
    "            n_samples=max_count,\n",
    "            random_state=42\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "df_upsampled = upsample(df, 'Category')\n",
    "\n",
    "# Encode labels\n",
    "category_encoder = LabelEncoder()\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Category'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Tokenization using BERT\n",
    "# -------------------------------\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            list(batch),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data\n",
    "input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Create window-based adjacency matrices\n",
    "def window_based_adjacency(sentences, window_size=2, max_len=20):\n",
    "    adjacency_matrices = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()[:max_len]\n",
    "        num_tokens = len(tokens)\n",
    "        adj = np.zeros((max_len, max_len), dtype=np.float32)\n",
    "        for i in range(num_tokens):\n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, num_tokens)):\n",
    "                if i != j:\n",
    "                    adj[i, j] = 1.0\n",
    "        adjacency_matrices.append(adj)\n",
    "    return np.array(adjacency_matrices, dtype=np.float32)\n",
    "\n",
    "adjacency_matrices = window_based_adjacency(df_upsampled['Text'].values, window_size=2, max_len=20)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Data Splitting\n",
    "# -------------------------------\n",
    "\n",
    "# Split the data\n",
    "X_train_ids, X_test_ids, X_train_masks, X_test_masks, adjacency_train, adjacency_test, y_train_category, y_test_category = train_test_split(\n",
    "    input_ids, attention_masks, adjacency_matrices,  df_upsampled['Category_encoded'].values,\n",
    "    test_size=0.2, random_state=42, stratify=df_upsampled['Category_encoded'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  177853440   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " adjacency (InputLayer)         [(None, 20, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " gnn_context_resonance (GNNCont  ((None, 20, 768),   1790977     ['tf_bert_model[0][0]',          \n",
      " extResonance)                   (None, 20, 1))                   'adjacency[0][0]']              \n",
      "                                                                                                  \n",
      " custom_multi_head_attention (C  ((None, 20, 768),   1769472     ['gnn_context_resonance[0][0]',  \n",
      " ustomMultiHeadAttention)        (None, 8, 20, 20))               'gnn_context_resonance[0][0]',  \n",
      "                                                                  'gnn_context_resonance[0][0]']  \n",
      "                                                                                                  \n",
      " custom_multi_head_attention_1   ((None, 20, 768),   1769472     ['tf_bert_model[0][0]',          \n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance[0][0]',  \n",
      "                                                                  'gnn_context_resonance[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 20, 1536)     0           ['custom_multi_head_attention[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'custom_multi_head_attention_1[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 20, 160)      245920      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 20, 10, 16)   0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " primary_caps_squash (Lambda)   (None, 20, 10, 16)   0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3200)         0           ['primary_caps_squash[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 3200)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " category_output (Dense)        (None, 5)            16005       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 183,445,286\n",
      "Trainable params: 183,445,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Concatenate, Embedding, Flatten, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers import GATConv\n",
    "from transformers import TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "# Squash function for Capsule Networks\n",
    "def squash(vectors):\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=-1, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm)\n",
    "    unit_vectors = vectors / tf.sqrt(s_squared_norm + 1e-9)\n",
    "    return scale * unit_vectors\n",
    "\n",
    "# Custom Multi-Head Attention Layer\n",
    "class CustomMultiHeadAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim, max_len, **kwargs):\n",
    "        super(CustomMultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.depth = key_dim // num_heads\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list) and len(input_shape) == 3:\n",
    "            q_shape, k_shape, v_shape = input_shape\n",
    "        else:\n",
    "            q_shape = input_shape\n",
    "            k_shape = input_shape\n",
    "            v_shape = input_shape\n",
    "        self.wq = self.add_weight(shape=(q_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wk = self.add_weight(shape=(k_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wv = self.add_weight(shape=(v_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        super(CustomMultiHeadAttention, self).build(input_shape)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.reshape(x, (batch_size, self.max_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list) and len(inputs) == 3:\n",
    "            q, k, v = inputs\n",
    "        else:\n",
    "            q = inputs\n",
    "            k = inputs\n",
    "            v = inputs\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = tf.matmul(q, self.wq)\n",
    "        k = tf.matmul(k, self.wk)\n",
    "        v = tf.matmul(v, self.wv)\n",
    "\n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(self.depth, tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(output, (batch_size, self.max_len, self.key_dim))\n",
    "\n",
    "        # Set shapes for Keras\n",
    "        concat_attention.set_shape((None, self.max_len, self.key_dim))\n",
    "        attention_weights.set_shape((None, self.num_heads, self.max_len, self.max_len))\n",
    "\n",
    "        return concat_attention, attention_weights\n",
    "\n",
    "# GNNContextResonance Layer\n",
    "class GNNContextResonance(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads=8, max_len=20, dropout_rate=0.2, **kwargs):\n",
    "        super(GNNContextResonance, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.position_embedding = Embedding(input_dim=max_len, output_dim=hidden_size)\n",
    "\n",
    "        # Multi-Head GAT Layers\n",
    "        self.gat_layers = [GATConv(hidden_size // num_heads, activation='elu') for _ in range(num_heads)]\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        self.transform_gate = Dense(hidden_size, activation='sigmoid')\n",
    "        self.carry_gate = Dense(hidden_size, activation='sigmoid')\n",
    "\n",
    "        # Dropout and Layer Norm\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dense layer for resonance scores\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, adjacency, edge_features=None, training=False):\n",
    "        position_indices = tf.range(self.max_len)[tf.newaxis, :]\n",
    "        position_embeddings = self.position_embedding(position_indices)\n",
    "        inputs = inputs + position_embeddings\n",
    "\n",
    "        gat_outputs = []\n",
    "        for gat_layer in self.gat_layers:\n",
    "            x = gat_layer([inputs, adjacency])\n",
    "            gat_outputs.append(x)\n",
    "        x = self.concat(gat_outputs)\n",
    "\n",
    "        # Residual Connection\n",
    "        x = x + inputs\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        transform = self.transform_gate(x)\n",
    "        carry = self.carry_gate(inputs)\n",
    "        outputs = transform * x + (1 - transform) * carry\n",
    "\n",
    "        # Apply dropout and layer normalization\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        outputs = self.layer_norm(outputs)\n",
    "\n",
    "        resonance_scores = self.dense(outputs)\n",
    "\n",
    "        return outputs, resonance_scores\n",
    "\n",
    "# Building the Model with BERT and GNN for Single Task (Category)\n",
    "def build_model_with_gnn(bert_model, hidden_size, max_len=20):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_masks = Input(shape=(max_len,), dtype=tf.int32, name='attention_masks')\n",
    "    adjacency = Input(shape=(max_len, max_len), dtype=tf.float32, name='adjacency')\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    bert_outputs = bert_model([input_ids, attention_masks])\n",
    "    sequence_output = bert_outputs.last_hidden_state  # BERT output\n",
    "\n",
    "    # Apply GNN-Based Context Resonance\n",
    "    gnn_resonance_layer = GNNContextResonance(hidden_size, num_heads=8, max_len=max_len)\n",
    "    gnn_output, resonance_scores = gnn_resonance_layer(sequence_output, adjacency)\n",
    "\n",
    "    # Implement Dual Attention Mechanism (Self-attention and Cross-attention)\n",
    "    self_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    self_attention_output, self_attention_scores = self_attention_layer([gnn_output, gnn_output, gnn_output])\n",
    "\n",
    "    cross_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    cross_attention_output, cross_attention_scores = cross_attention_layer([sequence_output, gnn_output, gnn_output])\n",
    "\n",
    "    # Combine outputs\n",
    "    combined_output = Concatenate(axis=-1)([self_attention_output, cross_attention_output])\n",
    "\n",
    "    # Capsule Networks Layer\n",
    "    caps_num_capsules = 10  # Number of capsules\n",
    "    caps_dim_capsules = 16  # Dimension of each capsule\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Conv1D(\n",
    "        filters=caps_num_capsules * caps_dim_capsules,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid'\n",
    "    )(combined_output)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Reshape(\n",
    "        target_shape=(max_len, caps_num_capsules, caps_dim_capsules)\n",
    "    )(primary_capsules)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Lambda(squash, name='primary_caps_squash')(primary_capsules)\n",
    "\n",
    "    flat_capsules = Flatten()(primary_capsules)\n",
    "\n",
    "    dropout = Dropout(0.3)(flat_capsules)\n",
    "\n",
    "    # Category Output\n",
    "    category_output = Dense(len(category_encoder.classes_), activation='softmax', name='category_output')(dropout)\n",
    "\n",
    "    # Model will only output Category and resonance scores\n",
    "    model = Model(\n",
    "        inputs=[input_ids, attention_masks, adjacency],\n",
    "        outputs=[category_output, resonance_scores]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load pre-trained multilingual BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "hidden_size = bert_model.config.hidden_size  # Typically 768\n",
    "\n",
    "# Build the model\n",
    "model = build_model_with_gnn(bert_model, hidden_size, max_len=20)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Step 0: Total Loss = 3.6809, CCE Loss Category = 1.7454, Smoothness Loss = 1.9355, Train Accuracy Category = 0.1250\n",
      "Step 100: Total Loss = 1.6199, CCE Loss Category = 1.5909, Smoothness Loss = 0.0291, Train Accuracy Category = 0.2525\n",
      "Epoch 1 Training Loss: 1.5383\n",
      "Epoch 1 Training CCE Loss Category: 1.5212\n",
      "Epoch 1 Training Smoothness Loss: 0.0171\n",
      "Epoch 1 Training Accuracy Category: 0.3137\n",
      "Epoch 1 Validation Loss: 1.3205\n",
      "Epoch 1 Validation CCE Loss Category: 1.3183\n",
      "Epoch 1 Validation Smoothness Loss: 0.0003\n",
      "Epoch 1 Validation Accuracy Category: 0.4676\n",
      "Epoch 1 Duration: 51.17 seconds\n",
      "\n",
      "Start of epoch 2\n",
      "Step 0: Total Loss = 1.5031, CCE Loss Category = 1.5022, Smoothness Loss = 0.0009, Train Accuracy Category = 0.3125\n",
      "Step 100: Total Loss = 1.1375, CCE Loss Category = 1.1365, Smoothness Loss = 0.0009, Train Accuracy Category = 0.5681\n",
      "Epoch 2 Training Loss: 1.0696\n",
      "Epoch 2 Training CCE Loss Category: 1.0685\n",
      "Epoch 2 Training Smoothness Loss: 0.0007\n",
      "Epoch 2 Training Accuracy Category: 0.6025\n",
      "Epoch 2 Validation Loss: 0.8386\n",
      "Epoch 2 Validation CCE Loss Category: 0.8441\n",
      "Epoch 2 Validation Smoothness Loss: 0.0001\n",
      "Epoch 2 Validation Accuracy Category: 0.7056\n",
      "Epoch 2 Duration: 26.13 seconds\n",
      "\n",
      "Start of epoch 3\n",
      "Step 0: Total Loss = 0.7838, CCE Loss Category = 0.7834, Smoothness Loss = 0.0004, Train Accuracy Category = 0.7500\n",
      "Step 100: Total Loss = 0.7331, CCE Loss Category = 0.7325, Smoothness Loss = 0.0006, Train Accuracy Category = 0.7463\n",
      "Epoch 3 Training Loss: 0.7115\n",
      "Epoch 3 Training CCE Loss Category: 0.7090\n",
      "Epoch 3 Training Smoothness Loss: 0.0006\n",
      "Epoch 3 Training Accuracy Category: 0.7553\n",
      "Epoch 3 Validation Loss: 0.8020\n",
      "Epoch 3 Validation CCE Loss Category: 0.8074\n",
      "Epoch 3 Validation Smoothness Loss: 0.0000\n",
      "Epoch 3 Validation Accuracy Category: 0.7239\n",
      "Epoch 3 Duration: 26.18 seconds\n",
      "\n",
      "Start of epoch 4\n",
      "Step 0: Total Loss = 0.2505, CCE Loss Category = 0.2502, Smoothness Loss = 0.0003, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.5515, CCE Loss Category = 0.5513, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8168\n",
      "Epoch 4 Training Loss: 0.5496\n",
      "Epoch 4 Training CCE Loss Category: 0.5503\n",
      "Epoch 4 Training Smoothness Loss: 0.0003\n",
      "Epoch 4 Training Accuracy Category: 0.8165\n",
      "Epoch 4 Validation Loss: 0.7664\n",
      "Epoch 4 Validation CCE Loss Category: 0.7641\n",
      "Epoch 4 Validation Smoothness Loss: 0.0000\n",
      "Epoch 4 Validation Accuracy Category: 0.7521\n",
      "Epoch 4 Duration: 26.13 seconds\n",
      "\n",
      "Start of epoch 5\n",
      "Step 0: Total Loss = 0.2237, CCE Loss Category = 0.2233, Smoothness Loss = 0.0004, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.4132, CCE Loss Category = 0.4127, Smoothness Loss = 0.0004, Train Accuracy Category = 0.8676\n",
      "Epoch 5 Training Loss: 0.4256\n",
      "Epoch 5 Training CCE Loss Category: 0.4255\n",
      "Epoch 5 Training Smoothness Loss: 0.0004\n",
      "Epoch 5 Training Accuracy Category: 0.8644\n",
      "Epoch 5 Validation Loss: 0.7195\n",
      "Epoch 5 Validation CCE Loss Category: 0.7193\n",
      "Epoch 5 Validation Smoothness Loss: 0.0000\n",
      "Epoch 5 Validation Accuracy Category: 0.7634\n",
      "Epoch 5 Duration: 26.12 seconds\n",
      "\n",
      "Start of epoch 6\n",
      "Step 0: Total Loss = 0.5705, CCE Loss Category = 0.5704, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8750\n",
      "Step 100: Total Loss = 0.3660, CCE Loss Category = 0.3656, Smoothness Loss = 0.0004, Train Accuracy Category = 0.8812\n",
      "Epoch 6 Training Loss: 0.3798\n",
      "Epoch 6 Training CCE Loss Category: 0.3802\n",
      "Epoch 6 Training Smoothness Loss: 0.0003\n",
      "Epoch 6 Training Accuracy Category: 0.8761\n",
      "Epoch 6 Validation Loss: 0.7561\n",
      "Epoch 6 Validation CCE Loss Category: 0.7602\n",
      "Epoch 6 Validation Smoothness Loss: 0.0000\n",
      "Epoch 6 Validation Accuracy Category: 0.7648\n",
      "Epoch 6 Duration: 26.12 seconds\n",
      "\n",
      "Start of epoch 7\n",
      "Step 0: Total Loss = 0.3143, CCE Loss Category = 0.3143, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8750\n",
      "Step 100: Total Loss = 0.3327, CCE Loss Category = 0.3325, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8806\n",
      "Epoch 7 Training Loss: 0.3476\n",
      "Epoch 7 Training CCE Loss Category: 0.3475\n",
      "Epoch 7 Training Smoothness Loss: 0.0003\n",
      "Epoch 7 Training Accuracy Category: 0.8778\n",
      "Epoch 7 Validation Loss: 0.7611\n",
      "Epoch 7 Validation CCE Loss Category: 0.7511\n",
      "Epoch 7 Validation Smoothness Loss: 0.0000\n",
      "Epoch 7 Validation Accuracy Category: 0.7690\n",
      "Epoch 7 Duration: 26.11 seconds\n",
      "\n",
      "Start of epoch 8\n",
      "Step 0: Total Loss = 0.1452, CCE Loss Category = 0.1450, Smoothness Loss = 0.0002, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.3244, CCE Loss Category = 0.3242, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8880\n",
      "Epoch 8 Training Loss: 0.3214\n",
      "Epoch 8 Training CCE Loss Category: 0.3211\n",
      "Epoch 8 Training Smoothness Loss: 0.0002\n",
      "Epoch 8 Training Accuracy Category: 0.8849\n",
      "Epoch 8 Validation Loss: 0.8049\n",
      "Epoch 8 Validation CCE Loss Category: 0.7970\n",
      "Epoch 8 Validation Smoothness Loss: 0.0000\n",
      "Epoch 8 Validation Accuracy Category: 0.7606\n",
      "Epoch 8 Duration: 26.14 seconds\n",
      "\n",
      "Start of epoch 9\n",
      "Step 0: Total Loss = 0.6586, CCE Loss Category = 0.6585, Smoothness Loss = 0.0002, Train Accuracy Category = 0.7500\n",
      "Step 100: Total Loss = 0.2844, CCE Loss Category = 0.2843, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8923\n",
      "Epoch 9 Training Loss: 0.3089\n",
      "Epoch 9 Training CCE Loss Category: 0.3095\n",
      "Epoch 9 Training Smoothness Loss: 0.0002\n",
      "Epoch 9 Training Accuracy Category: 0.8831\n",
      "Epoch 9 Validation Loss: 0.7295\n",
      "Epoch 9 Validation CCE Loss Category: 0.7270\n",
      "Epoch 9 Validation Smoothness Loss: 0.0000\n",
      "Epoch 9 Validation Accuracy Category: 0.7789\n",
      "Epoch 9 Duration: 26.13 seconds\n",
      "\n",
      "Start of epoch 10\n",
      "Step 0: Total Loss = 0.2171, CCE Loss Category = 0.2169, Smoothness Loss = 0.0002, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.2867, CCE Loss Category = 0.2865, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8861\n",
      "Epoch 10 Training Loss: 0.3018\n",
      "Epoch 10 Training CCE Loss Category: 0.2996\n",
      "Epoch 10 Training Smoothness Loss: 0.0002\n",
      "Epoch 10 Training Accuracy Category: 0.8803\n",
      "Epoch 10 Validation Loss: 0.7608\n",
      "Epoch 10 Validation CCE Loss Category: 0.7602\n",
      "Epoch 10 Validation Smoothness Loss: 0.0000\n",
      "Epoch 10 Validation Accuracy Category: 0.7704\n",
      "Epoch 10 Duration: 26.15 seconds\n",
      "\n",
      "Start of epoch 11\n",
      "Step 0: Total Loss = 0.2219, CCE Loss Category = 0.2219, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8750\n",
      "Step 100: Total Loss = 0.2885, CCE Loss Category = 0.2883, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8818\n",
      "Epoch 11 Training Loss: 0.2845\n",
      "Epoch 11 Training CCE Loss Category: 0.2840\n",
      "Epoch 11 Training Smoothness Loss: 0.0002\n",
      "Epoch 11 Training Accuracy Category: 0.8838\n",
      "Epoch 11 Validation Loss: 0.7985\n",
      "Epoch 11 Validation CCE Loss Category: 0.7859\n",
      "Epoch 11 Validation Smoothness Loss: 0.0000\n",
      "Epoch 11 Validation Accuracy Category: 0.7690\n",
      "Epoch 11 Duration: 27.13 seconds\n",
      "\n",
      "Start of epoch 12\n",
      "Step 0: Total Loss = 0.3463, CCE Loss Category = 0.3460, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8125\n",
      "Step 100: Total Loss = 0.2528, CCE Loss Category = 0.2526, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8998\n",
      "Epoch 12 Training Loss: 0.2728\n",
      "Epoch 12 Training CCE Loss Category: 0.2724\n",
      "Epoch 12 Training Smoothness Loss: 0.0002\n",
      "Epoch 12 Training Accuracy Category: 0.8880\n",
      "Epoch 12 Validation Loss: 0.7584\n",
      "Epoch 12 Validation CCE Loss Category: 0.7585\n",
      "Epoch 12 Validation Smoothness Loss: 0.0000\n",
      "Epoch 12 Validation Accuracy Category: 0.7620\n",
      "Epoch 12 Duration: 26.77 seconds\n",
      "\n",
      "Start of epoch 13\n",
      "Step 0: Total Loss = 0.4195, CCE Loss Category = 0.4194, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8125\n",
      "Step 100: Total Loss = 0.2532, CCE Loss Category = 0.2530, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9016\n",
      "Epoch 13 Training Loss: 0.2704\n",
      "Epoch 13 Training CCE Loss Category: 0.2706\n",
      "Epoch 13 Training Smoothness Loss: 0.0001\n",
      "Epoch 13 Training Accuracy Category: 0.8908\n",
      "Epoch 13 Validation Loss: 0.8054\n",
      "Epoch 13 Validation CCE Loss Category: 0.7967\n",
      "Epoch 13 Validation Smoothness Loss: 0.0000\n",
      "Epoch 13 Validation Accuracy Category: 0.7648\n",
      "Epoch 13 Duration: 26.77 seconds\n",
      "\n",
      "Start of epoch 14\n",
      "Step 0: Total Loss = 0.1159, CCE Loss Category = 0.1158, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.2443, CCE Loss Category = 0.2442, Smoothness Loss = 0.0002, Train Accuracy Category = 0.8991\n",
      "Epoch 14 Training Loss: 0.2569\n",
      "Epoch 14 Training CCE Loss Category: 0.2568\n",
      "Epoch 14 Training Smoothness Loss: 0.0002\n",
      "Epoch 14 Training Accuracy Category: 0.8880\n",
      "Epoch 14 Validation Loss: 0.7777\n",
      "Epoch 14 Validation CCE Loss Category: 0.7665\n",
      "Epoch 14 Validation Smoothness Loss: 0.0000\n",
      "Epoch 14 Validation Accuracy Category: 0.7704\n",
      "Epoch 14 Duration: 26.76 seconds\n",
      "\n",
      "Start of epoch 15\n",
      "Step 0: Total Loss = 0.0575, CCE Loss Category = 0.0575, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.2326, CCE Loss Category = 0.2325, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8979\n",
      "Epoch 15 Training Loss: 0.2555\n",
      "Epoch 15 Training CCE Loss Category: 0.2555\n",
      "Epoch 15 Training Smoothness Loss: 0.0001\n",
      "Epoch 15 Training Accuracy Category: 0.8852\n",
      "Epoch 15 Validation Loss: 0.7767\n",
      "Epoch 15 Validation CCE Loss Category: 0.7743\n",
      "Epoch 15 Validation Smoothness Loss: 0.0000\n",
      "Epoch 15 Validation Accuracy Category: 0.7718\n",
      "Epoch 15 Duration: 26.77 seconds\n",
      "\n",
      "Start of epoch 16\n",
      "Step 0: Total Loss = 0.2514, CCE Loss Category = 0.2511, Smoothness Loss = 0.0003, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.2479, CCE Loss Category = 0.2478, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8837\n",
      "Epoch 16 Training Loss: 0.2511\n",
      "Epoch 16 Training CCE Loss Category: 0.2513\n",
      "Epoch 16 Training Smoothness Loss: 0.0001\n",
      "Epoch 16 Training Accuracy Category: 0.8852\n",
      "Epoch 16 Validation Loss: 0.7685\n",
      "Epoch 16 Validation CCE Loss Category: 0.7599\n",
      "Epoch 16 Validation Smoothness Loss: 0.0000\n",
      "Epoch 16 Validation Accuracy Category: 0.7563\n",
      "Epoch 16 Duration: 26.81 seconds\n",
      "\n",
      "Start of epoch 17\n",
      "Step 0: Total Loss = 0.2604, CCE Loss Category = 0.2604, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8750\n",
      "Step 100: Total Loss = 0.2248, CCE Loss Category = 0.2247, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8960\n",
      "Epoch 17 Training Loss: 0.2401\n",
      "Epoch 17 Training CCE Loss Category: 0.2399\n",
      "Epoch 17 Training Smoothness Loss: 0.0001\n",
      "Epoch 17 Training Accuracy Category: 0.8923\n",
      "Epoch 17 Validation Loss: 0.8028\n",
      "Epoch 17 Validation CCE Loss Category: 0.7933\n",
      "Epoch 17 Validation Smoothness Loss: 0.0000\n",
      "Epoch 17 Validation Accuracy Category: 0.7577\n",
      "Epoch 17 Duration: 26.79 seconds\n",
      "\n",
      "Start of epoch 18\n",
      "Step 0: Total Loss = 0.1431, CCE Loss Category = 0.1431, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.2166, CCE Loss Category = 0.2165, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9028\n",
      "Epoch 18 Training Loss: 0.2356\n",
      "Epoch 18 Training CCE Loss Category: 0.2361\n",
      "Epoch 18 Training Smoothness Loss: 0.0001\n",
      "Epoch 18 Training Accuracy Category: 0.8923\n",
      "Epoch 18 Validation Loss: 0.8465\n",
      "Epoch 18 Validation CCE Loss Category: 0.8352\n",
      "Epoch 18 Validation Smoothness Loss: 0.0000\n",
      "Epoch 18 Validation Accuracy Category: 0.7563\n",
      "Epoch 18 Duration: 26.92 seconds\n",
      "\n",
      "Start of epoch 19\n",
      "Step 0: Total Loss = 0.1388, CCE Loss Category = 0.1388, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.2383, CCE Loss Category = 0.2383, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8960\n",
      "Epoch 19 Training Loss: 0.2397\n",
      "Epoch 19 Training CCE Loss Category: 0.2389\n",
      "Epoch 19 Training Smoothness Loss: 0.0001\n",
      "Epoch 19 Training Accuracy Category: 0.8944\n",
      "Epoch 19 Validation Loss: 0.8732\n",
      "Epoch 19 Validation CCE Loss Category: 0.8591\n",
      "Epoch 19 Validation Smoothness Loss: 0.0000\n",
      "Epoch 19 Validation Accuracy Category: 0.7648\n",
      "Epoch 19 Duration: 26.96 seconds\n",
      "\n",
      "Start of epoch 20\n",
      "Step 0: Total Loss = 0.1628, CCE Loss Category = 0.1627, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.2209, CCE Loss Category = 0.2209, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8960\n",
      "Epoch 20 Training Loss: 0.2341\n",
      "Epoch 20 Training CCE Loss Category: 0.2342\n",
      "Epoch 20 Training Smoothness Loss: 0.0001\n",
      "Epoch 20 Training Accuracy Category: 0.8912\n",
      "Epoch 20 Validation Loss: 0.8232\n",
      "Epoch 20 Validation CCE Loss Category: 0.8072\n",
      "Epoch 20 Validation Smoothness Loss: 0.0000\n",
      "Epoch 20 Validation Accuracy Category: 0.7577\n",
      "Epoch 20 Duration: 26.86 seconds\n",
      "\n",
      "Total Training Time: 554.91 seconds\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Defining Custom Loss Functions and Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "\n",
    "# Define the standard loss function for category classification without class weights\n",
    "loss_fn_category = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "# Define metrics\n",
    "train_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_category')\n",
    "val_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy_category')\n",
    "\n",
    "# Define the supervised contrastive loss function\n",
    "def supervised_contrastive_loss(labels, features, temperature=0.1):\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    label_mask = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    features = tf.math.l2_normalize(features, axis=1)\n",
    "    similarity_matrix = tf.matmul(features, features, transpose_b=True) / temperature\n",
    "    logits_max = tf.reduce_max(similarity_matrix, axis=1, keepdims=True)\n",
    "    logits = similarity_matrix - logits_max\n",
    "    exp_logits = tf.exp(logits) * tf.cast(label_mask, tf.float32)\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True) + 1e-8)\n",
    "    mean_log_prob_pos = tf.reduce_sum(log_prob * tf.cast(label_mask, tf.float32), axis=1) / tf.reduce_sum(tf.cast(label_mask, tf.float32), axis=1)\n",
    "    loss = -tf.reduce_mean(mean_log_prob_pos)\n",
    "    return loss\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Custom Training Loop\n",
    "# -------------------------------\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = model([input_ids, attention_masks, adjacency], training=True)\n",
    "        predictions_category = predictions[0]\n",
    "        resonance_scores = predictions[1]  # Resonance scores (if needed for other tasks)\n",
    "\n",
    "        # Compute per-sample standard loss for category\n",
    "        cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "        # Compute smoothness loss (if required by your architecture)\n",
    "        resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)  # (batch_size, seq_length)\n",
    "        resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "        squared_diff = tf.square(resonance_diff)\n",
    "        smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])  # (batch_size,)\n",
    "        smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "        # Remove contrastive loss (since features aren't being returned)\n",
    "        total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    # Forward pass\n",
    "    predictions = model([input_ids, attention_masks, adjacency], training=False)\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    # Compute per-sample standard loss for category\n",
    "    cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "    # Compute smoothness loss (if required by your architecture)\n",
    "    resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)\n",
    "    resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "    squared_diff = tf.square(resonance_diff)\n",
    "    smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])\n",
    "    smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "    # Remove contrastive loss (since features aren't being returned)\n",
    "    total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Update metrics\n",
    "    val_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training the Model\n",
    "# -------------------------------\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_train_ids,\n",
    "    'attention_masks': X_train_masks,\n",
    "    'adjacency': adjacency_train\n",
    "}, y_train_category)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_test_ids,\n",
    "    'attention_masks': X_test_masks,\n",
    "    'adjacency': adjacency_test\n",
    "}, y_test_category)).batch(batch_size)\n",
    "\n",
    "# Initialize history dictionaries\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_cce_loss_category': [],\n",
    "    'train_smoothness_loss': [],\n",
    "    'train_accuracy_category': [],\n",
    "    'val_loss': [],\n",
    "    'val_cce_loss_category': [],\n",
    "    'val_smoothness_loss': [],\n",
    "    'val_accuracy_category': [],\n",
    "    'epoch_time': []  # Added to record time per epoch\n",
    "}\n",
    "\n",
    "# Start time of training\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch + 1}\")\n",
    "    epoch_start_time = time.time()  # Record start time of the epoch\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_accuracy_category.reset_states()\n",
    "    val_accuracy_category.reset_states()\n",
    "\n",
    "    # Training\n",
    "    total_loss_avg = tf.keras.metrics.Mean()\n",
    "    cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for step, (batch_inputs, batch_labels_category) in enumerate(train_dataset):\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the train_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = train_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        total_loss_avg.update_state(total_loss)\n",
    "        cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        smoothness_loss_avg.update_state(smoothness_loss)\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Total Loss = {total_loss_avg.result():.4f}, \"\n",
    "                  f\"CCE Loss Category = {cce_loss_category_avg.result():.4f}, \"\n",
    "                  f\"Smoothness Loss = {smoothness_loss_avg.result():.4f}, \"\n",
    "                  f\"Train Accuracy Category = {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Record training metrics\n",
    "    history['train_loss'].append(total_loss_avg.result().numpy())\n",
    "    history['train_cce_loss_category'].append(cce_loss_category_avg.result().numpy())\n",
    "    history['train_smoothness_loss'].append(smoothness_loss_avg.result().numpy())\n",
    "    history['train_accuracy_category'].append(train_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training CCE Loss Category: {cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Smoothness Loss: {smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Accuracy Category: {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss_avg = tf.keras.metrics.Mean()\n",
    "    val_cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    val_smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for batch_inputs, batch_labels_category in test_dataset:\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the test_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = test_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        val_loss_avg.update_state(total_loss)\n",
    "        val_cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        val_smoothness_loss_avg.update_state(smoothness_loss)\n",
    "\n",
    "    # Record validation metrics\n",
    "    history['val_loss'].append(val_loss_avg.result().numpy())\n",
    "    history['val_cce_loss_category'].append(val_cce_loss_category_avg.result().numpy())\n",
    "    history['val_smoothness_loss'].append(val_smoothness_loss_avg.result().numpy())\n",
    "    history['val_accuracy_category'].append(val_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {val_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation CCE Loss Category: {val_cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Smoothness Loss: {val_smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Accuracy Category: {val_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    history['epoch_time'].append(epoch_duration)\n",
    "    print(f\"Epoch {epoch+1} Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "# Total training time\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "print(f\"\\nTotal Training Time: {total_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compute_macro_precision(y_true, y_pred, num_classes):\n",
    "    # Calculate precision for each class\n",
    "    precision_per_class = tf.keras.metrics.Precision(class_id=None, num_classes=num_classes)\n",
    "    precision_per_class.update_state(y_true, y_pred)\n",
    "    precision = precision_per_class.result().numpy()\n",
    "    return precision\n",
    "\n",
    "def compute_macro_recall(y_true, y_pred, num_classes):\n",
    "    # Calculate recall for each class\n",
    "    recall_per_class = tf.keras.metrics.Recall(class_id=None, num_classes=num_classes)\n",
    "    recall_per_class.update_state(y_true, y_pred)\n",
    "    recall = recall_per_class.result().numpy()\n",
    "    return recall\n",
    "\n",
    "def compute_macro_f1(y_true, y_pred, num_classes):\n",
    "    # Calculate F1 score for each class\n",
    "    precision = compute_macro_precision(y_true, y_pred, num_classes)\n",
    "    recall = compute_macro_recall(y_true, y_pred, num_classes)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Test Accuracy (Category): 0.7577\n",
      "Test Macro F1 Score (Category): 0.7542\n",
      "Test Macro Precision (Category): 0.7596\n",
      "Test Macro Recall (Category): 0.7577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 6. Evaluation and Visualization\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on the test set\n",
    "all_predictions_category = []\n",
    "all_labels_category = []\n",
    "all_resonance_scores = []\n",
    "\n",
    "for batch_inputs, batch_labels_category in test_dataset:\n",
    "    input_ids = batch_inputs['input_ids']\n",
    "    attention_masks = batch_inputs['attention_masks']\n",
    "    adjacency = batch_inputs['adjacency']\n",
    "\n",
    "    predictions = model.predict([input_ids, attention_masks, adjacency])\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    predicted_labels_category = np.argmax(predictions_category, axis=1)\n",
    "\n",
    "    all_predictions_category.extend(predicted_labels_category)\n",
    "    all_labels_category.extend(batch_labels_category.numpy())\n",
    "    all_resonance_scores.extend(resonance_scores)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels_category = np.array(all_labels_category)\n",
    "all_predictions_category = np.array(all_predictions_category)\n",
    "\n",
    "# Calculate metrics for Category\n",
    "accuracy_category = accuracy_score(all_labels_category, all_predictions_category)\n",
    "f1_category = f1_score(all_labels_category, all_predictions_category, average='macro')\n",
    "precision_category = precision_score(all_labels_category, all_predictions_category, average='macro')\n",
    "recall_category = recall_score(all_labels_category, all_predictions_category, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy (Category): {accuracy_category:.4f}\")\n",
    "print(f\"Test Macro F1 Score (Category): {f1_category:.4f}\")\n",
    "print(f\"Test Macro Precision (Category): {precision_category:.4f}\")\n",
    "print(f\"Test Macro Recall (Category): {recall_category:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Category\n",
    "plt.figure(figsize=(4, 4))\n",
    "cm_category = confusion_matrix(all_labels_category, all_predictions_category)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_category, display_labels=category_encoder.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=90)\n",
    "plt.title('Confusion Matrix - Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                                Text  Polarity\n",
      "0              স্টাফ কিন্তু, আমাদের জন্য ভয়ঙ্কর ছিল।  negative\n",
      "1  শুধুমাত্র,রিডামিং ফ্যাক্টর খাদ্য ছিল,পুরোপুরি ...  positive\n",
      "2  শুধুমাত্র,রিডামিং ফ্যাক্টর খাদ্য ছিল,পুরোপুরি ...  negative\n",
      "3  খাবার একদমই ব্যতিক্রমী, একটি খুব সক্ষম রান্নাঘ...  positive\n",
      "4  যেখানে গাব্রিয়েলা লোকালি আপনাকে শুভেচ্ছা জানা...  positive\n",
      "Initial Data Shape: (2059, 2)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text  Polarity\n",
      "0                                       স্টাফ ভয়ঙ্কর  negative\n",
      "1  শুধুমাত্ররিডামিং ফ্যাক্টর খাদ্য ছিলপুরোপুরি ন্...  positive\n",
      "2  শুধুমাত্ররিডামিং ফ্যাক্টর খাদ্য ছিলপুরোপুরি ন্...  negative\n",
      "3  খাবার একদমই ব্যতিক্রমী সক্ষম রান্নাঘর গর্বের খ...  positive\n",
      "4  গাব্রিয়েলা লোকালি আপনাকে শুভেচ্ছা আপনাকে খেতে...  positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 153/153 [00:01<00:00, 103.57it/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  177853440   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " adjacency (InputLayer)         [(None, 20, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " gnn_context_resonance_1 (GNNCo  ((None, 20, 768),   1790977     ['tf_bert_model_1[0][0]',        \n",
      " ntextResonance)                 (None, 20, 1))                   'adjacency[0][0]']              \n",
      "                                                                                                  \n",
      " custom_multi_head_attention_2   ((None, 20, 768),   1769472     ['gnn_context_resonance_1[0][0]',\n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_1[0][0]',\n",
      "                                                                  'gnn_context_resonance_1[0][0]']\n",
      "                                                                                                  \n",
      " custom_multi_head_attention_3   ((None, 20, 768),   1769472     ['tf_bert_model_1[0][0]',        \n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_1[0][0]',\n",
      "                                                                  'gnn_context_resonance_1[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 20, 1536)     0           ['custom_multi_head_attention_2[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'custom_multi_head_attention_3[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 20, 160)      245920      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 20, 10, 16)   0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " primary_caps_squash (Lambda)   (None, 20, 10, 16)   0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3200)         0           ['primary_caps_squash[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 3200)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " category_output (Dense)        (None, 4)            12804       ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 183,442,085\n",
      "Trainable params: 183,442,085\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Start of epoch 1\n",
      "Step 0: Total Loss = 2.9681, CCE Loss Category = 1.4959, Smoothness Loss = 1.4722, Train Accuracy Category = 0.0000\n",
      "Step 100: Total Loss = 1.3696, CCE Loss Category = 1.3484, Smoothness Loss = 0.0211, Train Accuracy Category = 0.3323\n",
      "Step 200: Total Loss = 1.2409, CCE Loss Category = 1.2302, Smoothness Loss = 0.0107, Train Accuracy Category = 0.4213\n",
      "Epoch 1 Training Loss: 1.1851\n",
      "Epoch 1 Training CCE Loss Category: 1.1746\n",
      "Epoch 1 Training Smoothness Loss: 0.0089\n",
      "Epoch 1 Training Accuracy Category: 0.4558\n",
      "Epoch 1 Validation Loss: 0.7714\n",
      "Epoch 1 Validation CCE Loss Category: 0.7697\n",
      "Epoch 1 Validation Smoothness Loss: 0.0000\n",
      "Epoch 1 Validation Accuracy Category: 0.7114\n",
      "Epoch 1 Duration: 62.91 seconds\n",
      "\n",
      "Start of epoch 2\n",
      "Step 0: Total Loss = 0.7335, CCE Loss Category = 0.7335, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8125\n",
      "Step 100: Total Loss = 0.6441, CCE Loss Category = 0.6438, Smoothness Loss = 0.0003, Train Accuracy Category = 0.7550\n",
      "Step 200: Total Loss = 0.6153, CCE Loss Category = 0.6149, Smoothness Loss = 0.0003, Train Accuracy Category = 0.7702\n",
      "Epoch 2 Training Loss: 0.5991\n",
      "Epoch 2 Training CCE Loss Category: 0.5986\n",
      "Epoch 2 Training Smoothness Loss: 0.0003\n",
      "Epoch 2 Training Accuracy Category: 0.7789\n",
      "Epoch 2 Validation Loss: 0.4760\n",
      "Epoch 2 Validation CCE Loss Category: 0.4823\n",
      "Epoch 2 Validation Smoothness Loss: 0.0000\n",
      "Epoch 2 Validation Accuracy Category: 0.8178\n",
      "Epoch 2 Duration: 36.73 seconds\n",
      "\n",
      "Start of epoch 3\n",
      "Step 0: Total Loss = 0.6121, CCE Loss Category = 0.6107, Smoothness Loss = 0.0013, Train Accuracy Category = 0.6875\n",
      "Step 100: Total Loss = 0.3667, CCE Loss Category = 0.3663, Smoothness Loss = 0.0004, Train Accuracy Category = 0.8793\n",
      "Step 200: Total Loss = 0.3641, CCE Loss Category = 0.3638, Smoothness Loss = 0.0003, Train Accuracy Category = 0.8828\n",
      "Epoch 3 Training Loss: 0.3583\n",
      "Epoch 3 Training CCE Loss Category: 0.3528\n",
      "Epoch 3 Training Smoothness Loss: 0.0003\n",
      "Epoch 3 Training Accuracy Category: 0.8853\n",
      "Epoch 3 Validation Loss: 0.3390\n",
      "Epoch 3 Validation CCE Loss Category: 0.3433\n",
      "Epoch 3 Validation Smoothness Loss: 0.0000\n",
      "Epoch 3 Validation Accuracy Category: 0.8884\n",
      "Epoch 3 Duration: 36.65 seconds\n",
      "\n",
      "Start of epoch 4\n",
      "Step 0: Total Loss = 0.2831, CCE Loss Category = 0.2829, Smoothness Loss = 0.0001, Train Accuracy Category = 0.8750\n",
      "Step 100: Total Loss = 0.2390, CCE Loss Category = 0.2387, Smoothness Loss = 0.0003, Train Accuracy Category = 0.9245\n",
      "Step 200: Total Loss = 0.2383, CCE Loss Category = 0.2380, Smoothness Loss = 0.0003, Train Accuracy Category = 0.9263\n",
      "Epoch 4 Training Loss: 0.2452\n",
      "Epoch 4 Training CCE Loss Category: 0.2422\n",
      "Epoch 4 Training Smoothness Loss: 0.0003\n",
      "Epoch 4 Training Accuracy Category: 0.9242\n",
      "Epoch 4 Validation Loss: 0.3332\n",
      "Epoch 4 Validation CCE Loss Category: 0.3379\n",
      "Epoch 4 Validation Smoothness Loss: 0.0000\n",
      "Epoch 4 Validation Accuracy Category: 0.8915\n",
      "Epoch 4 Duration: 36.89 seconds\n",
      "\n",
      "Start of epoch 5\n",
      "Step 0: Total Loss = 0.0720, CCE Loss Category = 0.0718, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1913, CCE Loss Category = 0.1912, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9332\n",
      "Step 200: Total Loss = 0.2083, CCE Loss Category = 0.2081, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9279\n",
      "Epoch 5 Training Loss: 0.2023\n",
      "Epoch 5 Training CCE Loss Category: 0.2028\n",
      "Epoch 5 Training Smoothness Loss: 0.0001\n",
      "Epoch 5 Training Accuracy Category: 0.9304\n",
      "Epoch 5 Validation Loss: 0.2991\n",
      "Epoch 5 Validation CCE Loss Category: 0.3026\n",
      "Epoch 5 Validation Smoothness Loss: 0.0000\n",
      "Epoch 5 Validation Accuracy Category: 0.9069\n",
      "Epoch 5 Duration: 36.82 seconds\n",
      "\n",
      "Start of epoch 6\n",
      "Step 0: Total Loss = 0.1592, CCE Loss Category = 0.1591, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.1534, CCE Loss Category = 0.1533, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9511\n",
      "Step 200: Total Loss = 0.1597, CCE Loss Category = 0.1596, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9487\n",
      "Epoch 6 Training Loss: 0.1590\n",
      "Epoch 6 Training CCE Loss Category: 0.1594\n",
      "Epoch 6 Training Smoothness Loss: 0.0001\n",
      "Epoch 6 Training Accuracy Category: 0.9496\n",
      "Epoch 6 Validation Loss: 0.3095\n",
      "Epoch 6 Validation CCE Loss Category: 0.3138\n",
      "Epoch 6 Validation Smoothness Loss: 0.0000\n",
      "Epoch 6 Validation Accuracy Category: 0.9110\n",
      "Epoch 6 Duration: 35.70 seconds\n",
      "\n",
      "Start of epoch 7\n",
      "Step 0: Total Loss = 0.0191, CCE Loss Category = 0.0191, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1222, CCE Loss Category = 0.1221, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9573\n",
      "Step 200: Total Loss = 0.1285, CCE Loss Category = 0.1284, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9571\n",
      "Epoch 7 Training Loss: 0.1289\n",
      "Epoch 7 Training CCE Loss Category: 0.1293\n",
      "Epoch 7 Training Smoothness Loss: 0.0001\n",
      "Epoch 7 Training Accuracy Category: 0.9575\n",
      "Epoch 7 Validation Loss: 0.2966\n",
      "Epoch 7 Validation CCE Loss Category: 0.3007\n",
      "Epoch 7 Validation Smoothness Loss: 0.0000\n",
      "Epoch 7 Validation Accuracy Category: 0.9110\n",
      "Epoch 7 Duration: 34.97 seconds\n",
      "\n",
      "Start of epoch 8\n",
      "Step 0: Total Loss = 0.0726, CCE Loss Category = 0.0725, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1313, CCE Loss Category = 0.1312, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9548\n",
      "Step 200: Total Loss = 0.1192, CCE Loss Category = 0.1191, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9586\n",
      "Epoch 8 Training Loss: 0.1255\n",
      "Epoch 8 Training CCE Loss Category: 0.1258\n",
      "Epoch 8 Training Smoothness Loss: 0.0001\n",
      "Epoch 8 Training Accuracy Category: 0.9565\n",
      "Epoch 8 Validation Loss: 0.3010\n",
      "Epoch 8 Validation CCE Loss Category: 0.3037\n",
      "Epoch 8 Validation Smoothness Loss: 0.0000\n",
      "Epoch 8 Validation Accuracy Category: 0.9110\n",
      "Epoch 8 Duration: 34.71 seconds\n",
      "\n",
      "Start of epoch 9\n",
      "Step 0: Total Loss = 0.0128, CCE Loss Category = 0.0127, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1126, CCE Loss Category = 0.1125, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9616\n",
      "Step 200: Total Loss = 0.1119, CCE Loss Category = 0.1119, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9611\n",
      "Epoch 9 Training Loss: 0.1174\n",
      "Epoch 9 Training CCE Loss Category: 0.1175\n",
      "Epoch 9 Training Smoothness Loss: 0.0001\n",
      "Epoch 9 Training Accuracy Category: 0.9590\n",
      "Epoch 9 Validation Loss: 0.2910\n",
      "Epoch 9 Validation CCE Loss Category: 0.2941\n",
      "Epoch 9 Validation Smoothness Loss: 0.0000\n",
      "Epoch 9 Validation Accuracy Category: 0.9120\n",
      "Epoch 9 Duration: 35.25 seconds\n",
      "\n",
      "Start of epoch 10\n",
      "Step 0: Total Loss = 0.0318, CCE Loss Category = 0.0318, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1296, CCE Loss Category = 0.1296, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9524\n",
      "Step 200: Total Loss = 0.1249, CCE Loss Category = 0.1249, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9540\n",
      "Epoch 10 Training Loss: 0.1346\n",
      "Epoch 10 Training CCE Loss Category: 0.1308\n",
      "Epoch 10 Training Smoothness Loss: 0.0001\n",
      "Epoch 10 Training Accuracy Category: 0.9511\n",
      "Epoch 10 Validation Loss: 0.3616\n",
      "Epoch 10 Validation CCE Loss Category: 0.3665\n",
      "Epoch 10 Validation Smoothness Loss: 0.0000\n",
      "Epoch 10 Validation Accuracy Category: 0.9069\n",
      "Epoch 10 Duration: 35.47 seconds\n",
      "\n",
      "Start of epoch 11\n",
      "Step 0: Total Loss = 0.2032, CCE Loss Category = 0.2031, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.1482, CCE Loss Category = 0.1481, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9474\n",
      "Step 200: Total Loss = 0.1386, CCE Loss Category = 0.1385, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9478\n",
      "Epoch 11 Training Loss: 0.1383\n",
      "Epoch 11 Training CCE Loss Category: 0.1386\n",
      "Epoch 11 Training Smoothness Loss: 0.0001\n",
      "Epoch 11 Training Accuracy Category: 0.9475\n",
      "Epoch 11 Validation Loss: 0.2909\n",
      "Epoch 11 Validation CCE Loss Category: 0.2941\n",
      "Epoch 11 Validation Smoothness Loss: 0.0000\n",
      "Epoch 11 Validation Accuracy Category: 0.9181\n",
      "Epoch 11 Duration: 34.85 seconds\n",
      "\n",
      "Start of epoch 12\n",
      "Step 0: Total Loss = 0.2420, CCE Loss Category = 0.2419, Smoothness Loss = 0.0000, Train Accuracy Category = 0.8125\n",
      "Step 100: Total Loss = 0.1058, CCE Loss Category = 0.1057, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9585\n",
      "Step 200: Total Loss = 0.1136, CCE Loss Category = 0.1135, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9543\n",
      "Epoch 12 Training Loss: 0.1148\n",
      "Epoch 12 Training CCE Loss Category: 0.1150\n",
      "Epoch 12 Training Smoothness Loss: 0.0001\n",
      "Epoch 12 Training Accuracy Category: 0.9552\n",
      "Epoch 12 Validation Loss: 0.2786\n",
      "Epoch 12 Validation CCE Loss Category: 0.2821\n",
      "Epoch 12 Validation Smoothness Loss: 0.0000\n",
      "Epoch 12 Validation Accuracy Category: 0.9212\n",
      "Epoch 12 Duration: 35.58 seconds\n",
      "\n",
      "Start of epoch 13\n",
      "Step 0: Total Loss = 0.0229, CCE Loss Category = 0.0229, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0929, CCE Loss Category = 0.0929, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9629\n",
      "Step 200: Total Loss = 0.1067, CCE Loss Category = 0.1066, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9565\n",
      "Epoch 13 Training Loss: 0.1066\n",
      "Epoch 13 Training CCE Loss Category: 0.1069\n",
      "Epoch 13 Training Smoothness Loss: 0.0000\n",
      "Epoch 13 Training Accuracy Category: 0.9567\n",
      "Epoch 13 Validation Loss: 0.3160\n",
      "Epoch 13 Validation CCE Loss Category: 0.3199\n",
      "Epoch 13 Validation Smoothness Loss: 0.0000\n",
      "Epoch 13 Validation Accuracy Category: 0.9110\n",
      "Epoch 13 Duration: 35.71 seconds\n",
      "\n",
      "Start of epoch 14\n",
      "Step 0: Total Loss = 0.0323, CCE Loss Category = 0.0322, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0858, CCE Loss Category = 0.0857, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9684\n",
      "Step 200: Total Loss = 0.0901, CCE Loss Category = 0.0901, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9642\n",
      "Epoch 14 Training Loss: 0.0896\n",
      "Epoch 14 Training CCE Loss Category: 0.0898\n",
      "Epoch 14 Training Smoothness Loss: 0.0000\n",
      "Epoch 14 Training Accuracy Category: 0.9629\n",
      "Epoch 14 Validation Loss: 0.3399\n",
      "Epoch 14 Validation CCE Loss Category: 0.3423\n",
      "Epoch 14 Validation Smoothness Loss: 0.0000\n",
      "Epoch 14 Validation Accuracy Category: 0.9202\n",
      "Epoch 14 Duration: 34.62 seconds\n",
      "\n",
      "Start of epoch 15\n",
      "Step 0: Total Loss = 0.1249, CCE Loss Category = 0.1249, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.1042, CCE Loss Category = 0.1041, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9554\n",
      "Step 200: Total Loss = 0.1006, CCE Loss Category = 0.1005, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9586\n",
      "Epoch 15 Training Loss: 0.1081\n",
      "Epoch 15 Training CCE Loss Category: 0.1063\n",
      "Epoch 15 Training Smoothness Loss: 0.0000\n",
      "Epoch 15 Training Accuracy Category: 0.9565\n",
      "Epoch 15 Validation Loss: 0.3581\n",
      "Epoch 15 Validation CCE Loss Category: 0.3618\n",
      "Epoch 15 Validation Smoothness Loss: 0.0000\n",
      "Epoch 15 Validation Accuracy Category: 0.8936\n",
      "Epoch 15 Duration: 35.46 seconds\n",
      "\n",
      "Start of epoch 16\n",
      "Step 0: Total Loss = 0.0644, CCE Loss Category = 0.0644, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.1191, CCE Loss Category = 0.1190, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9511\n",
      "Step 200: Total Loss = 0.1018, CCE Loss Category = 0.1018, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9568\n",
      "Epoch 16 Training Loss: 0.0957\n",
      "Epoch 16 Training CCE Loss Category: 0.0956\n",
      "Epoch 16 Training Smoothness Loss: 0.0001\n",
      "Epoch 16 Training Accuracy Category: 0.9598\n",
      "Epoch 16 Validation Loss: 0.3604\n",
      "Epoch 16 Validation CCE Loss Category: 0.3636\n",
      "Epoch 16 Validation Smoothness Loss: 0.0000\n",
      "Epoch 16 Validation Accuracy Category: 0.9028\n",
      "Epoch 16 Duration: 36.09 seconds\n",
      "\n",
      "Start of epoch 17\n",
      "Step 0: Total Loss = 0.0899, CCE Loss Category = 0.0898, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0849, CCE Loss Category = 0.0848, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9616\n",
      "Step 200: Total Loss = 0.0887, CCE Loss Category = 0.0887, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9639\n",
      "Epoch 17 Training Loss: 0.0931\n",
      "Epoch 17 Training CCE Loss Category: 0.0933\n",
      "Epoch 17 Training Smoothness Loss: 0.0000\n",
      "Epoch 17 Training Accuracy Category: 0.9608\n",
      "Epoch 17 Validation Loss: 0.3007\n",
      "Epoch 17 Validation CCE Loss Category: 0.3034\n",
      "Epoch 17 Validation Smoothness Loss: 0.0000\n",
      "Epoch 17 Validation Accuracy Category: 0.9181\n",
      "Epoch 17 Duration: 35.62 seconds\n",
      "\n",
      "Start of epoch 18\n",
      "Step 0: Total Loss = 0.0444, CCE Loss Category = 0.0444, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0865, CCE Loss Category = 0.0865, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9585\n",
      "Step 200: Total Loss = 0.0923, CCE Loss Category = 0.0922, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9586\n",
      "Epoch 18 Training Loss: 0.0942\n",
      "Epoch 18 Training CCE Loss Category: 0.0914\n",
      "Epoch 18 Training Smoothness Loss: 0.0000\n",
      "Epoch 18 Training Accuracy Category: 0.9588\n",
      "Epoch 18 Validation Loss: 0.3131\n",
      "Epoch 18 Validation CCE Loss Category: 0.3159\n",
      "Epoch 18 Validation Smoothness Loss: 0.0000\n",
      "Epoch 18 Validation Accuracy Category: 0.9212\n",
      "Epoch 18 Duration: 35.31 seconds\n",
      "\n",
      "Start of epoch 19\n",
      "Step 0: Total Loss = 0.0101, CCE Loss Category = 0.0101, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0834, CCE Loss Category = 0.0834, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9604\n",
      "Step 200: Total Loss = 0.0787, CCE Loss Category = 0.0786, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9633\n",
      "Epoch 19 Training Loss: 0.0761\n",
      "Epoch 19 Training CCE Loss Category: 0.0763\n",
      "Epoch 19 Training Smoothness Loss: 0.0001\n",
      "Epoch 19 Training Accuracy Category: 0.9639\n",
      "Epoch 19 Validation Loss: 0.3705\n",
      "Epoch 19 Validation CCE Loss Category: 0.3762\n",
      "Epoch 19 Validation Smoothness Loss: 0.0000\n",
      "Epoch 19 Validation Accuracy Category: 0.9191\n",
      "Epoch 19 Duration: 35.73 seconds\n",
      "\n",
      "Start of epoch 20\n",
      "Step 0: Total Loss = 0.0031, CCE Loss Category = 0.0031, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0687, CCE Loss Category = 0.0686, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9709\n",
      "Step 200: Total Loss = 0.0770, CCE Loss Category = 0.0770, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9655\n",
      "Epoch 20 Training Loss: 0.0752\n",
      "Epoch 20 Training CCE Loss Category: 0.0754\n",
      "Epoch 20 Training Smoothness Loss: 0.0000\n",
      "Epoch 20 Training Accuracy Category: 0.9657\n",
      "Epoch 20 Validation Loss: 0.3641\n",
      "Epoch 20 Validation CCE Loss Category: 0.3676\n",
      "Epoch 20 Validation Smoothness Loss: 0.0000\n",
      "Epoch 20 Validation Accuracy Category: 0.9191\n",
      "Epoch 20 Duration: 34.91 seconds\n",
      "\n",
      "Total Training Time: 739.98 seconds\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Test Accuracy (Category): 0.9191\n",
      "Test Macro F1 Score (Category): 0.9184\n",
      "Test Macro Precision (Category): 0.9192\n",
      "Test Macro Recall (Category): 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"F:\\Context-Resonance Transformer\\Restuarant\\Restaurant - Sheet1.csv\")  # Replace with your dataset path\n",
    "df = df[['Text', 'Polarity']]  # Focus on only one task: Category classification\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Initialize Bengali stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Bengali stopwords\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Remove non-Bengali characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = text.split()\n",
    "    if stop_words:\n",
    "        words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Upsampling to Balance Classes\n",
    "# -------------------------------\n",
    "\n",
    "def upsample(df, target_column):\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        df_label = df[df[target_column] == label]\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,\n",
    "            n_samples=max_count,\n",
    "            random_state=42\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "df_upsampled = upsample(df, 'Polarity')\n",
    "\n",
    "# Encode labels\n",
    "category_encoder = LabelEncoder()\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Polarity'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Tokenization using BERT\n",
    "# -------------------------------\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            list(batch),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data\n",
    "input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Create window-based adjacency matrices\n",
    "def window_based_adjacency(sentences, window_size=2, max_len=20):\n",
    "    adjacency_matrices = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()[:max_len]\n",
    "        num_tokens = len(tokens)\n",
    "        adj = np.zeros((max_len, max_len), dtype=np.float32)\n",
    "        for i in range(num_tokens):\n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, num_tokens)):\n",
    "                if i != j:\n",
    "                    adj[i, j] = 1.0\n",
    "        adjacency_matrices.append(adj)\n",
    "    return np.array(adjacency_matrices, dtype=np.float32)\n",
    "\n",
    "adjacency_matrices = window_based_adjacency(df_upsampled['Text'].values, window_size=2, max_len=20)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Data Splitting\n",
    "# -------------------------------\n",
    "\n",
    "# Split the data\n",
    "X_train_ids, X_test_ids, X_train_masks, X_test_masks, adjacency_train, adjacency_test, y_train_category, y_test_category = train_test_split(\n",
    "    input_ids, attention_masks, adjacency_matrices,  df_upsampled['Category_encoded'].values,\n",
    "    test_size=0.2, random_state=42, stratify=df_upsampled['Category_encoded'].values\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Concatenate, Embedding, Flatten, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers import GATConv\n",
    "from transformers import TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "# Squash function for Capsule Networks\n",
    "def squash(vectors):\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=-1, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm)\n",
    "    unit_vectors = vectors / tf.sqrt(s_squared_norm + 1e-9)\n",
    "    return scale * unit_vectors\n",
    "\n",
    "# Custom Multi-Head Attention Layer\n",
    "class CustomMultiHeadAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim, max_len, **kwargs):\n",
    "        super(CustomMultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.depth = key_dim // num_heads\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list) and len(input_shape) == 3:\n",
    "            q_shape, k_shape, v_shape = input_shape\n",
    "        else:\n",
    "            q_shape = input_shape\n",
    "            k_shape = input_shape\n",
    "            v_shape = input_shape\n",
    "        self.wq = self.add_weight(shape=(q_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wk = self.add_weight(shape=(k_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wv = self.add_weight(shape=(v_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        super(CustomMultiHeadAttention, self).build(input_shape)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.reshape(x, (batch_size, self.max_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list) and len(inputs) == 3:\n",
    "            q, k, v = inputs\n",
    "        else:\n",
    "            q = inputs\n",
    "            k = inputs\n",
    "            v = inputs\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = tf.matmul(q, self.wq)\n",
    "        k = tf.matmul(k, self.wk)\n",
    "        v = tf.matmul(v, self.wv)\n",
    "\n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(self.depth, tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(output, (batch_size, self.max_len, self.key_dim))\n",
    "\n",
    "        # Set shapes for Keras\n",
    "        concat_attention.set_shape((None, self.max_len, self.key_dim))\n",
    "        attention_weights.set_shape((None, self.num_heads, self.max_len, self.max_len))\n",
    "\n",
    "        return concat_attention, attention_weights\n",
    "\n",
    "# GNNContextResonance Layer\n",
    "class GNNContextResonance(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads=8, max_len=20, dropout_rate=0.2, **kwargs):\n",
    "        super(GNNContextResonance, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.position_embedding = Embedding(input_dim=max_len, output_dim=hidden_size)\n",
    "\n",
    "        # Multi-Head GAT Layers\n",
    "        self.gat_layers = [GATConv(hidden_size // num_heads, activation='elu') for _ in range(num_heads)]\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        self.transform_gate = Dense(hidden_size, activation='sigmoid')\n",
    "        self.carry_gate = Dense(hidden_size, activation='sigmoid')\n",
    "\n",
    "        # Dropout and Layer Norm\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dense layer for resonance scores\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, adjacency, edge_features=None, training=False):\n",
    "        position_indices = tf.range(self.max_len)[tf.newaxis, :]\n",
    "        position_embeddings = self.position_embedding(position_indices)\n",
    "        inputs = inputs + position_embeddings\n",
    "\n",
    "        gat_outputs = []\n",
    "        for gat_layer in self.gat_layers:\n",
    "            x = gat_layer([inputs, adjacency])\n",
    "            gat_outputs.append(x)\n",
    "        x = self.concat(gat_outputs)\n",
    "\n",
    "        # Residual Connection\n",
    "        x = x + inputs\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        transform = self.transform_gate(x)\n",
    "        carry = self.carry_gate(inputs)\n",
    "        outputs = transform * x + (1 - transform) * carry\n",
    "\n",
    "        # Apply dropout and layer normalization\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        outputs = self.layer_norm(outputs)\n",
    "\n",
    "        resonance_scores = self.dense(outputs)\n",
    "\n",
    "        return outputs, resonance_scores\n",
    "\n",
    "# Building the Model with BERT and GNN for Single Task (Category)\n",
    "def build_model_with_gnn(bert_model, hidden_size, max_len=20):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_masks = Input(shape=(max_len,), dtype=tf.int32, name='attention_masks')\n",
    "    adjacency = Input(shape=(max_len, max_len), dtype=tf.float32, name='adjacency')\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    bert_outputs = bert_model([input_ids, attention_masks])\n",
    "    sequence_output = bert_outputs.last_hidden_state  # BERT output\n",
    "\n",
    "    # Apply GNN-Based Context Resonance\n",
    "    gnn_resonance_layer = GNNContextResonance(hidden_size, num_heads=8, max_len=max_len)\n",
    "    gnn_output, resonance_scores = gnn_resonance_layer(sequence_output, adjacency)\n",
    "\n",
    "    # Implement Dual Attention Mechanism (Self-attention and Cross-attention)\n",
    "    self_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    self_attention_output, self_attention_scores = self_attention_layer([gnn_output, gnn_output, gnn_output])\n",
    "\n",
    "    cross_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    cross_attention_output, cross_attention_scores = cross_attention_layer([sequence_output, gnn_output, gnn_output])\n",
    "\n",
    "    # Combine outputs\n",
    "    combined_output = Concatenate(axis=-1)([self_attention_output, cross_attention_output])\n",
    "\n",
    "    # Capsule Networks Layer\n",
    "    caps_num_capsules = 10  # Number of capsules\n",
    "    caps_dim_capsules = 16  # Dimension of each capsule\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Conv1D(\n",
    "        filters=caps_num_capsules * caps_dim_capsules,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid'\n",
    "    )(combined_output)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Reshape(\n",
    "        target_shape=(max_len, caps_num_capsules, caps_dim_capsules)\n",
    "    )(primary_capsules)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Lambda(squash, name='primary_caps_squash')(primary_capsules)\n",
    "\n",
    "    flat_capsules = Flatten()(primary_capsules)\n",
    "\n",
    "    dropout = Dropout(0.3)(flat_capsules)\n",
    "\n",
    "    # Category Output\n",
    "    category_output = Dense(len(category_encoder.classes_), activation='softmax', name='category_output')(dropout)\n",
    "\n",
    "    # Model will only output Category and resonance scores\n",
    "    model = Model(\n",
    "        inputs=[input_ids, attention_masks, adjacency],\n",
    "        outputs=[category_output, resonance_scores]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load pre-trained multilingual BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "hidden_size = bert_model.config.hidden_size  # Typically 768\n",
    "\n",
    "# Build the model\n",
    "model = build_model_with_gnn(bert_model, hidden_size, max_len=20)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Defining Custom Loss Functions and Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "\n",
    "# Define the standard loss function for category classification without class weights\n",
    "loss_fn_category = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "# Define metrics\n",
    "train_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_category')\n",
    "val_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy_category')\n",
    "\n",
    "# Define the supervised contrastive loss function\n",
    "def supervised_contrastive_loss(labels, features, temperature=0.1):\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    label_mask = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    features = tf.math.l2_normalize(features, axis=1)\n",
    "    similarity_matrix = tf.matmul(features, features, transpose_b=True) / temperature\n",
    "    logits_max = tf.reduce_max(similarity_matrix, axis=1, keepdims=True)\n",
    "    logits = similarity_matrix - logits_max\n",
    "    exp_logits = tf.exp(logits) * tf.cast(label_mask, tf.float32)\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True) + 1e-8)\n",
    "    mean_log_prob_pos = tf.reduce_sum(log_prob * tf.cast(label_mask, tf.float32), axis=1) / tf.reduce_sum(tf.cast(label_mask, tf.float32), axis=1)\n",
    "    loss = -tf.reduce_mean(mean_log_prob_pos)\n",
    "    return loss\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Custom Training Loop\n",
    "# -------------------------------\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = model([input_ids, attention_masks, adjacency], training=True)\n",
    "        predictions_category = predictions[0]\n",
    "        resonance_scores = predictions[1]  # Resonance scores (if needed for other tasks)\n",
    "\n",
    "        # Compute per-sample standard loss for category\n",
    "        cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "        # Compute smoothness loss (if required by your architecture)\n",
    "        resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)  # (batch_size, seq_length)\n",
    "        resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "        squared_diff = tf.square(resonance_diff)\n",
    "        smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])  # (batch_size,)\n",
    "        smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "        # Remove contrastive loss (since features aren't being returned)\n",
    "        total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    # Forward pass\n",
    "    predictions = model([input_ids, attention_masks, adjacency], training=False)\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    # Compute per-sample standard loss for category\n",
    "    cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "    # Compute smoothness loss (if required by your architecture)\n",
    "    resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)\n",
    "    resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "    squared_diff = tf.square(resonance_diff)\n",
    "    smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])\n",
    "    smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "    # Remove contrastive loss (since features aren't being returned)\n",
    "    total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Update metrics\n",
    "    val_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training the Model\n",
    "# -------------------------------\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_train_ids,\n",
    "    'attention_masks': X_train_masks,\n",
    "    'adjacency': adjacency_train\n",
    "}, y_train_category)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_test_ids,\n",
    "    'attention_masks': X_test_masks,\n",
    "    'adjacency': adjacency_test\n",
    "}, y_test_category)).batch(batch_size)\n",
    "\n",
    "# Initialize history dictionaries\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_cce_loss_category': [],\n",
    "    'train_smoothness_loss': [],\n",
    "    'train_accuracy_category': [],\n",
    "    'val_loss': [],\n",
    "    'val_cce_loss_category': [],\n",
    "    'val_smoothness_loss': [],\n",
    "    'val_accuracy_category': [],\n",
    "    'epoch_time': []  # Added to record time per epoch\n",
    "}\n",
    "\n",
    "# Start time of training\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch + 1}\")\n",
    "    epoch_start_time = time.time()  # Record start time of the epoch\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_accuracy_category.reset_states()\n",
    "    val_accuracy_category.reset_states()\n",
    "\n",
    "    # Training\n",
    "    total_loss_avg = tf.keras.metrics.Mean()\n",
    "    cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for step, (batch_inputs, batch_labels_category) in enumerate(train_dataset):\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the train_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = train_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        total_loss_avg.update_state(total_loss)\n",
    "        cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        smoothness_loss_avg.update_state(smoothness_loss)\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Total Loss = {total_loss_avg.result():.4f}, \"\n",
    "                  f\"CCE Loss Category = {cce_loss_category_avg.result():.4f}, \"\n",
    "                  f\"Smoothness Loss = {smoothness_loss_avg.result():.4f}, \"\n",
    "                  f\"Train Accuracy Category = {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Record training metrics\n",
    "    history['train_loss'].append(total_loss_avg.result().numpy())\n",
    "    history['train_cce_loss_category'].append(cce_loss_category_avg.result().numpy())\n",
    "    history['train_smoothness_loss'].append(smoothness_loss_avg.result().numpy())\n",
    "    history['train_accuracy_category'].append(train_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training CCE Loss Category: {cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Smoothness Loss: {smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Accuracy Category: {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss_avg = tf.keras.metrics.Mean()\n",
    "    val_cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    val_smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for batch_inputs, batch_labels_category in test_dataset:\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the test_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = test_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        val_loss_avg.update_state(total_loss)\n",
    "        val_cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        val_smoothness_loss_avg.update_state(smoothness_loss)\n",
    "\n",
    "    # Record validation metrics\n",
    "    history['val_loss'].append(val_loss_avg.result().numpy())\n",
    "    history['val_cce_loss_category'].append(val_cce_loss_category_avg.result().numpy())\n",
    "    history['val_smoothness_loss'].append(val_smoothness_loss_avg.result().numpy())\n",
    "    history['val_accuracy_category'].append(val_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {val_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation CCE Loss Category: {val_cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Smoothness Loss: {val_smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Accuracy Category: {val_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    history['epoch_time'].append(epoch_duration)\n",
    "    print(f\"Epoch {epoch+1} Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "# Total training time\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "print(f\"\\nTotal Training Time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def compute_macro_precision(y_true, y_pred, num_classes):\n",
    "    # Calculate precision for each class\n",
    "    precision_per_class = tf.keras.metrics.Precision(class_id=None, num_classes=num_classes)\n",
    "    precision_per_class.update_state(y_true, y_pred)\n",
    "    precision = precision_per_class.result().numpy()\n",
    "    return precision\n",
    "\n",
    "def compute_macro_recall(y_true, y_pred, num_classes):\n",
    "    # Calculate recall for each class\n",
    "    recall_per_class = tf.keras.metrics.Recall(class_id=None, num_classes=num_classes)\n",
    "    recall_per_class.update_state(y_true, y_pred)\n",
    "    recall = recall_per_class.result().numpy()\n",
    "    return recall\n",
    "\n",
    "def compute_macro_f1(y_true, y_pred, num_classes):\n",
    "    # Calculate F1 score for each class\n",
    "    precision = compute_macro_precision(y_true, y_pred, num_classes)\n",
    "    recall = compute_macro_recall(y_true, y_pred, num_classes)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Evaluation and Visualization\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on the test set\n",
    "all_predictions_category = []\n",
    "all_labels_category = []\n",
    "all_resonance_scores = []\n",
    "\n",
    "for batch_inputs, batch_labels_category in test_dataset:\n",
    "    input_ids = batch_inputs['input_ids']\n",
    "    attention_masks = batch_inputs['attention_masks']\n",
    "    adjacency = batch_inputs['adjacency']\n",
    "\n",
    "    predictions = model.predict([input_ids, attention_masks, adjacency])\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    predicted_labels_category = np.argmax(predictions_category, axis=1)\n",
    "\n",
    "    all_predictions_category.extend(predicted_labels_category)\n",
    "    all_labels_category.extend(batch_labels_category.numpy())\n",
    "    all_resonance_scores.extend(resonance_scores)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels_category = np.array(all_labels_category)\n",
    "all_predictions_category = np.array(all_predictions_category)\n",
    "\n",
    "# Calculate metrics for Category\n",
    "accuracy_category = accuracy_score(all_labels_category, all_predictions_category)\n",
    "f1_category = f1_score(all_labels_category, all_predictions_category, average='macro')\n",
    "precision_category = precision_score(all_labels_category, all_predictions_category, average='macro')\n",
    "recall_category = recall_score(all_labels_category, all_predictions_category, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy (Category): {accuracy_category:.4f}\")\n",
    "print(f\"Test Macro F1 Score (Category): {f1_category:.4f}\")\n",
    "print(f\"Test Macro Precision (Category): {precision_category:.4f}\")\n",
    "print(f\"Test Macro Recall (Category): {recall_category:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Category\n",
    "plt.figure(figsize=(4, 4))\n",
    "cm_category = confusion_matrix(all_labels_category, all_predictions_category)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_category, display_labels=category_encoder.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=90)\n",
    "plt.title('Confusion Matrix - Category')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
