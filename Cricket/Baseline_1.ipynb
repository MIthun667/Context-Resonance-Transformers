{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for 1 GPU(s).\n",
      "Initial DataFrame:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...    other  positive\n",
      "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...     team  positive\n",
      "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?     team  positive\n",
      "3                              সৌম্যকে বাদ দেওয়া হোক  batting  negative\n",
      "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...     team  positive\n",
      "Initial Data Shape: (2979, 3)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...    other  positive\n",
      "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...     team  positive\n",
      "2                           বাংলাদেশের ভারতের সাপর্ট     team  positive\n",
      "3                                        সৌম্যকে বাদ  batting  negative\n",
      "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে     team  positive\n",
      "Category distribution after upsampling:\n",
      "Category\n",
      "bowling            2799\n",
      "batting            2226\n",
      "team               2094\n",
      "other              1913\n",
      "team management    1468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Polarity distribution after upsampling:\n",
      "Polarity\n",
      "negative    3500\n",
      "neutral     3500\n",
      "positive    3500\n",
      "Name: count, dtype: int64\n",
      "Encoded Category and Polarity:\n",
      "  Category  Category_encoded  Polarity  Polarity_encoded\n",
      "0  bowling                 1  negative                 0\n",
      "1    other                 2   neutral                 1\n",
      "2  batting                 0   neutral                 1\n",
      "3     team                 3   neutral                 1\n",
      "4  batting                 0   neutral                 1\n",
      "\n",
      "Tokenizing data for model: IndicBERT\n",
      "Error loading tokenizer for IndicBERT: Can't load tokenizer for 'ai4bharat/indic-bert'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'ai4bharat/indic-bert' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.\n",
      "\n",
      "Tokenizing data for model: XLM-RoBERTa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 329/329 [00:04<00:00, 73.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing data for model: MuRIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mhose\\.cache\\huggingface\\hub\\models--google--muril-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Tokenizing: 100%|██████████| 329/329 [00:00<00:00, 1089.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing data for model: BanglaBERT\n",
      "Error loading tokenizer for BanglaBERT: AshrafulIslam/BanglaBERT is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "Skipping model IndicBERT due to previous errors.\n",
      "Skipping model BanglaBERT due to previous errors.\n",
      "Skipping model IndicBERT due to previous errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: XLM-RoBERTa\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 85s 253ms/step - loss: 2.3075 - category_loss: 1.3237 - polarity_loss: 0.9838 - category_accuracy: 0.4417 - polarity_accuracy: 0.4963 - val_loss: 1.4345 - val_category_loss: 0.7596 - val_polarity_loss: 0.6749 - val_category_accuracy: 0.7400 - val_polarity_accuracy: 0.7514\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 65s 248ms/step - loss: 1.1706 - category_loss: 0.6741 - polarity_loss: 0.4965 - category_accuracy: 0.7779 - polarity_accuracy: 0.8179 - val_loss: 0.7383 - val_category_loss: 0.4803 - val_polarity_loss: 0.2580 - val_category_accuracy: 0.8505 - val_polarity_accuracy: 0.9095\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 65s 246ms/step - loss: 0.6611 - category_loss: 0.4321 - polarity_loss: 0.2290 - category_accuracy: 0.8619 - polarity_accuracy: 0.9256 - val_loss: 0.5389 - val_category_loss: 0.3697 - val_polarity_loss: 0.1692 - val_category_accuracy: 0.8748 - val_polarity_accuracy: 0.9467\n",
      "\n",
      "Evaluating model: XLM-RoBERTa\n",
      "66/66 [==============================] - 6s 52ms/step\n",
      "\n",
      "Category Classification Report for XLM-RoBERTa:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        batting       0.89      0.89      0.89       445\n",
      "        bowling       0.90      0.93      0.91       560\n",
      "          other       0.88      0.82      0.85       383\n",
      "           team       0.85      0.79      0.82       419\n",
      "team management       0.83      0.95      0.88       293\n",
      "\n",
      "       accuracy                           0.87      2100\n",
      "      macro avg       0.87      0.87      0.87      2100\n",
      "   weighted avg       0.88      0.87      0.87      2100\n",
      "\n",
      "\n",
      "Polarity Classification Report for XLM-RoBERTa:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.89      0.93       729\n",
      "     neutral       0.98      0.98      0.98       686\n",
      "    positive       0.89      0.97      0.93       685\n",
      "\n",
      "    accuracy                           0.95      2100\n",
      "   macro avg       0.95      0.95      0.95      2100\n",
      "weighted avg       0.95      0.95      0.95      2100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 421). These functions will not be directly callable after loading.\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 410\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m    409\u001b[0m pretrained_model_info \u001b[38;5;241m=\u001b[39m pretrained_models[model_name]\n\u001b[1;32m--> 410\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_polarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[0;32m    413\u001b[0m history, pred_categories, pred_polarities \u001b[38;5;241m=\u001b[39m train_and_evaluate(\n\u001b[0;32m    414\u001b[0m     model,\n\u001b[0;32m    415\u001b[0m     tokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    426\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE\n\u001b[0;32m    427\u001b[0m )\n",
      "Cell \u001b[1;32mIn[2], line 247\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(pretrained_model_info, num_categories, num_polarities, max_len)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[0;32m    246\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_name)\n\u001b[1;32m--> 247\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Define inputs\u001b[39;00m\n\u001b[0;32m    250\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\modeling_tf_utils.py:2843\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m SAFE_WEIGHTS_NAME:\n\u001b[0;32m   2840\u001b[0m     \u001b[38;5;66;03m# Did not find the safetensors file, let's fallback to TF.\u001b[39;00m\n\u001b[0;32m   2841\u001b[0m     \u001b[38;5;66;03m# No support for sharded safetensors yet, so we'll raise an error if that's all we find.\u001b[39;00m\n\u001b[0;32m   2842\u001b[0m     filename \u001b[38;5;241m=\u001b[39m TF2_WEIGHTS_NAME\n\u001b[1;32m-> 2843\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m   2844\u001b[0m         pretrained_model_name_or_path, TF2_WEIGHTS_NAME, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[0;32m   2845\u001b[0m     )\n\u001b[0;32m   2846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m TF2_WEIGHTS_NAME:\n\u001b[0;32m   2847\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[0;32m   2848\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m   2849\u001b[0m         pretrained_model_name_or_path, TF2_WEIGHTS_INDEX_NAME, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[0;32m   2850\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    551\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\urllib3\\response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\urllib3\\response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\urllib3\\response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\urllib3\\response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sentiment_analysis_multimodel_finetune.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    TFBertModel,\n",
    "    XLMRobertaTokenizer,\n",
    "    TFXLMRobertaModel,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModel,\n",
    ")\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Download NLTK resources if not already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Bengali stopwords and lemmatizer\n",
    "# Note: WordNetLemmatizer is for English. For Bengali, consider using a Bengali-specific lemmatizer or skip lemmatization.\n",
    "# For demonstration, proceed with lemmatization, but it may not work correctly for Bengali.\n",
    "# Alternatively, use NLTK's SnowballStemmer for possible Bengali support.\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# -------------------------------\n",
    "# 1. GPU Memory Management\n",
    "# -------------------------------\n",
    "\n",
    "# Enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "# Ensure the CSV has at least three columns: 'Text', 'Category', 'Polarity'\n",
    "data_path = r\"F:\\Context-Resonance Transformer\\Cricket\\Cricket - Sheet1.csv\"  # Update this path as needed\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[['Text', 'Category', 'Polarity']]\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Keep only Bengali characters: Unicode range for Bengali: \\u0980-\\u09FF\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "    words = text.split()\n",
    "    # Lemmatize and remove stopwords if available\n",
    "    if stop_words:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    else:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].astype(str).apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# Upsampling 'Category' and 'Polarity' to balance classes\n",
    "\n",
    "# Define a function to perform random upsampling\n",
    "def upsample(df, target_column):\n",
    "    # Get the maximum count of samples in any class\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "\n",
    "    # Separate each class and upsample the minority classes\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        # Get samples for the current label\n",
    "        df_label = df[df[target_column] == label]\n",
    "\n",
    "        # Upsample minority classes to match the majority class count\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,            # Sample with replacement\n",
    "            n_samples=max_count,     # Match the number of samples in the majority class\n",
    "            random_state=42          # Set random seed for reproducibility\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "\n",
    "    # Combine the upsampled DataFrames\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "# Apply upsampling to 'Category' and 'Polarity'\n",
    "df_upsampled_category = upsample(df, 'Category')\n",
    "df_upsampled_polarity = upsample(df_upsampled_category, 'Polarity')\n",
    "\n",
    "# Shuffle the DataFrame to mix the resampled classes\n",
    "df_upsampled = df_upsampled_polarity.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display new class distribution\n",
    "print(\"Category distribution after upsampling:\")\n",
    "print(df_upsampled['Category'].value_counts())\n",
    "print(\"\\nPolarity distribution after upsampling:\")\n",
    "print(df_upsampled['Polarity'].value_counts())\n",
    "\n",
    "# Encode 'Category' and 'Polarity' labels\n",
    "category_encoder = LabelEncoder()\n",
    "polarity_encoder = LabelEncoder()\n",
    "\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Category'])\n",
    "df_upsampled['Polarity_encoded'] = polarity_encoder.fit_transform(df_upsampled['Polarity'])\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Encoded Category and Polarity:\")\n",
    "print(df_upsampled[['Category', 'Category_encoded', 'Polarity', 'Polarity_encoded']].head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Tokenization and Adjacency Matrix Creation\n",
    "# -------------------------------\n",
    "\n",
    "# Define the pre-trained models and their corresponding tokenizers\n",
    "pretrained_models = {\n",
    "    'IndicBERT': {\n",
    "        'tokenizer': BertTokenizer,\n",
    "        'model': TFBertModel,\n",
    "        'pretrained_name': 'ai4bharat/indic-bert'\n",
    "    },\n",
    "    'XLM-RoBERTa': {\n",
    "        'tokenizer': XLMRobertaTokenizer,\n",
    "        'model': TFXLMRobertaModel,\n",
    "        'pretrained_name': 'xlm-roberta-base'\n",
    "    },\n",
    "    'MuRIL': {\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': TFAutoModel,\n",
    "        'pretrained_name': 'google/muril-base-cased'\n",
    "    },\n",
    "    'BanglaBERT': {  # Ensure this model exists or remove if unavailable\n",
    "        'tokenizer': BertTokenizer,\n",
    "        'model': TFBertModel,\n",
    "        'pretrained_name': 'AshrafulIslam/BanglaBERT'  # Updated to a valid model\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to create window-based adjacency matrices\n",
    "def window_based_adjacency(sentences, window_size=2, max_len=50):\n",
    "    \"\"\"\n",
    "    Creates adjacency matrices based on a sliding window approach.\n",
    "    Each token is connected to its neighbors within the window size.\n",
    "    \"\"\"\n",
    "    adjacency_matrices = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()[:max_len]\n",
    "        num_tokens = len(tokens)\n",
    "        adj = np.zeros((max_len, max_len), dtype=np.float32)\n",
    "\n",
    "        for i in range(num_tokens):\n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, num_tokens)):\n",
    "                if i != j:\n",
    "                    adj[i, j] = 1.0\n",
    "\n",
    "        adjacency_matrices.append(adj)\n",
    "\n",
    "    return np.array(adjacency_matrices, dtype=np.float32)\n",
    "\n",
    "# Function to tokenize sentences\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences in batches for efficiency.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            list(batch),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "    # Concatenate all batches\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Function to build and compile the model\n",
    "def build_model(pretrained_model_info, num_categories, num_polarities, max_len=20):\n",
    "    \"\"\"\n",
    "    Builds a multi-task model with shared pre-trained layers and separate output layers.\n",
    "    \"\"\"\n",
    "    tokenizer_class = pretrained_model_info['tokenizer']\n",
    "    model_class = pretrained_model_info['model']\n",
    "    pretrained_name = pretrained_model_info['pretrained_name']\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_name)\n",
    "    bert_model = model_class.from_pretrained(pretrained_name)\n",
    "\n",
    "    # Define inputs\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    # BERT embeddings\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    # For models like XLM-RoBERTa and MuRIL, the pooled output might be at index 1\n",
    "    # For BERT-based models, it's also at index 1\n",
    "    pooled_output = bert_outputs[1]\n",
    "\n",
    "    # Shared Dense layer\n",
    "    shared_dense = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\n",
    "\n",
    "    # Category output\n",
    "    category_output = tf.keras.layers.Dense(num_categories, activation='softmax', name='category')(shared_dense)\n",
    "\n",
    "    # Polarity output\n",
    "    polarity_output = tf.keras.layers.Dense(num_polarities, activation='softmax', name='polarity')(shared_dense)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[category_output, polarity_output])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss={\n",
    "            'category': 'sparse_categorical_crossentropy',\n",
    "            'polarity': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'category': 'accuracy',\n",
    "            'polarity': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, tokenizer, X_train_ids, X_train_masks, y_train_category, y_train_polarity,\n",
    "                       X_test_ids, X_test_masks, y_test_category, y_test_polarity, model_name, epochs=3, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains the model and evaluates its performance on the test set.\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    history = model.fit(\n",
    "        {'input_ids': X_train_ids, 'attention_mask': X_train_masks},\n",
    "        {'category': y_train_category, 'polarity': y_train_polarity},\n",
    "        validation_data=(\n",
    "            {'input_ids': X_test_ids, 'attention_mask': X_test_masks},\n",
    "            {'category': y_test_category, 'polarity': y_test_polarity}\n",
    "        ),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"\\nEvaluating model: {model_name}\")\n",
    "    predictions = model.predict({'input_ids': X_test_ids, 'attention_mask': X_test_masks})\n",
    "    pred_categories = np.argmax(predictions[0], axis=1)\n",
    "    pred_polarities = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "    # Category Evaluation\n",
    "    print(f\"\\nCategory Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test_category, pred_categories, target_names=category_encoder.classes_))\n",
    "\n",
    "    # Polarity Evaluation\n",
    "    print(f\"\\nPolarity Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test_polarity, pred_polarities, target_names=polarity_encoder.classes_))\n",
    "\n",
    "    # Return history and predictions if needed\n",
    "    return history, pred_categories, pred_polarities\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Model Configuration\n",
    "# -------------------------------\n",
    "\n",
    "# Define the list of pre-trained models to fine-tune\n",
    "selected_models = ['IndicBERT', 'XLM-RoBERTa', 'MuRIL', 'BanglaBERT']  # Ensure BanglaBERT is available\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN = 20\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Tokenization\n",
    "# -------------------------------\n",
    "\n",
    "# Tokenize the data for each model and store in a dictionary\n",
    "tokenized_data = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    print(f\"\\nTokenizing data for model: {model_name}\")\n",
    "    try:\n",
    "        tokenizer = pretrained_models[model_name]['tokenizer'].from_pretrained(pretrained_models[model_name]['pretrained_name'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer for {model_name}: {e}\")\n",
    "        continue\n",
    "    input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE)\n",
    "    tokenized_data[model_name] = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_masks': attention_masks\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Preparing Labels and Splits\n",
    "# -------------------------------\n",
    "\n",
    "# Define labels for multi-task learning\n",
    "labels_category = df_upsampled['Category_encoded'].values\n",
    "labels_polarity = df_upsampled['Polarity_encoded'].values\n",
    "\n",
    "# Split the data into training and testing sets for each model\n",
    "X_train_ids_dict = {}\n",
    "X_test_ids_dict = {}\n",
    "X_train_masks_dict = {}\n",
    "X_test_masks_dict = {}\n",
    "y_train_category_dict = {}\n",
    "y_test_category_dict = {}\n",
    "y_train_polarity_dict = {}\n",
    "y_test_polarity_dict = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in tokenized_data:\n",
    "        print(f\"Skipping model {model_name} due to previous errors.\")\n",
    "        continue\n",
    "    X_train_ids, X_test_ids, X_train_masks, X_test_masks, y_train_cat, y_test_cat, y_train_pol, y_test_pol = train_test_split(\n",
    "        tokenized_data[model_name]['input_ids'],\n",
    "        tokenized_data[model_name]['attention_masks'],\n",
    "        labels_category,\n",
    "        labels_polarity,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=labels_category\n",
    "    )\n",
    "    X_train_ids_dict[model_name] = X_train_ids\n",
    "    X_test_ids_dict[model_name] = X_test_ids\n",
    "    X_train_masks_dict[model_name] = X_train_masks\n",
    "    X_test_masks_dict[model_name] = X_test_masks\n",
    "    y_train_category_dict[model_name] = y_train_cat\n",
    "    y_test_category_dict[model_name] = y_test_cat\n",
    "    y_train_polarity_dict[model_name] = y_train_pol\n",
    "    y_test_polarity_dict[model_name] = y_test_pol\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Model Building, Training, and Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "# Number of classes\n",
    "num_categories = df_upsampled['Category_encoded'].nunique()\n",
    "num_polarities = df_upsampled['Polarity_encoded'].nunique()\n",
    "\n",
    "# Dictionary to store results\n",
    "model_results = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in tokenized_data:\n",
    "        print(f\"Skipping model {model_name} due to previous errors.\")\n",
    "        continue\n",
    "    # Build the model\n",
    "    pretrained_model_info = pretrained_models[model_name]\n",
    "    model, tokenizer = build_model(pretrained_model_info, num_categories, num_polarities, max_len=MAX_LEN)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    history, pred_categories, pred_polarities = train_and_evaluate(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        X_train_ids_dict[model_name],\n",
    "        X_train_masks_dict[model_name],\n",
    "        y_train_category_dict[model_name],\n",
    "        y_train_polarity_dict[model_name],\n",
    "        X_test_ids_dict[model_name],\n",
    "        X_test_masks_dict[model_name],\n",
    "        y_test_category_dict[model_name],\n",
    "        y_test_polarity_dict[model_name],\n",
    "        model_name,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Save the model and tokenizer if desired\n",
    "    save_dir = f'./fine_tuned_models/{model_name}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model.save(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'history': history,\n",
    "        'pred_categories': pred_categories,\n",
    "        'pred_polarities': pred_polarities\n",
    "    }\n",
    "\n",
    "print(\"\\nAll models have been trained and evaluated.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Optional: Compare Model Performances\n",
    "# -------------------------------\n",
    "\n",
    "# Example: Plotting category accuracy for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name in selected_models:\n",
    "    if model_name not in model_results:\n",
    "        continue\n",
    "    acc = model_results[model_name]['history'].history['category_accuracy'][-1]\n",
    "    val_acc = model_results[model_name]['history'].history['val_category_accuracy'][-1]\n",
    "    plt.bar(model_name, acc, alpha=0.6, label=f'{model_name} Train Acc')\n",
    "    plt.bar(model_name, val_acc, alpha=0.6, label=f'{model_name} Val Acc')\n",
    "\n",
    "plt.xlabel('Pre-trained Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Category Classification Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for 1 GPU(s).\n",
      "Initial DataFrame:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...    other  positive\n",
      "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...     team  positive\n",
      "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?     team  positive\n",
      "3                              সৌম্যকে বাদ দেওয়া হোক  batting  negative\n",
      "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...     team  positive\n",
      "Initial Data Shape: (2979, 3)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...    other  positive\n",
      "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...     team  positive\n",
      "2                           বাংলাদেশের ভারতের সাপর্ট     team  positive\n",
      "3                                        সৌম্যকে বাদ  batting  negative\n",
      "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে     team  positive\n",
      "Category distribution after upsampling:\n",
      "Category\n",
      "bowling            2799\n",
      "batting            2226\n",
      "team               2094\n",
      "other              1913\n",
      "team management    1468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Polarity distribution after upsampling:\n",
      "Polarity\n",
      "negative    3500\n",
      "neutral     3500\n",
      "positive    3500\n",
      "Name: count, dtype: int64\n",
      "Encoded Category and Polarity:\n",
      "  Category  Category_encoded  Polarity  Polarity_encoded\n",
      "0  bowling                 1  negative                 0\n",
      "1    other                 2   neutral                 1\n",
      "2  batting                 0   neutral                 1\n",
      "3     team                 3   neutral                 1\n",
      "4  batting                 0   neutral                 1\n",
      "\n",
      "Tokenizing data for model: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 329/329 [00:01<00:00, 267.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing data for model: sagorsarker/bangla-bert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 329/329 [00:00<00:00, 1067.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model for: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: bert-base-multilingual-cased\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 72s 218ms/step - loss: 2.1663 - category_loss: 1.2490 - polarity_loss: 0.9173 - category_accuracy: 0.5014 - polarity_accuracy: 0.5499 - val_loss: 1.3358 - val_category_loss: 0.7870 - val_polarity_loss: 0.5488 - val_category_accuracy: 0.7471 - val_polarity_accuracy: 0.7838\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 54s 206ms/step - loss: 1.1204 - category_loss: 0.6995 - polarity_loss: 0.4209 - category_accuracy: 0.7727 - polarity_accuracy: 0.8421 - val_loss: 0.7086 - val_category_loss: 0.4692 - val_polarity_loss: 0.2394 - val_category_accuracy: 0.8495 - val_polarity_accuracy: 0.9238\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 0.7110 - category_loss: 0.4811 - polarity_loss: 0.2299 - category_accuracy: 0.8433 - polarity_accuracy: 0.9226 - val_loss: 0.4933 - val_category_loss: 0.3586 - val_polarity_loss: 0.1347 - val_category_accuracy: 0.8829 - val_polarity_accuracy: 0.9624\n",
      "\n",
      "Evaluating model: bert-base-multilingual-cased\n",
      "66/66 [==============================] - 6s 57ms/step\n",
      "\n",
      "Category Classification Report for bert-base-multilingual-cased:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        batting       0.85      0.93      0.89       445\n",
      "        bowling       0.91      0.94      0.93       560\n",
      "          other       0.89      0.84      0.87       383\n",
      "           team       0.89      0.75      0.81       419\n",
      "team management       0.85      0.96      0.90       293\n",
      "\n",
      "       accuracy                           0.88      2100\n",
      "      macro avg       0.88      0.88      0.88      2100\n",
      "   weighted avg       0.88      0.88      0.88      2100\n",
      "\n",
      "\n",
      "Polarity Classification Report for bert-base-multilingual-cased:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.96       729\n",
      "     neutral       0.97      0.98      0.98       686\n",
      "    positive       0.94      0.96      0.95       685\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.96      0.96      0.96      2100\n",
      "weighted avg       0.96      0.96      0.96      2100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 421). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_models/bert-base-multilingual-cased\n",
      "\n",
      "Building model for: sagorsarker/bangla-bert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: sagorsarker/bangla-bert-base\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 69s 212ms/step - loss: 1.9818 - category_loss: 1.1338 - polarity_loss: 0.8479 - category_accuracy: 0.5624 - polarity_accuracy: 0.6038 - val_loss: 1.0179 - val_category_loss: 0.5993 - val_polarity_loss: 0.4186 - val_category_accuracy: 0.8095 - val_polarity_accuracy: 0.8624\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 0.8779 - category_loss: 0.5331 - polarity_loss: 0.3448 - category_accuracy: 0.8304 - polarity_accuracy: 0.8846 - val_loss: 0.6194 - val_category_loss: 0.3691 - val_polarity_loss: 0.2503 - val_category_accuracy: 0.8876 - val_polarity_accuracy: 0.9124\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 53s 203ms/step - loss: 0.5021 - category_loss: 0.3377 - polarity_loss: 0.1644 - category_accuracy: 0.8939 - polarity_accuracy: 0.9542 - val_loss: 0.3848 - val_category_loss: 0.2761 - val_polarity_loss: 0.1087 - val_category_accuracy: 0.9095 - val_polarity_accuracy: 0.9643\n",
      "\n",
      "Evaluating model: sagorsarker/bangla-bert-base\n",
      "66/66 [==============================] - 6s 59ms/step\n",
      "\n",
      "Category Classification Report for sagorsarker/bangla-bert-base:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        batting       0.90      0.91      0.91       445\n",
      "        bowling       0.94      0.92      0.93       560\n",
      "          other       0.93      0.95      0.94       383\n",
      "           team       0.88      0.81      0.84       419\n",
      "team management       0.89      0.98      0.93       293\n",
      "\n",
      "       accuracy                           0.91      2100\n",
      "      macro avg       0.91      0.91      0.91      2100\n",
      "   weighted avg       0.91      0.91      0.91      2100\n",
      "\n",
      "\n",
      "Polarity Classification Report for sagorsarker/bangla-bert-base:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.94      0.96       729\n",
      "     neutral       0.98      0.99      0.98       686\n",
      "    positive       0.94      0.97      0.95       685\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.96      0.96      0.96      2100\n",
      "weighted avg       0.96      0.96      0.96      2100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 421). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_models/sagorsarker_bangla-bert-base\n",
      "\n",
      "All models have been trained and evaluated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentiment_analysis_multimodel_finetune.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModel,\n",
    "    TFBertModel,\n",
    "    TFXLMRobertaModel,\n",
    "    TFAlbertModel\n",
    ")\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Download NLTK resources if not already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Bengali stopwords and lemmatizer\n",
    "# Note: NLTK may not have comprehensive Bengali stopwords. Consider using a custom list if needed.\n",
    "try:\n",
    "    stop_words = set(stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# -------------------------------\n",
    "# 1. GPU Memory Management\n",
    "# -------------------------------\n",
    "\n",
    "# Enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "# Ensure the CSV has at least three columns: 'Text', 'Category', 'Polarity'\n",
    "data_path = r\"F:\\Context-Resonance Transformer\\Cricket\\Cricket - Sheet1.csv\"  # Update this path as needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['Text', 'Category', 'Polarity']]\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Keep only Bengali characters: Unicode range for Bengali: \\u0980-\\u09FF\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "    words = text.split()\n",
    "    # Lemmatize and remove stopwords if available\n",
    "    if stop_words:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    else:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply cleaning\n",
    "df['Text'] = df['Text'].astype(str).apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# Upsampling 'Category' and 'Polarity' to balance classes\n",
    "\n",
    "# Define a function to perform random upsampling\n",
    "def upsample(df, target_column):\n",
    "    # Get the maximum count of samples in any class\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "\n",
    "    # Separate each class and upsample the minority classes\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        # Get samples for the current label\n",
    "        df_label = df[df[target_column] == label]\n",
    "\n",
    "        # Upsample minority classes to match the majority class count\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,            # Sample with replacement\n",
    "            n_samples=max_count,     # Match the number of samples in the majority class\n",
    "            random_state=42          # Set random seed for reproducibility\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "\n",
    "    # Combine the upsampled DataFrames\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "# Apply upsampling to 'Category' and 'Polarity'\n",
    "df_upsampled_category = upsample(df, 'Category')\n",
    "df_upsampled_polarity = upsample(df_upsampled_category, 'Polarity')\n",
    "\n",
    "# Shuffle the DataFrame to mix the resampled classes\n",
    "df_upsampled = df_upsampled_polarity.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display new class distribution\n",
    "print(\"Category distribution after upsampling:\")\n",
    "print(df_upsampled['Category'].value_counts())\n",
    "print(\"\\nPolarity distribution after upsampling:\")\n",
    "print(df_upsampled['Polarity'].value_counts())\n",
    "\n",
    "# Encode 'Category' and 'Polarity' labels\n",
    "category_encoder = LabelEncoder()\n",
    "polarity_encoder = LabelEncoder()\n",
    "\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Category'])\n",
    "df_upsampled['Polarity_encoded'] = polarity_encoder.fit_transform(df_upsampled['Polarity'])\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Encoded Category and Polarity:\")\n",
    "print(df_upsampled[['Category', 'Category_encoded', 'Polarity', 'Polarity_encoded']].head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Model Configuration\n",
    "# -------------------------------\n",
    "\n",
    "# Define the list of pre-trained models to fine-tune\n",
    "# Ensure these models have TensorFlow support. If not, adjust accordingly.\n",
    "pretrained_models = {\n",
    "    'bert-base-multilingual-cased': {\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': TFBertModel,\n",
    "        'pretrained_name': 'bert-base-multilingual-cased'\n",
    "    },\n",
    "    'sagorsarker/bangla-bert-base': {\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': TFBertModel,\n",
    "        'pretrained_name': 'sagorsarker/bangla-bert-base'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define selected models\n",
    "selected_models = list(pretrained_models.keys())\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Tokenization\n",
    "# -------------------------------\n",
    "\n",
    "# Function to tokenize sentences\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences in batches for efficiency.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        try:\n",
    "            encoded = tokenizer(\n",
    "                list(batch),\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            input_ids.append(encoded['input_ids'])\n",
    "            attention_masks.append(encoded['attention_mask'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error during tokenization for batch starting at index {i}: {e}\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data for each model and store in a dictionary\n",
    "tokenized_data = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    print(f\"\\nTokenizing data for model: {model_name}\")\n",
    "    tokenizer_class = pretrained_models[model_name]['tokenizer']\n",
    "    pretrained_name = pretrained_models[model_name]['pretrained_name']\n",
    "    try:\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer for {model_name}: {e}\")\n",
    "        continue\n",
    "    input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "    tokenized_data[model_name] = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_masks': attention_masks\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Preparing Labels and Splits\n",
    "# -------------------------------\n",
    "\n",
    "# Define labels for multi-task learning\n",
    "labels_category = df_upsampled['Category_encoded'].values\n",
    "labels_polarity = df_upsampled['Polarity_encoded'].values\n",
    "\n",
    "# Split the data into training and testing sets for each model\n",
    "X_train_ids_dict = {}\n",
    "X_test_ids_dict = {}\n",
    "X_train_masks_dict = {}\n",
    "X_test_masks_dict = {}\n",
    "y_train_category_dict = {}\n",
    "y_test_category_dict = {}\n",
    "y_train_polarity_dict = {}\n",
    "y_test_polarity_dict = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in tokenized_data:\n",
    "        print(f\"Skipping model {model_name} due to previous errors.\")\n",
    "        continue\n",
    "    X_train_ids, X_test_ids, X_train_masks, X_test_masks, y_train_cat, y_test_cat, y_train_pol, y_test_pol = train_test_split(\n",
    "        tokenized_data[model_name]['input_ids'],\n",
    "        tokenized_data[model_name]['attention_masks'],\n",
    "        labels_category,\n",
    "        labels_polarity,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=labels_category\n",
    "    )\n",
    "    X_train_ids_dict[model_name] = X_train_ids\n",
    "    X_test_ids_dict[model_name] = X_test_ids\n",
    "    X_train_masks_dict[model_name] = X_train_masks\n",
    "    X_test_masks_dict[model_name] = X_test_masks\n",
    "    y_train_category_dict[model_name] = y_train_cat\n",
    "    y_test_category_dict[model_name] = y_test_cat\n",
    "    y_train_polarity_dict[model_name] = y_train_pol\n",
    "    y_test_polarity_dict[model_name] = y_test_pol\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Model Building, Training, and Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "# Number of classes\n",
    "num_categories = df_upsampled['Category_encoded'].nunique()\n",
    "num_polarities = df_upsampled['Polarity_encoded'].nunique()\n",
    "\n",
    "# Function to build and compile the model\n",
    "def build_model(pretrained_model_info, num_categories, num_polarities, max_len=20):\n",
    "    \"\"\"\n",
    "    Builds a multi-task model with shared pre-trained layers and separate output layers.\n",
    "    \"\"\"\n",
    "    tokenizer_class = pretrained_model_info['tokenizer']\n",
    "    model_class = pretrained_model_info['model']\n",
    "    pretrained_name = pretrained_model_info['pretrained_name']\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    try:\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer for {pretrained_name}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Attempt to load the model with TensorFlow weights first\n",
    "        base_model = model_class.from_pretrained(pretrained_name)\n",
    "    except OSError:\n",
    "        # If TensorFlow weights are unavailable, try loading PyTorch weights\n",
    "        print(f\"TensorFlow weights not found for {pretrained_name}. Attempting to load PyTorch weights.\")\n",
    "        try:\n",
    "            base_model = model_class.from_pretrained(pretrained_name, from_pt=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model for {pretrained_name}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    # Define inputs\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    # Get base model outputs\n",
    "    base_outputs = base_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = base_outputs[1]\n",
    "\n",
    "    # Shared Dense layer\n",
    "    shared_dense = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\n",
    "\n",
    "    # Dropout layer for regularization\n",
    "    shared_dense = tf.keras.layers.Dropout(0.3)(shared_dense)\n",
    "\n",
    "    # Category output\n",
    "    category_output = tf.keras.layers.Dense(num_categories, activation='softmax', name='category')(shared_dense)\n",
    "\n",
    "    # Polarity output\n",
    "    polarity_output = tf.keras.layers.Dense(num_polarities, activation='softmax', name='polarity')(shared_dense)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[category_output, polarity_output])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss={\n",
    "            'category': 'sparse_categorical_crossentropy',\n",
    "            'polarity': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'category': 'accuracy',\n",
    "            'polarity': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, X_train_ids, X_train_masks, y_train_category, y_train_polarity,\n",
    "                       X_test_ids, X_test_masks, y_test_category, y_test_polarity, model_name, epochs=3, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains the model and evaluates its performance on the test set.\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    history = model.fit(\n",
    "        {'input_ids': X_train_ids, 'attention_mask': X_train_masks},\n",
    "        {'category': y_train_category, 'polarity': y_train_polarity},\n",
    "        validation_data=(\n",
    "            {'input_ids': X_test_ids, 'attention_mask': X_test_masks},\n",
    "            {'category': y_test_category, 'polarity': y_test_polarity}\n",
    "        ),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"\\nEvaluating model: {model_name}\")\n",
    "    predictions = model.predict({'input_ids': X_test_ids, 'attention_mask': X_test_masks})\n",
    "    pred_categories = np.argmax(predictions[0], axis=1)\n",
    "    pred_polarities = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "    # Category Evaluation\n",
    "    print(f\"\\nCategory Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test_category, pred_categories, target_names=category_encoder.classes_))\n",
    "\n",
    "    # Polarity Evaluation\n",
    "    print(f\"\\nPolarity Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test_polarity, pred_polarities, target_names=polarity_encoder.classes_))\n",
    "\n",
    "    # Return history and predictions if needed\n",
    "    return history, pred_categories, pred_polarities\n",
    "\n",
    "# Dictionary to store results\n",
    "model_results = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in tokenized_data:\n",
    "        print(f\"Skipping model {model_name} due to previous errors.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nBuilding model for: {model_name}\")\n",
    "    pretrained_model_info = pretrained_models[model_name]\n",
    "    model, tokenizer = build_model(pretrained_model_info, num_categories, num_polarities, max_len=20)\n",
    "\n",
    "    if model is None:\n",
    "        print(f\"Skipping training for {model_name} due to build errors.\")\n",
    "        continue\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    history, pred_categories, pred_polarities = train_and_evaluate(\n",
    "        model,\n",
    "        X_train_ids_dict[model_name],\n",
    "        X_train_masks_dict[model_name],\n",
    "        y_train_category_dict[model_name],\n",
    "        y_train_polarity_dict[model_name],\n",
    "        X_test_ids_dict[model_name],\n",
    "        X_test_masks_dict[model_name],\n",
    "        y_test_category_dict[model_name],\n",
    "        y_test_polarity_dict[model_name],\n",
    "        model_name,\n",
    "        epochs=3,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    save_dir = f'./fine_tuned_models/{model_name.replace(\"/\", \"_\")}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    try:\n",
    "        model.save(save_dir)\n",
    "        tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"Model and tokenizer saved to {save_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model for {model_name}: {e}\")\n",
    "\n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'history': history,\n",
    "        'pred_categories': pred_categories,\n",
    "        'pred_polarities': pred_polarities\n",
    "    }\n",
    "\n",
    "print(\"\\nAll models have been trained and evaluated.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Optional: Compare Model Performances\n",
    "# -------------------------------\n",
    "\n",
    "# Example: Plotting category and polarity accuracy for each model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Category Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "model_labels = []\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in model_results:\n",
    "        continue\n",
    "    history = model_results[model_name]['history']\n",
    "    train_acc.append(history.history['category_accuracy'][-1])\n",
    "    val_acc.append(history.history['val_category_accuracy'][-1])\n",
    "    model_labels.append(model_name)\n",
    "\n",
    "x = np.arange(len(model_labels))  # label locations\n",
    "width = 0.35  # bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width/2, train_acc, width, label='Train Accuracy')\n",
    "rects2 = ax.bar(x + width/2, val_acc, width, label='Validation Accuracy')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Category Classification Accuracy by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_labels, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Attach a text label above each bar\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Similarly, you can plot Polarity Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "train_acc_polar = []\n",
    "val_acc_polar = []\n",
    "model_labels_polar = []\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in model_results:\n",
    "        continue\n",
    "    history = model_results[model_name]['history']\n",
    "    train_acc_polar.append(history.history['polarity_accuracy'][-1])\n",
    "    val_acc_polar.append(history.history['val_polarity_accuracy'][-1])\n",
    "    model_labels_polar.append(model_name)\n",
    "\n",
    "x = np.arange(len(model_labels_polar))  # label locations\n",
    "width = 0.35  # bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width/2, train_acc_polar, width, label='Train Accuracy')\n",
    "rects2 = ax.bar(x + width/2, val_acc_polar, width, label='Validation Accuracy')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Polarity Classification Accuracy by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_labels_polar, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Attach a text label above each bar\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for 1 GPU(s).\n",
      "Initial DataFrame:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...    other  positive\n",
      "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...     team  positive\n",
      "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?     team  positive\n",
      "3                              সৌম্যকে বাদ দেওয়া হোক  batting  negative\n",
      "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...     team  positive\n",
      "Initial Data Shape: (2979, 3)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text Category  Polarity\n",
      "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...    other  positive\n",
      "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...     team  positive\n",
      "2                           বাংলাদেশের ভারতের সাপর্ট     team  positive\n",
      "3                                        সৌম্যকে বাদ  batting  negative\n",
      "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে     team  positive\n",
      "Category distribution after upsampling:\n",
      "Category\n",
      "bowling            2799\n",
      "batting            2226\n",
      "team               2094\n",
      "other              1913\n",
      "team management    1468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Polarity distribution after upsampling:\n",
      "Polarity\n",
      "negative    3500\n",
      "neutral     3500\n",
      "positive    3500\n",
      "Name: count, dtype: int64\n",
      "Encoded Category and Polarity:\n",
      "  Category  Category_encoded  Polarity  Polarity_encoded\n",
      "0  bowling                 1  negative                 0\n",
      "1    other                 2   neutral                 1\n",
      "2  batting                 0   neutral                 1\n",
      "3     team                 3   neutral                 1\n",
      "4  batting                 0   neutral                 1\n"
     ]
    }
   ],
   "source": [
    "# sentiment_analysis_multimodel_finetune.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModel,\n",
    "    TFBertModel,\n",
    "    TFXLMRobertaModel,\n",
    "    TFAlbertModel\n",
    ")\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Download NLTK resources if not already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Bengali stopwords and lemmatizer\n",
    "# Note: NLTK may not have comprehensive Bengali stopwords. Consider using a custom list if needed.\n",
    "try:\n",
    "    stop_words = set(stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# -------------------------------\n",
    "# 1. GPU Memory Management\n",
    "# -------------------------------\n",
    "\n",
    "# Enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "# Ensure the CSV has at least three columns: 'Text', 'Category', 'Polarity'\n",
    "data_path = r\"F:\\Context-Resonance Transformer\\Cricket\\Cricket - Sheet1.csv\"  # Update this path as needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['Text', 'Category', 'Polarity']]\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Keep only Bengali characters: Unicode range for Bengali: \\u0980-\\u09FF\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "    words = text.split()\n",
    "    # Lemmatize and remove stopwords if available\n",
    "    if stop_words:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    else:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply cleaning\n",
    "df['Text'] = df['Text'].astype(str).apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# Upsampling 'Category' and 'Polarity' to balance classes\n",
    "\n",
    "# Define a function to perform random upsampling\n",
    "def upsample(df, target_column):\n",
    "    # Get the maximum count of samples in any class\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "\n",
    "    # Separate each class and upsample the minority classes\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        # Get samples for the current label\n",
    "        df_label = df[df[target_column] == label]\n",
    "\n",
    "        # Upsample minority classes to match the majority class count\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,            # Sample with replacement\n",
    "            n_samples=max_count,     # Match the number of samples in the majority class\n",
    "            random_state=42          # Set random seed for reproducibility\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "\n",
    "    # Combine the upsampled DataFrames\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "# Apply upsampling to 'Category' and 'Polarity'\n",
    "df_upsampled_category = upsample(df, 'Category')\n",
    "df_upsampled_polarity = upsample(df_upsampled_category, 'Polarity')\n",
    "\n",
    "# Shuffle the DataFrame to mix the resampled classes\n",
    "df_upsampled = df_upsampled_polarity.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display new class distribution\n",
    "print(\"Category distribution after upsampling:\")\n",
    "print(df_upsampled['Category'].value_counts())\n",
    "print(\"\\nPolarity distribution after upsampling:\")\n",
    "print(df_upsampled['Polarity'].value_counts())\n",
    "\n",
    "# Encode 'Category' and 'Polarity' labels\n",
    "category_encoder = LabelEncoder()\n",
    "polarity_encoder = LabelEncoder()\n",
    "\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Category'])\n",
    "df_upsampled['Polarity_encoded'] = polarity_encoder.fit_transform(df_upsampled['Polarity'])\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Encoded Category and Polarity:\")\n",
    "print(df_upsampled[['Category', 'Category_encoded', 'Polarity', 'Polarity_encoded']].head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Model Configuration\n",
    "# -------------------------------\n",
    "\n",
    "# Define the list of pre-trained models to fine-tune\n",
    "# Ensure these models have TensorFlow support. If not, adjust accordingly.\n",
    "pretrained_models = {\n",
    "    'xlm-roberta-base': {\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': TFXLMRobertaModel,\n",
    "        'pretrained_name': 'xlm-roberta-base'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define selected models\n",
    "selected_models = list(pretrained_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing data for model: xlm-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 329/329 [00:04<00:00, 81.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Tokenization\n",
    "# -------------------------------\n",
    "\n",
    "# Function to tokenize sentences\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences in batches for efficiency.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        try:\n",
    "            encoded = tokenizer(\n",
    "                list(batch),\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            input_ids.append(encoded['input_ids'])\n",
    "            attention_masks.append(encoded['attention_mask'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error during tokenization for batch starting at index {i}: {e}\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data for each model and store in a dictionary\n",
    "tokenized_data = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    print(f\"\\nTokenizing data for model: {model_name}\")\n",
    "    tokenizer_class = pretrained_models[model_name]['tokenizer']\n",
    "    pretrained_name = pretrained_models[model_name]['pretrained_name']\n",
    "    try:\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer for {model_name}: {e}\")\n",
    "        continue\n",
    "    input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "    tokenized_data[model_name] = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_masks': attention_masks\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Preparing Labels and Splits\n",
    "# -------------------------------\n",
    "\n",
    "# Define labels for multi-task learning\n",
    "labels_category = df_upsampled['Category_encoded'].values\n",
    "labels_polarity = df_upsampled['Polarity_encoded'].values\n",
    "\n",
    "# Split the data into training and testing sets for each model\n",
    "X_train_ids_dict = {}\n",
    "X_test_ids_dict = {}\n",
    "X_train_masks_dict = {}\n",
    "X_test_masks_dict = {}\n",
    "y_train_category_dict = {}\n",
    "y_test_category_dict = {}\n",
    "y_train_polarity_dict = {}\n",
    "y_test_polarity_dict = {}\n",
    "\n",
    "for model_name in selected_models:\n",
    "    if model_name not in tokenized_data:\n",
    "        print(f\"Skipping model {model_name} due to previous errors.\")\n",
    "        continue\n",
    "    X_train_ids, X_test_ids, X_train_masks, X_test_masks, y_train_cat, y_test_cat, y_train_pol, y_test_pol = train_test_split(\n",
    "        tokenized_data[model_name]['input_ids'],\n",
    "        tokenized_data[model_name]['attention_masks'],\n",
    "        labels_category,\n",
    "        labels_polarity,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=labels_category\n",
    "    )\n",
    "    X_train_ids_dict[model_name] = X_train_ids\n",
    "    X_test_ids_dict[model_name] = X_test_ids\n",
    "    X_train_masks_dict[model_name] = X_train_masks\n",
    "    X_test_masks_dict[model_name] = X_test_masks\n",
    "    y_train_category_dict[model_name] = y_train_cat\n",
    "    y_test_category_dict[model_name] = y_test_cat\n",
    "    y_train_polarity_dict[model_name] = y_train_pol\n",
    "    y_test_polarity_dict[model_name] = y_test_pol\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Model Building, Training, and Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "# Number of classes\n",
    "num_categories = df_upsampled['Category_encoded'].nunique()\n",
    "num_polarities = df_upsampled['Polarity_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model for: xlm-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: xlm-roberta-base\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 87s 260ms/step - loss: 2.5085 - category_loss: 1.4625 - polarity_loss: 1.0460 - category_accuracy: 0.3530 - polarity_accuracy: 0.4404 - val_loss: 1.7685 - val_category_loss: 0.9534 - val_polarity_loss: 0.8151 - val_category_accuracy: 0.6719 - val_polarity_accuracy: 0.6362\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 65s 249ms/step - loss: 1.4732 - category_loss: 0.8229 - polarity_loss: 0.6503 - category_accuracy: 0.7219 - polarity_accuracy: 0.7388 - val_loss: 0.9268 - val_category_loss: 0.5638 - val_polarity_loss: 0.3630 - val_category_accuracy: 0.8076 - val_polarity_accuracy: 0.8652\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 66s 249ms/step - loss: 0.8785 - category_loss: 0.5489 - polarity_loss: 0.3296 - category_accuracy: 0.8236 - polarity_accuracy: 0.8900 - val_loss: 0.6633 - val_category_loss: 0.4574 - val_polarity_loss: 0.2059 - val_category_accuracy: 0.8505 - val_polarity_accuracy: 0.9357\n",
      "\n",
      "Evaluating model: xlm-roberta-base\n",
      "66/66 [==============================] - 6s 58ms/step\n",
      "\n",
      "Category Classification Report for xlm-roberta-base:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        batting       0.88      0.87      0.87       445\n",
      "        bowling       0.87      0.92      0.89       560\n",
      "          other       0.92      0.73      0.82       383\n",
      "           team       0.85      0.79      0.82       419\n",
      "team management       0.73      0.94      0.82       293\n",
      "\n",
      "       accuracy                           0.85      2100\n",
      "      macro avg       0.85      0.85      0.84      2100\n",
      "   weighted avg       0.86      0.85      0.85      2100\n",
      "\n",
      "\n",
      "Polarity Classification Report for xlm-roberta-base:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.86      0.92       729\n",
      "     neutral       0.92      0.99      0.95       686\n",
      "    positive       0.92      0.96      0.94       685\n",
      "\n",
      "    accuracy                           0.94      2100\n",
      "   macro avg       0.94      0.94      0.94      2100\n",
      "weighted avg       0.94      0.94      0.94      2100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 421). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_models/xlm-roberta-base\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Modify Selected Model\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "selected_models = ['xlm-roberta-base']\n",
    "\n",
    "# -------------------------------\n",
    "# Model Building, Training, and Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "# Number of classes\n",
    "num_categories = df_upsampled['Category_encoded'].nunique()\n",
    "num_polarities = df_upsampled['Polarity_encoded'].nunique()\n",
    "\n",
    "# Function to build and compile the model\n",
    "def build_model(pretrained_model_info, num_categories, num_polarities, max_len=20):\n",
    "    \"\"\"\n",
    "    Builds a multi-task model with shared pre-trained layers and separate output layers.\n",
    "    \"\"\"\n",
    "    tokenizer_class = pretrained_model_info['tokenizer']\n",
    "    model_class = pretrained_model_info['model']\n",
    "    pretrained_name = pretrained_model_info['pretrained_name']\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_name)\n",
    "    base_model = model_class.from_pretrained(pretrained_name)\n",
    "\n",
    "    # Define inputs\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    # Get base model outputs\n",
    "    base_outputs = base_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = base_outputs[1]\n",
    "\n",
    "    # Shared Dense layer\n",
    "    shared_dense = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\n",
    "    shared_dense = tf.keras.layers.Dropout(0.3)(shared_dense)\n",
    "\n",
    "    # Category output\n",
    "    category_output = tf.keras.layers.Dense(num_categories, activation='softmax', name='category')(shared_dense)\n",
    "\n",
    "    # Polarity output\n",
    "    polarity_output = tf.keras.layers.Dense(num_polarities, activation='softmax', name='polarity')(shared_dense)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[category_output, polarity_output])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss={\n",
    "            'category': 'sparse_categorical_crossentropy',\n",
    "            'polarity': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'category': 'accuracy',\n",
    "            'polarity': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Train and evaluate the xlm-roberta-base model\n",
    "model_name = 'xlm-roberta-base'\n",
    "pretrained_model_info = pretrained_models[model_name]\n",
    "\n",
    "print(f\"\\nBuilding model for: {model_name}\")\n",
    "model, tokenizer = build_model(pretrained_model_info, num_categories, num_polarities, max_len=20)\n",
    "\n",
    "# Train the model\n",
    "print(f\"\\nTraining model: {model_name}\")\n",
    "history = model.fit(\n",
    "    {'input_ids': X_train_ids_dict[model_name], 'attention_mask': X_train_masks_dict[model_name]},\n",
    "    {'category': y_train_category_dict[model_name], 'polarity': y_train_polarity_dict[model_name]},\n",
    "    validation_data=(\n",
    "        {'input_ids': X_test_ids_dict[model_name], 'attention_mask': X_test_masks_dict[model_name]},\n",
    "        {'category': y_test_category_dict[model_name], 'polarity': y_test_polarity_dict[model_name]}\n",
    "    ),\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nEvaluating model: {model_name}\")\n",
    "predictions = model.predict({'input_ids': X_test_ids_dict[model_name], 'attention_mask': X_test_masks_dict[model_name]})\n",
    "pred_categories = np.argmax(predictions[0], axis=1)\n",
    "pred_polarities = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "# Classification Reports\n",
    "print(f\"\\nCategory Classification Report for {model_name}:\")\n",
    "print(classification_report(y_test_category_dict[model_name], pred_categories, target_names=category_encoder.classes_))\n",
    "\n",
    "print(f\"\\nPolarity Classification Report for {model_name}:\")\n",
    "print(classification_report(y_test_polarity_dict[model_name], pred_polarities, target_names=polarity_encoder.classes_))\n",
    "\n",
    "# Save the model and tokenizer\n",
    "save_dir = f'./fine_tuned_models/{model_name.replace(\"/\", \"_\")}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"Model and tokenizer saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
