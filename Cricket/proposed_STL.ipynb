{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                                Text Category\n",
      "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...    other\n",
      "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...     team\n",
      "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?     team\n",
      "3                              সৌম্যকে বাদ দেওয়া হোক  batting\n",
      "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...     team\n",
      "Initial Data Shape: (2979, 2)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text Category\n",
      "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...    other\n",
      "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...     team\n",
      "2                           বাংলাদেশের ভারতের সাপর্ট     team\n",
      "3                                        সৌম্যকে বাদ  batting\n",
      "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে     team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 158/158 [00:01<00:00, 129.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"F:\\Context-Resonance Transformer\\Cricket\\Cricket - Sheet1.csv\")  # Replace with your dataset path\n",
    "df = df[['Text', 'Category']]  # Focus on only one task: Category classification\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Initialize Bengali stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Bengali stopwords\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Remove non-Bengali characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = text.split()\n",
    "    if stop_words:\n",
    "        words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Upsampling to Balance Classes\n",
    "# -------------------------------\n",
    "\n",
    "def upsample(df, target_column):\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        df_label = df[df[target_column] == label]\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,\n",
    "            n_samples=max_count,\n",
    "            random_state=42\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "df_upsampled = upsample(df, 'Category')\n",
    "\n",
    "# Encode labels\n",
    "category_encoder = LabelEncoder()\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Category'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Tokenization using BERT\n",
    "# -------------------------------\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            list(batch),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data\n",
    "input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Create window-based adjacency matrices\n",
    "def window_based_adjacency(sentences, window_size=2, max_len=20):\n",
    "    adjacency_matrices = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()[:max_len]\n",
    "        num_tokens = len(tokens)\n",
    "        adj = np.zeros((max_len, max_len), dtype=np.float32)\n",
    "        for i in range(num_tokens):\n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, num_tokens)):\n",
    "                if i != j:\n",
    "                    adj[i, j] = 1.0\n",
    "        adjacency_matrices.append(adj)\n",
    "    return np.array(adjacency_matrices, dtype=np.float32)\n",
    "\n",
    "adjacency_matrices = window_based_adjacency(df_upsampled['Text'].values, window_size=2, max_len=20)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Data Splitting\n",
    "# -------------------------------\n",
    "\n",
    "# Split the data\n",
    "X_train_ids, X_test_ids, X_train_masks, X_test_masks, adjacency_train, adjacency_test, y_train_category, y_test_category = train_test_split(\n",
    "    input_ids, attention_masks, adjacency_matrices,  df_upsampled['Category_encoded'].values,\n",
    "    test_size=0.2, random_state=42, stratify=df_upsampled['Category_encoded'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  177853440   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " adjacency (InputLayer)         [(None, 20, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " gnn_context_resonance_2 (GNNCo  ((None, 20, 768),   1790977     ['tf_bert_model_2[0][0]',        \n",
      " ntextResonance)                 (None, 20, 1))                   'adjacency[0][0]']              \n",
      "                                                                                                  \n",
      " custom_multi_head_attention_4   ((None, 20, 768),   1769472     ['gnn_context_resonance_2[0][0]',\n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_2[0][0]',\n",
      "                                                                  'gnn_context_resonance_2[0][0]']\n",
      "                                                                                                  \n",
      " custom_multi_head_attention_5   ((None, 20, 768),   1769472     ['tf_bert_model_2[0][0]',        \n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_2[0][0]',\n",
      "                                                                  'gnn_context_resonance_2[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 20, 1536)     0           ['custom_multi_head_attention_4[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'custom_multi_head_attention_5[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 20, 160)      245920      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 20, 10, 16)   0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " primary_caps_squash (Lambda)   (None, 20, 10, 16)   0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3200)         0           ['primary_caps_squash[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 3200)         0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " category_output (Dense)        (None, 5)            16005       ['dropout_116[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 183,445,286\n",
      "Trainable params: 183,445,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Concatenate, Embedding, Flatten, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers import GATConv\n",
    "from transformers import TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "# Squash function for Capsule Networks\n",
    "def squash(vectors):\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=-1, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm)\n",
    "    unit_vectors = vectors / tf.sqrt(s_squared_norm + 1e-9)\n",
    "    return scale * unit_vectors\n",
    "\n",
    "# Custom Multi-Head Attention Layer\n",
    "class CustomMultiHeadAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim, max_len, **kwargs):\n",
    "        super(CustomMultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.depth = key_dim // num_heads\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list) and len(input_shape) == 3:\n",
    "            q_shape, k_shape, v_shape = input_shape\n",
    "        else:\n",
    "            q_shape = input_shape\n",
    "            k_shape = input_shape\n",
    "            v_shape = input_shape\n",
    "        self.wq = self.add_weight(shape=(q_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wk = self.add_weight(shape=(k_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wv = self.add_weight(shape=(v_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        super(CustomMultiHeadAttention, self).build(input_shape)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.reshape(x, (batch_size, self.max_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list) and len(inputs) == 3:\n",
    "            q, k, v = inputs\n",
    "        else:\n",
    "            q = inputs\n",
    "            k = inputs\n",
    "            v = inputs\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = tf.matmul(q, self.wq)\n",
    "        k = tf.matmul(k, self.wk)\n",
    "        v = tf.matmul(v, self.wv)\n",
    "\n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(self.depth, tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(output, (batch_size, self.max_len, self.key_dim))\n",
    "\n",
    "        # Set shapes for Keras\n",
    "        concat_attention.set_shape((None, self.max_len, self.key_dim))\n",
    "        attention_weights.set_shape((None, self.num_heads, self.max_len, self.max_len))\n",
    "\n",
    "        return concat_attention, attention_weights\n",
    "\n",
    "# GNNContextResonance Layer\n",
    "class GNNContextResonance(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads=8, max_len=20, dropout_rate=0.2, **kwargs):\n",
    "        super(GNNContextResonance, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.position_embedding = Embedding(input_dim=max_len, output_dim=hidden_size)\n",
    "\n",
    "        # Multi-Head GAT Layers\n",
    "        self.gat_layers = [GATConv(hidden_size // num_heads, activation='elu') for _ in range(num_heads)]\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        self.transform_gate = Dense(hidden_size, activation='sigmoid')\n",
    "        self.carry_gate = Dense(hidden_size, activation='sigmoid')\n",
    "\n",
    "        # Dropout and Layer Norm\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dense layer for resonance scores\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, adjacency, edge_features=None, training=False):\n",
    "        position_indices = tf.range(self.max_len)[tf.newaxis, :]\n",
    "        position_embeddings = self.position_embedding(position_indices)\n",
    "        inputs = inputs + position_embeddings\n",
    "\n",
    "        gat_outputs = []\n",
    "        for gat_layer in self.gat_layers:\n",
    "            x = gat_layer([inputs, adjacency])\n",
    "            gat_outputs.append(x)\n",
    "        x = self.concat(gat_outputs)\n",
    "\n",
    "        # Residual Connection\n",
    "        x = x + inputs\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        transform = self.transform_gate(x)\n",
    "        carry = self.carry_gate(inputs)\n",
    "        outputs = transform * x + (1 - transform) * carry\n",
    "\n",
    "        # Apply dropout and layer normalization\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        outputs = self.layer_norm(outputs)\n",
    "\n",
    "        resonance_scores = self.dense(outputs)\n",
    "\n",
    "        return outputs, resonance_scores\n",
    "\n",
    "# Building the Model with BERT and GNN for Single Task (Category)\n",
    "def build_model_with_gnn(bert_model, hidden_size, max_len=20):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_masks = Input(shape=(max_len,), dtype=tf.int32, name='attention_masks')\n",
    "    adjacency = Input(shape=(max_len, max_len), dtype=tf.float32, name='adjacency')\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    bert_outputs = bert_model([input_ids, attention_masks])\n",
    "    sequence_output = bert_outputs.last_hidden_state  # BERT output\n",
    "\n",
    "    # Apply GNN-Based Context Resonance\n",
    "    gnn_resonance_layer = GNNContextResonance(hidden_size, num_heads=8, max_len=max_len)\n",
    "    gnn_output, resonance_scores = gnn_resonance_layer(sequence_output, adjacency)\n",
    "\n",
    "    # Implement Dual Attention Mechanism (Self-attention and Cross-attention)\n",
    "    self_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    self_attention_output, self_attention_scores = self_attention_layer([gnn_output, gnn_output, gnn_output])\n",
    "\n",
    "    cross_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    cross_attention_output, cross_attention_scores = cross_attention_layer([sequence_output, gnn_output, gnn_output])\n",
    "\n",
    "    # Combine outputs\n",
    "    combined_output = Concatenate(axis=-1)([self_attention_output, cross_attention_output])\n",
    "\n",
    "    # Capsule Networks Layer\n",
    "    caps_num_capsules = 10  # Number of capsules\n",
    "    caps_dim_capsules = 16  # Dimension of each capsule\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Conv1D(\n",
    "        filters=caps_num_capsules * caps_dim_capsules,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid'\n",
    "    )(combined_output)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Reshape(\n",
    "        target_shape=(max_len, caps_num_capsules, caps_dim_capsules)\n",
    "    )(primary_capsules)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Lambda(squash, name='primary_caps_squash')(primary_capsules)\n",
    "\n",
    "    flat_capsules = Flatten()(primary_capsules)\n",
    "\n",
    "    dropout = Dropout(0.3)(flat_capsules)\n",
    "\n",
    "    # Category Output\n",
    "    category_output = Dense(len(category_encoder.classes_), activation='softmax', name='category_output')(dropout)\n",
    "\n",
    "    # Model will only output Category and resonance scores\n",
    "    model = Model(\n",
    "        inputs=[input_ids, attention_masks, adjacency],\n",
    "        outputs=[category_output, resonance_scores]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load pre-trained multilingual BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "hidden_size = bert_model.config.hidden_size  # Typically 768\n",
    "\n",
    "# Build the model\n",
    "model = build_model_with_gnn(bert_model, hidden_size, max_len=20)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 147\u001b[0m\n\u001b[0;32m    144\u001b[0m labels_category \u001b[38;5;241m=\u001b[39m batch_labels_category\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Unpack only 3 values, since the train_step now returns 3 values\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m total_loss, cce_loss_cat, smoothness_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_category\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m total_loss_avg\u001b[38;5;241m.\u001b[39mupdate_state(total_loss)\n\u001b[0;32m    151\u001b[0m cce_loss_category_avg\u001b[38;5;241m.\u001b[39mupdate_state(cce_loss_cat)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file__o_rfye.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(input_ids, attention_masks, adjacency, labels_category)\u001b[0m\n\u001b[0;32m     19\u001b[0m     smoothness_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mld(smoothness_loss),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     20\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mld(cce_loss_category),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(smoothness_loss)\n\u001b[1;32m---> 21\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(optimizer)\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     23\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(train_accuracy_category)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(labels_category), ag__\u001b[38;5;241m.\u001b[39mld(predictions_category)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:801\u001b[0m, in \u001b[0;36m_ReshapeGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;129m@ops\u001b[39m\u001b[38;5;241m.\u001b[39mRegisterGradient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ReshapeGrad\u001b[39m(op, grad):\n\u001b[0;32m    800\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 801\u001b[0m       \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m          \u001b[49m\u001b[43m_IndexedSlicesToTensorNoWarning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    803\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    804\u001b[0m   ]\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:199\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     64\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m   tensor_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8550\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8548\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   8549\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 8550\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8551\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8552\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   8553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3801\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3802\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3807\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3809\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_c_op(c_op\u001b[38;5;241m=\u001b[39mc_op, g\u001b[38;5;241m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mf:\\Mini Conda\\envs\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Defining Custom Loss Functions and Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "\n",
    "# Define the standard loss function for category classification without class weights\n",
    "loss_fn_category = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "# Define metrics\n",
    "train_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_category')\n",
    "val_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy_category')\n",
    "\n",
    "# Define the supervised contrastive loss function\n",
    "def supervised_contrastive_loss(labels, features, temperature=0.1):\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    label_mask = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    features = tf.math.l2_normalize(features, axis=1)\n",
    "    similarity_matrix = tf.matmul(features, features, transpose_b=True) / temperature\n",
    "    logits_max = tf.reduce_max(similarity_matrix, axis=1, keepdims=True)\n",
    "    logits = similarity_matrix - logits_max\n",
    "    exp_logits = tf.exp(logits) * tf.cast(label_mask, tf.float32)\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True) + 1e-8)\n",
    "    mean_log_prob_pos = tf.reduce_sum(log_prob * tf.cast(label_mask, tf.float32), axis=1) / tf.reduce_sum(tf.cast(label_mask, tf.float32), axis=1)\n",
    "    loss = -tf.reduce_mean(mean_log_prob_pos)\n",
    "    return loss\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Custom Training Loop\n",
    "# -------------------------------\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = model([input_ids, attention_masks, adjacency], training=True)\n",
    "        predictions_category = predictions[0]\n",
    "        resonance_scores = predictions[1]  # Resonance scores (if needed for other tasks)\n",
    "\n",
    "        # Compute per-sample standard loss for category\n",
    "        cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "        # Compute smoothness loss (if required by your architecture)\n",
    "        resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)  # (batch_size, seq_length)\n",
    "        resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "        squared_diff = tf.square(resonance_diff)\n",
    "        smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])  # (batch_size,)\n",
    "        smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "        # Remove contrastive loss (since features aren't being returned)\n",
    "        total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    # Forward pass\n",
    "    predictions = model([input_ids, attention_masks, adjacency], training=False)\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    # Compute per-sample standard loss for category\n",
    "    cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "    # Compute smoothness loss (if required by your architecture)\n",
    "    resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)\n",
    "    resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "    squared_diff = tf.square(resonance_diff)\n",
    "    smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])\n",
    "    smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "    # Remove contrastive loss (since features aren't being returned)\n",
    "    total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Update metrics\n",
    "    val_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training the Model\n",
    "# -------------------------------\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_train_ids,\n",
    "    'attention_masks': X_train_masks,\n",
    "    'adjacency': adjacency_train\n",
    "}, y_train_category)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_test_ids,\n",
    "    'attention_masks': X_test_masks,\n",
    "    'adjacency': adjacency_test\n",
    "}, y_test_category)).batch(batch_size)\n",
    "\n",
    "# Initialize history dictionaries\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_cce_loss_category': [],\n",
    "    'train_smoothness_loss': [],\n",
    "    'train_accuracy_category': [],\n",
    "    'val_loss': [],\n",
    "    'val_cce_loss_category': [],\n",
    "    'val_smoothness_loss': [],\n",
    "    'val_accuracy_category': [],\n",
    "    'epoch_time': []  # Added to record time per epoch\n",
    "}\n",
    "\n",
    "# Start time of training\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch + 1}\")\n",
    "    epoch_start_time = time.time()  # Record start time of the epoch\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_accuracy_category.reset_states()\n",
    "    val_accuracy_category.reset_states()\n",
    "\n",
    "    # Training\n",
    "    total_loss_avg = tf.keras.metrics.Mean()\n",
    "    cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for step, (batch_inputs, batch_labels_category) in enumerate(train_dataset):\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the train_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = train_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        total_loss_avg.update_state(total_loss)\n",
    "        cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        smoothness_loss_avg.update_state(smoothness_loss)\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Total Loss = {total_loss_avg.result():.4f}, \"\n",
    "                  f\"CCE Loss Category = {cce_loss_category_avg.result():.4f}, \"\n",
    "                  f\"Smoothness Loss = {smoothness_loss_avg.result():.4f}, \"\n",
    "                  f\"Train Accuracy Category = {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Record training metrics\n",
    "    history['train_loss'].append(total_loss_avg.result().numpy())\n",
    "    history['train_cce_loss_category'].append(cce_loss_category_avg.result().numpy())\n",
    "    history['train_smoothness_loss'].append(smoothness_loss_avg.result().numpy())\n",
    "    history['train_accuracy_category'].append(train_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training CCE Loss Category: {cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Smoothness Loss: {smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Accuracy Category: {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss_avg = tf.keras.metrics.Mean()\n",
    "    val_cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    val_smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for batch_inputs, batch_labels_category in test_dataset:\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the test_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = test_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        val_loss_avg.update_state(total_loss)\n",
    "        val_cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        val_smoothness_loss_avg.update_state(smoothness_loss)\n",
    "\n",
    "    # Record validation metrics\n",
    "    history['val_loss'].append(val_loss_avg.result().numpy())\n",
    "    history['val_cce_loss_category'].append(val_cce_loss_category_avg.result().numpy())\n",
    "    history['val_smoothness_loss'].append(val_smoothness_loss_avg.result().numpy())\n",
    "    history['val_accuracy_category'].append(val_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {val_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation CCE Loss Category: {val_cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Smoothness Loss: {val_smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Accuracy Category: {val_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    history['epoch_time'].append(epoch_duration)\n",
    "    print(f\"Epoch {epoch+1} Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "# Total training time\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "print(f\"\\nTotal Training Time: {total_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compute_macro_precision(y_true, y_pred, num_classes):\n",
    "    # Calculate precision for each class\n",
    "    precision_per_class = tf.keras.metrics.Precision(class_id=None, num_classes=num_classes)\n",
    "    precision_per_class.update_state(y_true, y_pred)\n",
    "    precision = precision_per_class.result().numpy()\n",
    "    return precision\n",
    "\n",
    "def compute_macro_recall(y_true, y_pred, num_classes):\n",
    "    # Calculate recall for each class\n",
    "    recall_per_class = tf.keras.metrics.Recall(class_id=None, num_classes=num_classes)\n",
    "    recall_per_class.update_state(y_true, y_pred)\n",
    "    recall = recall_per_class.result().numpy()\n",
    "    return recall\n",
    "\n",
    "def compute_macro_f1(y_true, y_pred, num_classes):\n",
    "    # Calculate F1 score for each class\n",
    "    precision = compute_macro_precision(y_true, y_pred, num_classes)\n",
    "    recall = compute_macro_recall(y_true, y_pred, num_classes)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Test Accuracy (Category): 0.8218\n",
      "Test Macro F1 Score (Category): 0.8201\n",
      "Test Macro Precision (Category): 0.8237\n",
      "Test Macro Recall (Category): 0.8218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 6. Evaluation and Visualization\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on the test set\n",
    "all_predictions_category = []\n",
    "all_labels_category = []\n",
    "all_resonance_scores = []\n",
    "\n",
    "for batch_inputs, batch_labels_category in test_dataset:\n",
    "    input_ids = batch_inputs['input_ids']\n",
    "    attention_masks = batch_inputs['attention_masks']\n",
    "    adjacency = batch_inputs['adjacency']\n",
    "\n",
    "    predictions = model.predict([input_ids, attention_masks, adjacency])\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    predicted_labels_category = np.argmax(predictions_category, axis=1)\n",
    "\n",
    "    all_predictions_category.extend(predicted_labels_category)\n",
    "    all_labels_category.extend(batch_labels_category.numpy())\n",
    "    all_resonance_scores.extend(resonance_scores)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels_category = np.array(all_labels_category)\n",
    "all_predictions_category = np.array(all_predictions_category)\n",
    "\n",
    "# Calculate metrics for Category\n",
    "accuracy_category = accuracy_score(all_labels_category, all_predictions_category)\n",
    "f1_category = f1_score(all_labels_category, all_predictions_category, average='macro')\n",
    "precision_category = precision_score(all_labels_category, all_predictions_category, average='macro')\n",
    "recall_category = recall_score(all_labels_category, all_predictions_category, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy (Category): {accuracy_category:.4f}\")\n",
    "print(f\"Test Macro F1 Score (Category): {f1_category:.4f}\")\n",
    "print(f\"Test Macro Precision (Category): {precision_category:.4f}\")\n",
    "print(f\"Test Macro Recall (Category): {recall_category:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Category\n",
    "plt.figure(figsize=(4, 4))\n",
    "cm_category = confusion_matrix(all_labels_category, all_predictions_category)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_category, display_labels=category_encoder.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=90)\n",
    "plt.title('Confusion Matrix - Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                                Text  Polarity\n",
      "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...  positive\n",
      "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...  positive\n",
      "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?  positive\n",
      "3                              সৌম্যকে বাদ দেওয়া হোক  negative\n",
      "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...  positive\n",
      "Initial Data Shape: (2979, 2)\n",
      "DataFrame after text cleaning:\n",
      "                                                Text  Polarity\n",
      "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...  positive\n",
      "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...  positive\n",
      "2                           বাংলাদেশের ভারতের সাপর্ট  positive\n",
      "3                                        সৌম্যকে বাদ  negative\n",
      "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে  positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Tokenizing: 100%|██████████| 202/202 [00:01<00:00, 134.46it/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_3 (TFBertModel)  TFBaseModelOutputWi  177853440   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 20,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " adjacency (InputLayer)         [(None, 20, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " gnn_context_resonance_3 (GNNCo  ((None, 20, 768),   1790977     ['tf_bert_model_3[0][0]',        \n",
      " ntextResonance)                 (None, 20, 1))                   'adjacency[0][0]']              \n",
      "                                                                                                  \n",
      " custom_multi_head_attention_6   ((None, 20, 768),   1769472     ['gnn_context_resonance_3[0][0]',\n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_3[0][0]',\n",
      "                                                                  'gnn_context_resonance_3[0][0]']\n",
      "                                                                                                  \n",
      " custom_multi_head_attention_7   ((None, 20, 768),   1769472     ['tf_bert_model_3[0][0]',        \n",
      " (CustomMultiHeadAttention)      (None, 8, 20, 20))               'gnn_context_resonance_3[0][0]',\n",
      "                                                                  'gnn_context_resonance_3[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 20, 1536)     0           ['custom_multi_head_attention_6[0\n",
      "                                                                 ][0]',                           \n",
      "                                                                  'custom_multi_head_attention_7[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 20, 160)      245920      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 20, 10, 16)   0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " primary_caps_squash (Lambda)   (None, 20, 10, 16)   0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 3200)         0           ['primary_caps_squash[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 3200)         0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " category_output (Dense)        (None, 3)            9603        ['dropout_155[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 183,438,884\n",
      "Trainable params: 183,438,884\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Start of epoch 1\n",
      "Step 0: Total Loss = 2.7641, CCE Loss Category = 1.2211, Smoothness Loss = 1.5430, Train Accuracy Category = 0.1875\n",
      "Step 100: Total Loss = 1.1391, CCE Loss Category = 1.1182, Smoothness Loss = 0.0210, Train Accuracy Category = 0.3694\n",
      "Step 200: Total Loss = 1.0913, CCE Loss Category = 1.0807, Smoothness Loss = 0.0105, Train Accuracy Category = 0.4126\n",
      "Step 300: Total Loss = 1.0227, CCE Loss Category = 1.0156, Smoothness Loss = 0.0071, Train Accuracy Category = 0.4732\n",
      "Epoch 1 Training Loss: 1.0046\n",
      "Epoch 1 Training CCE Loss Category: 0.9982\n",
      "Epoch 1 Training Smoothness Loss: 0.0066\n",
      "Epoch 1 Training Accuracy Category: 0.4882\n",
      "Epoch 1 Validation Loss: 0.5620\n",
      "Epoch 1 Validation CCE Loss Category: 0.5613\n",
      "Epoch 1 Validation Smoothness Loss: 0.0000\n",
      "Epoch 1 Validation Accuracy Category: 0.7817\n",
      "Epoch 1 Duration: 62.02 seconds\n",
      "\n",
      "Start of epoch 2\n",
      "Step 0: Total Loss = 0.7947, CCE Loss Category = 0.7940, Smoothness Loss = 0.0007, Train Accuracy Category = 0.6875\n",
      "Step 100: Total Loss = 0.5208, CCE Loss Category = 0.5203, Smoothness Loss = 0.0005, Train Accuracy Category = 0.8032\n",
      "Step 200: Total Loss = 0.4781, CCE Loss Category = 0.4777, Smoothness Loss = 0.0004, Train Accuracy Category = 0.8240\n",
      "Step 300: Total Loss = 0.4392, CCE Loss Category = 0.4388, Smoothness Loss = 0.0003, Train Accuracy Category = 0.8393\n",
      "Epoch 2 Training Loss: 0.4307\n",
      "Epoch 2 Training CCE Loss Category: 0.4304\n",
      "Epoch 2 Training Smoothness Loss: 0.0003\n",
      "Epoch 2 Training Accuracy Category: 0.8424\n",
      "Epoch 2 Validation Loss: 0.2525\n",
      "Epoch 2 Validation CCE Loss Category: 0.2520\n",
      "Epoch 2 Validation Smoothness Loss: 0.0000\n",
      "Epoch 2 Validation Accuracy Category: 0.9187\n",
      "Epoch 2 Duration: 39.96 seconds\n",
      "\n",
      "Start of epoch 3\n",
      "Step 0: Total Loss = 0.1014, CCE Loss Category = 0.1013, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.2233, CCE Loss Category = 0.2230, Smoothness Loss = 0.0002, Train Accuracy Category = 0.9301\n",
      "Step 200: Total Loss = 0.2274, CCE Loss Category = 0.2273, Smoothness Loss = 0.0002, Train Accuracy Category = 0.9275\n",
      "Step 300: Total Loss = 0.2218, CCE Loss Category = 0.2217, Smoothness Loss = 0.0002, Train Accuracy Category = 0.9284\n",
      "Epoch 3 Training Loss: 0.2187\n",
      "Epoch 3 Training CCE Loss Category: 0.2187\n",
      "Epoch 3 Training Smoothness Loss: 0.0001\n",
      "Epoch 3 Training Accuracy Category: 0.9299\n",
      "Epoch 3 Validation Loss: 0.2326\n",
      "Epoch 3 Validation CCE Loss Category: 0.2328\n",
      "Epoch 3 Validation Smoothness Loss: 0.0000\n",
      "Epoch 3 Validation Accuracy Category: 0.9296\n",
      "Epoch 3 Duration: 39.94 seconds\n",
      "\n",
      "Start of epoch 4\n",
      "Step 0: Total Loss = 0.0279, CCE Loss Category = 0.0277, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1239, CCE Loss Category = 0.1237, Smoothness Loss = 0.0002, Train Accuracy Category = 0.9561\n",
      "Step 200: Total Loss = 0.1320, CCE Loss Category = 0.1319, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9565\n",
      "Step 300: Total Loss = 0.1309, CCE Loss Category = 0.1308, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9576\n",
      "Epoch 4 Training Loss: 0.1331\n",
      "Epoch 4 Training CCE Loss Category: 0.1328\n",
      "Epoch 4 Training Smoothness Loss: 0.0001\n",
      "Epoch 4 Training Accuracy Category: 0.9564\n",
      "Epoch 4 Validation Loss: 0.2366\n",
      "Epoch 4 Validation CCE Loss Category: 0.2359\n",
      "Epoch 4 Validation Smoothness Loss: 0.0000\n",
      "Epoch 4 Validation Accuracy Category: 0.9311\n",
      "Epoch 4 Duration: 39.86 seconds\n",
      "\n",
      "Start of epoch 5\n",
      "Step 0: Total Loss = 0.0388, CCE Loss Category = 0.0387, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.1118, CCE Loss Category = 0.1117, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9684\n",
      "Step 200: Total Loss = 0.1139, CCE Loss Category = 0.1139, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9652\n",
      "Step 300: Total Loss = 0.1180, CCE Loss Category = 0.1180, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9630\n",
      "Epoch 5 Training Loss: 0.1187\n",
      "Epoch 5 Training CCE Loss Category: 0.1187\n",
      "Epoch 5 Training Smoothness Loss: 0.0001\n",
      "Epoch 5 Training Accuracy Category: 0.9626\n",
      "Epoch 5 Validation Loss: 0.2716\n",
      "Epoch 5 Validation CCE Loss Category: 0.2710\n",
      "Epoch 5 Validation Smoothness Loss: 0.0000\n",
      "Epoch 5 Validation Accuracy Category: 0.9342\n",
      "Epoch 5 Duration: 39.78 seconds\n",
      "\n",
      "Start of epoch 6\n",
      "Step 0: Total Loss = 0.3458, CCE Loss Category = 0.3457, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.1082, CCE Loss Category = 0.1082, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9610\n",
      "Step 200: Total Loss = 0.1077, CCE Loss Category = 0.1077, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9608\n",
      "Step 300: Total Loss = 0.1028, CCE Loss Category = 0.1027, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9641\n",
      "Epoch 6 Training Loss: 0.1010\n",
      "Epoch 6 Training CCE Loss Category: 0.1009\n",
      "Epoch 6 Training Smoothness Loss: 0.0001\n",
      "Epoch 6 Training Accuracy Category: 0.9646\n",
      "Epoch 6 Validation Loss: 0.2221\n",
      "Epoch 6 Validation CCE Loss Category: 0.2218\n",
      "Epoch 6 Validation Smoothness Loss: 0.0000\n",
      "Epoch 6 Validation Accuracy Category: 0.9327\n",
      "Epoch 6 Duration: 39.70 seconds\n",
      "\n",
      "Start of epoch 7\n",
      "Step 0: Total Loss = 0.0082, CCE Loss Category = 0.0082, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0704, CCE Loss Category = 0.0704, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9771\n",
      "Step 200: Total Loss = 0.0703, CCE Loss Category = 0.0702, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9773\n",
      "Step 300: Total Loss = 0.0704, CCE Loss Category = 0.0704, Smoothness Loss = 0.0001, Train Accuracy Category = 0.9755\n",
      "Epoch 7 Training Loss: 0.0702\n",
      "Epoch 7 Training CCE Loss Category: 0.0702\n",
      "Epoch 7 Training Smoothness Loss: 0.0001\n",
      "Epoch 7 Training Accuracy Category: 0.9758\n",
      "Epoch 7 Validation Loss: 0.1929\n",
      "Epoch 7 Validation CCE Loss Category: 0.1930\n",
      "Epoch 7 Validation Smoothness Loss: 0.0000\n",
      "Epoch 7 Validation Accuracy Category: 0.9481\n",
      "Epoch 7 Duration: 39.74 seconds\n",
      "\n",
      "Start of epoch 8\n",
      "Step 0: Total Loss = 0.0135, CCE Loss Category = 0.0134, Smoothness Loss = 0.0001, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0842, CCE Loss Category = 0.0841, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9715\n",
      "Step 200: Total Loss = 0.0776, CCE Loss Category = 0.0775, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9754\n",
      "Step 300: Total Loss = 0.0710, CCE Loss Category = 0.0709, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9772\n",
      "Epoch 8 Training Loss: 0.0702\n",
      "Epoch 8 Training CCE Loss Category: 0.0702\n",
      "Epoch 8 Training Smoothness Loss: 0.0000\n",
      "Epoch 8 Training Accuracy Category: 0.9775\n",
      "Epoch 8 Validation Loss: 0.2988\n",
      "Epoch 8 Validation CCE Loss Category: 0.2982\n",
      "Epoch 8 Validation Smoothness Loss: 0.0000\n",
      "Epoch 8 Validation Accuracy Category: 0.9350\n",
      "Epoch 8 Duration: 41.14 seconds\n",
      "\n",
      "Start of epoch 9\n",
      "Step 0: Total Loss = 0.0626, CCE Loss Category = 0.0626, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0729, CCE Loss Category = 0.0729, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9771\n",
      "Step 200: Total Loss = 0.0820, CCE Loss Category = 0.0819, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9723\n",
      "Step 300: Total Loss = 0.0870, CCE Loss Category = 0.0870, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9695\n",
      "Epoch 9 Training Loss: 0.0852\n",
      "Epoch 9 Training CCE Loss Category: 0.0853\n",
      "Epoch 9 Training Smoothness Loss: 0.0000\n",
      "Epoch 9 Training Accuracy Category: 0.9706\n",
      "Epoch 9 Validation Loss: 0.2454\n",
      "Epoch 9 Validation CCE Loss Category: 0.2447\n",
      "Epoch 9 Validation Smoothness Loss: 0.0000\n",
      "Epoch 9 Validation Accuracy Category: 0.9381\n",
      "Epoch 9 Duration: 40.66 seconds\n",
      "\n",
      "Start of epoch 10\n",
      "Step 0: Total Loss = 0.0529, CCE Loss Category = 0.0529, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0672, CCE Loss Category = 0.0672, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9771\n",
      "Step 200: Total Loss = 0.0782, CCE Loss Category = 0.0782, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9717\n",
      "Step 300: Total Loss = 0.0789, CCE Loss Category = 0.0788, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9713\n",
      "Epoch 10 Training Loss: 0.0788\n",
      "Epoch 10 Training CCE Loss Category: 0.0788\n",
      "Epoch 10 Training Smoothness Loss: 0.0000\n",
      "Epoch 10 Training Accuracy Category: 0.9713\n",
      "Epoch 10 Validation Loss: 0.2661\n",
      "Epoch 10 Validation CCE Loss Category: 0.2664\n",
      "Epoch 10 Validation Smoothness Loss: 0.0000\n",
      "Epoch 10 Validation Accuracy Category: 0.9365\n",
      "Epoch 10 Duration: 41.51 seconds\n",
      "\n",
      "Start of epoch 11\n",
      "Step 0: Total Loss = 0.0541, CCE Loss Category = 0.0541, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0561, CCE Loss Category = 0.0560, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9783\n",
      "Step 200: Total Loss = 0.0525, CCE Loss Category = 0.0525, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9789\n",
      "Step 300: Total Loss = 0.0523, CCE Loss Category = 0.0523, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9811\n",
      "Epoch 11 Training Loss: 0.0549\n",
      "Epoch 11 Training CCE Loss Category: 0.0547\n",
      "Epoch 11 Training Smoothness Loss: 0.0000\n",
      "Epoch 11 Training Accuracy Category: 0.9797\n",
      "Epoch 11 Validation Loss: 0.2537\n",
      "Epoch 11 Validation CCE Loss Category: 0.2535\n",
      "Epoch 11 Validation Smoothness Loss: 0.0000\n",
      "Epoch 11 Validation Accuracy Category: 0.9396\n",
      "Epoch 11 Duration: 40.92 seconds\n",
      "\n",
      "Start of epoch 12\n",
      "Step 0: Total Loss = 0.1009, CCE Loss Category = 0.1009, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0694, CCE Loss Category = 0.0693, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9746\n",
      "Step 200: Total Loss = 0.0765, CCE Loss Category = 0.0765, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9714\n",
      "Step 300: Total Loss = 0.0760, CCE Loss Category = 0.0760, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9722\n",
      "Epoch 12 Training Loss: 0.0787\n",
      "Epoch 12 Training CCE Loss Category: 0.0787\n",
      "Epoch 12 Training Smoothness Loss: 0.0000\n",
      "Epoch 12 Training Accuracy Category: 0.9710\n",
      "Epoch 12 Validation Loss: 0.3525\n",
      "Epoch 12 Validation CCE Loss Category: 0.3514\n",
      "Epoch 12 Validation Smoothness Loss: 0.0000\n",
      "Epoch 12 Validation Accuracy Category: 0.9071\n",
      "Epoch 12 Duration: 40.85 seconds\n",
      "\n",
      "Start of epoch 13\n",
      "Step 0: Total Loss = 0.0431, CCE Loss Category = 0.0431, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0593, CCE Loss Category = 0.0593, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9808\n",
      "Step 200: Total Loss = 0.0642, CCE Loss Category = 0.0642, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9801\n",
      "Step 300: Total Loss = 0.0710, CCE Loss Category = 0.0710, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9761\n",
      "Epoch 13 Training Loss: 0.0698\n",
      "Epoch 13 Training CCE Loss Category: 0.0697\n",
      "Epoch 13 Training Smoothness Loss: 0.0000\n",
      "Epoch 13 Training Accuracy Category: 0.9768\n",
      "Epoch 13 Validation Loss: 0.2667\n",
      "Epoch 13 Validation CCE Loss Category: 0.2658\n",
      "Epoch 13 Validation Smoothness Loss: 0.0000\n",
      "Epoch 13 Validation Accuracy Category: 0.9350\n",
      "Epoch 13 Duration: 41.34 seconds\n",
      "\n",
      "Start of epoch 14\n",
      "Step 0: Total Loss = 0.0131, CCE Loss Category = 0.0131, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0418, CCE Loss Category = 0.0418, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9845\n",
      "Step 200: Total Loss = 0.0579, CCE Loss Category = 0.0579, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9764\n",
      "Step 300: Total Loss = 0.0587, CCE Loss Category = 0.0586, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9767\n",
      "Epoch 14 Training Loss: 0.0581\n",
      "Epoch 14 Training CCE Loss Category: 0.0581\n",
      "Epoch 14 Training Smoothness Loss: 0.0000\n",
      "Epoch 14 Training Accuracy Category: 0.9764\n",
      "Epoch 14 Validation Loss: 0.3096\n",
      "Epoch 14 Validation CCE Loss Category: 0.3092\n",
      "Epoch 14 Validation Smoothness Loss: 0.0000\n",
      "Epoch 14 Validation Accuracy Category: 0.9280\n",
      "Epoch 14 Duration: 40.82 seconds\n",
      "\n",
      "Start of epoch 15\n",
      "Step 0: Total Loss = 0.1870, CCE Loss Category = 0.1870, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0471, CCE Loss Category = 0.0470, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9802\n",
      "Step 200: Total Loss = 0.0418, CCE Loss Category = 0.0418, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9829\n",
      "Step 300: Total Loss = 0.0507, CCE Loss Category = 0.0506, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9797\n",
      "Epoch 15 Training Loss: 0.0523\n",
      "Epoch 15 Training CCE Loss Category: 0.0524\n",
      "Epoch 15 Training Smoothness Loss: 0.0000\n",
      "Epoch 15 Training Accuracy Category: 0.9793\n",
      "Epoch 15 Validation Loss: 0.2227\n",
      "Epoch 15 Validation CCE Loss Category: 0.2232\n",
      "Epoch 15 Validation Smoothness Loss: 0.0000\n",
      "Epoch 15 Validation Accuracy Category: 0.9466\n",
      "Epoch 15 Duration: 40.92 seconds\n",
      "\n",
      "Start of epoch 16\n",
      "Step 0: Total Loss = 0.0311, CCE Loss Category = 0.0311, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0376, CCE Loss Category = 0.0376, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9870\n",
      "Step 200: Total Loss = 0.0433, CCE Loss Category = 0.0433, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9854\n",
      "Step 300: Total Loss = 0.0451, CCE Loss Category = 0.0451, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9838\n",
      "Epoch 16 Training Loss: 0.0486\n",
      "Epoch 16 Training CCE Loss Category: 0.0486\n",
      "Epoch 16 Training Smoothness Loss: 0.0000\n",
      "Epoch 16 Training Accuracy Category: 0.9826\n",
      "Epoch 16 Validation Loss: 0.2517\n",
      "Epoch 16 Validation CCE Loss Category: 0.2522\n",
      "Epoch 16 Validation Smoothness Loss: 0.0000\n",
      "Epoch 16 Validation Accuracy Category: 0.9427\n",
      "Epoch 16 Duration: 40.89 seconds\n",
      "\n",
      "Start of epoch 17\n",
      "Step 0: Total Loss = 0.0031, CCE Loss Category = 0.0031, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0586, CCE Loss Category = 0.0586, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9777\n",
      "Step 200: Total Loss = 0.0523, CCE Loss Category = 0.0523, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9792\n",
      "Step 300: Total Loss = 0.0539, CCE Loss Category = 0.0538, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9790\n",
      "Epoch 17 Training Loss: 0.0581\n",
      "Epoch 17 Training CCE Loss Category: 0.0580\n",
      "Epoch 17 Training Smoothness Loss: 0.0000\n",
      "Epoch 17 Training Accuracy Category: 0.9783\n",
      "Epoch 17 Validation Loss: 0.3020\n",
      "Epoch 17 Validation CCE Loss Category: 0.3014\n",
      "Epoch 17 Validation Smoothness Loss: 0.0000\n",
      "Epoch 17 Validation Accuracy Category: 0.9280\n",
      "Epoch 17 Duration: 40.99 seconds\n",
      "\n",
      "Start of epoch 18\n",
      "Step 0: Total Loss = 0.0120, CCE Loss Category = 0.0120, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0780, CCE Loss Category = 0.0779, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9678\n",
      "Step 200: Total Loss = 0.0660, CCE Loss Category = 0.0659, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9739\n",
      "Step 300: Total Loss = 0.0698, CCE Loss Category = 0.0698, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9747\n",
      "Epoch 18 Training Loss: 0.0677\n",
      "Epoch 18 Training CCE Loss Category: 0.0677\n",
      "Epoch 18 Training Smoothness Loss: 0.0000\n",
      "Epoch 18 Training Accuracy Category: 0.9752\n",
      "Epoch 18 Validation Loss: 0.2723\n",
      "Epoch 18 Validation CCE Loss Category: 0.2729\n",
      "Epoch 18 Validation Smoothness Loss: 0.0000\n",
      "Epoch 18 Validation Accuracy Category: 0.9466\n",
      "Epoch 18 Duration: 40.84 seconds\n",
      "\n",
      "Start of epoch 19\n",
      "Step 0: Total Loss = 0.0025, CCE Loss Category = 0.0025, Smoothness Loss = 0.0000, Train Accuracy Category = 1.0000\n",
      "Step 100: Total Loss = 0.0607, CCE Loss Category = 0.0607, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9783\n",
      "Step 200: Total Loss = 0.0535, CCE Loss Category = 0.0534, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9782\n",
      "Step 300: Total Loss = 0.0555, CCE Loss Category = 0.0555, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9770\n",
      "Epoch 19 Training Loss: 0.0557\n",
      "Epoch 19 Training CCE Loss Category: 0.0557\n",
      "Epoch 19 Training Smoothness Loss: 0.0000\n",
      "Epoch 19 Training Accuracy Category: 0.9768\n",
      "Epoch 19 Validation Loss: 0.2844\n",
      "Epoch 19 Validation CCE Loss Category: 0.2842\n",
      "Epoch 19 Validation Smoothness Loss: 0.0000\n",
      "Epoch 19 Validation Accuracy Category: 0.9311\n",
      "Epoch 19 Duration: 40.69 seconds\n",
      "\n",
      "Start of epoch 20\n",
      "Step 0: Total Loss = 0.1216, CCE Loss Category = 0.1215, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9375\n",
      "Step 100: Total Loss = 0.0559, CCE Loss Category = 0.0559, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9783\n",
      "Step 200: Total Loss = 0.0431, CCE Loss Category = 0.0431, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9832\n",
      "Step 300: Total Loss = 0.0454, CCE Loss Category = 0.0454, Smoothness Loss = 0.0000, Train Accuracy Category = 0.9824\n",
      "Epoch 20 Training Loss: 0.0439\n",
      "Epoch 20 Training CCE Loss Category: 0.0440\n",
      "Epoch 20 Training Smoothness Loss: 0.0000\n",
      "Epoch 20 Training Accuracy Category: 0.9828\n",
      "Epoch 20 Validation Loss: 0.3436\n",
      "Epoch 20 Validation CCE Loss Category: 0.3428\n",
      "Epoch 20 Validation Smoothness Loss: 0.0000\n",
      "Epoch 20 Validation Accuracy Category: 0.9342\n",
      "Epoch 20 Duration: 40.81 seconds\n",
      "\n",
      "Total Training Time: 833.38 seconds\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Test Accuracy (Category): 0.9342\n",
      "Test Macro F1 Score (Category): 0.9332\n",
      "Test Macro Precision (Category): 0.9378\n",
      "Test Macro Recall (Category): 0.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAH0CAYAAAD1xc01AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrTElEQVR4nO3deVxUVf8H8M+wDTsCyqaAoIiiuIELVOKCC+ZeLokGiZqpGCnZY6ZiqaSZS5pLZoJb2qNhmqbiRrkjbrjkFigmhAuy75zfH/6YpxEXBgbGC593r/vKOffcM9+ZceTL2a5MCCFAREREJBFamg6AiIiISBVMXoiIiEhSmLwQERGRpDB5ISIiIklh8kJERESSwuSFiIiIJIXJCxEREUkKkxciIiKSFCYvREREJClMXkgyLl68iPfeew9OTk7Q19eHsbEx2rZtiwULFuDRo0dV+tznzp2Dj48PzMzMIJPJsGTJErU/h0wmQ1hYmNrbfZmIiAjIZDLIZDIcOXKkzHkhBBo3bgyZTIbOnTtX6DlWrFiBiIgIla45cuTIc2OqLhkZGZg7dy48PT1hamoKuVyOhg0bYtSoUTh79qzK7d27dw9hYWE4f/68+oMlqkV0NB0AUXmsWbMG48ePh6urKz7++GO4ubmhsLAQZ86cwapVq3DixAlERUVV2fOPGjUK2dnZ2LJlC8zNzdGwYUO1P8eJEyfQoEEDtbdbXiYmJli7dm2ZBCUmJga3bt2CiYlJhdtesWIF6tati8DAwHJf07ZtW5w4cQJubm4Vft7KuHXrFnr06IHU1FSMGzcOs2fPhrGxMRITE/HTTz/Bw8MDjx8/hpmZWbnbvHfvHmbPno2GDRuidevWVRc8UQ3H5IVeeSdOnMAHH3yA7t27Y8eOHZDL5Ypz3bt3x5QpU7B3794qjeHSpUsYM2YM/Pz8quw5OnbsWGVtl8fQoUOxadMmfPvttzA1NVWUr127Fl5eXsjIyKiWOAoLCyGTyWBqaqqx96S4uBgDBw7EgwcPcOLECbRo0UJxzsfHBwEBAfjtt9+gq6urkfiqQ05ODgwNDTUdBtGzCaJXXJ8+fYSOjo64c+dOueoXFxeL+fPnC1dXV6Gnpyfq1asnRo4cKZKSkpTq+fj4iObNm4vTp0+L119/XRgYGAgnJycRHh4uiouLhRBCrFu3TgAocwghxKxZs8SzvkKl1yQkJCjKDh48KHx8fISFhYXQ19cX9vb2YtCgQSI7O1tRB4CYNWuWUlvx8fGiX79+ok6dOkIul4tWrVqJiIgIpTqHDx8WAMTmzZvFp59+KmxtbYWJiYno1q2b+PPPP1/6fpXGe/DgQWFgYCBWrVqlOPf48WNhYGAg1qxZI5o3by58fHyUrg0LCxPt27cX5ubmwsTERLRp00Z8//33oqSkRFHH0dGxzPvn6OioFPv69evF5MmThZ2dnZDJZOLq1auKc4cPHxZCCHH//n3RoEED4eXlJQoKChTtX758WRgaGooRI0a89LWW17Zt2wQAER4eXq76N27cEIGBgaJx48bCwMBA2NnZiT59+oiLFy8q6pS+nqePf3/msbGxom/fvsLc3FzI5XLRunVrsXXr1jLP98cff4iOHTsKuVwu7OzsxGeffSbWrFlT5u+dqt+FmJgY4eXlJQwMDMTQoUPFqFGjhLm5udLf01JdunQRbm5u5Xp/iNSNyQu90oqKioShoaHo0KFDua8ZO3asACAmTpwo9u7dK1atWiXq1asn7O3txf379xX1fHx8hKWlpXBxcRGrVq0S0dHRYvz48QKAiIyMFEIIkZqaKk6cOCEAiLffflucOHFCnDhxQghR/uQlISFB6Ovri+7du4sdO3aII0eOiE2bNomRI0eKtLQ0xXVP/yD7888/hYmJiWjUqJFYv3692L17t3jnnXcEADF//nxFvdIfig0bNhT+/v5i9+7d4scffxQODg7CxcVFFBUVvfD9Ko03NjZWjBw5UrRv315xbuXKlcLIyEhkZGQ8M3kJDAwUa9euFdHR0SI6Olp88cUXwsDAQMyePVtR5+zZs8LZ2Vm0adNG8f6dPXtWKfb69euLt99+W+zcuVP8+uuv4uHDh2WSFyGEOHr0qNDR0REfffSREEKI7Oxs4ebmJpo2bSqysrJe+DpVUfp36OrVq+WqHxMTI6ZMmSK2bdsmYmJiRFRUlBgwYIAwMDBQJJDp6emK9/qzzz5TvBelicShQ4eEnp6eeOONN8TWrVvF3r17RWBgoAAg1q1bp3iuCxcuCH19fdGyZUuxZcsWsXPnTtG7d2/RsGHDMsmLKt8FCwsLYW9vL5YtWyYOHz4sYmJixIULFwQAsWbNGqXXe/nyZQFAfPvttxV8h4kqh8kLvdJSUlIEADFs2LBy1b969aoAIMaPH69UfurUKQFAfPrpp4oyHx8fAUCcOnVKqa6bm5vo2bOnUhkAMWHCBKWy8iYvpb/Fnz9//oWxP528DBs2TMjl8jI9Tn5+fsLQ0FA8fvxYCPG/BKB3795K9X766ScBQJFsPc+/k5fSti5duiSEEKJdu3YiMDBQCCGembz8W3FxsSgsLBSff/65sLS0VOp9ed61pc/XqVOn5577d/IihBDz588XAERUVJQICAgQBgYGSj0c6tCrVy8BQOTl5VXo+qKiIlFQUCBcXFwUiZYQT3pWnk5GSjVt2lS0adNGFBYWKpX36dNH2NraKnoDBw8eLIyMjJSSj+LiYuHm5qb0964i34WDBw+WicvHx0e0bt1aqeyDDz4QpqamIjMzs3xvCJGacbUR1SiHDx8GgDITQ9u3b49mzZrh4MGDSuU2NjZo3769UlnLli1x+/ZttcXUunVr6OnpYezYsYiMjMRff/1VrusOHTqEbt26wd7eXqk8MDAQOTk5OHHihFJ5v379lB63bNkSAFR6LT4+PmjUqBF++OEHxMfHIzY2FqNGjXphjL6+vjAzM4O2tjZ0dXUxc+ZMPHz4EKmpqeV+3rfeeqvcdT/++GO8+eabeOeddxAZGYlly5bB3d39pdcVFRUpHUKIcj9nedqeN28e3NzcoKenBx0dHejp6eHGjRu4evXqS6+/efMm/vzzT/j7+5eJtXfv3khOTsa1a9cAPJlA3bVrV9StW1dxvZaWFoYMGaLUpqrfBXNzc3Tt2rVMbB9++CHOnz+PY8eOAXiyAmvDhg0ICAiAsbHxS18bUVVg8kKvtLp168LQ0BAJCQnlqv/w4UMAgK2tbZlzdnZ2ivOlLC0ty9STy+XIzc2tQLTP1qhRIxw4cABWVlaYMGECGjVqhEaNGmHp0qUvvO7hw4fPfR2l5//t6ddSOrFZldcik8nw3nvvYePGjVi1ahWaNGmCN95445l1T58+jR49egB4shrs2LFjiI2NxfTp01V+3me9zhfFGBgYiLy8PNjY2GDkyJEvvSYxMRG6urpKR0xMzHPrOzg4AEC5/95NnjwZM2bMwIABA7Br1y6cOnUKsbGxaNWqVbneh3/++QcAEBoaWibO8ePHAwAePHgA4Mnnbm1tXaaNp8tU/S487zPo378/GjZsiG+//RbAk6X12dnZmDBhwktfF1FVYfJCrzRtbW1069YNcXFxuHv37kvrl/4AT05OLnPu3r17Sr+tVpa+vj4AID8/X6m89IfMv73xxhvYtWsX0tPTcfLkSXh5eSEkJARbtmx5bvuWlpbPfR0A1Ppa/i0wMBAPHjzAqlWr8N577z233pYtW6Crq4tff/0VQ4YMgbe3Nzw9PSv0nDKZrNx1k5OTMWHCBLRu3RoPHz5EaGjoS6+xs7NDbGys0uHh4fHc+j179gQA7Nixo1wxbdy4Ee+++y7mzZuHnj17on379vD09Hzm34VnKf0sp02bVibO0qN0abWlpaUi2fm3lJQUpceqfhee9xloaWlhwoQJ2LZtG5KTk7FixQp069YNrq6u5XptRFWByQu98qZNmwYhBMaMGYOCgoIy5wsLC7Fr1y4AUHR7b9y4UalObGwsrl69im7duqktrtK9Xi5evKhUXhrLs2hra6NDhw6K32JftNFZt27dcOjQIUWyUmr9+vUwNDSssmXE9evXx8cff4y+ffsiICDgufVkMhl0dHSgra2tKMvNzcWGDRvK1FVXb1ZxcTHeeecdyGQy/PbbbwgPD8eyZcvw888/v/A6PT09eHp6Kh0v2remf//+cHd3R3h4OC5duvTMOvv27UNOTg6AJ+/Fv5fwA8Du3bvx999/K5U9rzfM1dUVLi4uuHDhQpk4n47Xx8cHhw4dUkqMSkpK8N///lepTXV+F0aPHg09PT34+/vj2rVrmDhxYrmvJaoK3OeFXnleXl5YuXIlxo8fDw8PD3zwwQdo3rw5CgsLce7cOXz33Xdo0aIF+vbtC1dXV4wdOxbLli2DlpYW/Pz8kJiYiBkzZsDe3h4fffSR2uLq3bs3LCwsEBQUhM8//xw6OjqIiIhAUlKSUr1Vq1bh0KFDePPNN+Hg4IC8vDz88MMPAABfX9/ntj9r1iz8+uuv6NKlC2bOnAkLCwts2rQJu3fvxoIFC1TaHE1VX3755UvrvPnmm1i0aBGGDx+OsWPH4uHDh1i4cGGZH+IA4O7uji1btmDr1q1wdnaGvr5+ueapPG3WrFn4448/sH//ftjY2GDKlCmIiYlBUFAQ2rRpAycnJ5XbfBZtbW1ERUWhR48e8PLywgcffIAuXbrAyMgIt2/fxrZt27Br1y6kpaUBAPr06YOIiAg0bdoULVu2RFxcHL766qsymw42atQIBgYG2LRpE5o1awZjY2PY2dnBzs4Oq1evhp+fH3r27InAwEDUr18fjx49wtWrV3H27FlFcjJ9+nTs2rUL3bp1w/Tp02FgYIBVq1YhOzsbwJOeEgBq/S7UqVMH7777LlauXAlHR0f07dtXHW8zUcVpesYwUXmdP39eBAQECAcHB6GnpyeMjIxEmzZtxMyZM0VqaqqiXuneFk2aNBG6urqibt26YsSIEc/d2+JpAQEBin1ISuEZq42EEOL06dPC29tbGBkZifr164tZs2aJ77//XmnVx4kTJ8TAgQOFo6OjkMvlwtLSUvj4+IidO3eWeY5n7fPSt29fYWZmJvT09ESrVq3KrFQpXZXz3//+V6k8ISHhuStb/u3fq41e5Fkrhn744Qfh6uoq5HK5cHZ2FuHh4WLt2rVlluwmJiaKHj16CBMTk2fu8/J07P8+V7raaP/+/UJLS6vMe/Tw4UPh4OAg2rVrJ/Lz81/4GlT1+PFj8cUXX4i2bdsKY2NjoaurKxwcHMSIESPEsWPHFPXS0tJEUFCQsLKyEoaGhuL1118Xf/zxh/Dx8Snznv3444+iadOmQldXt8xnfuHCBTFkyBBhZWUldHV1hY2NjejatavS3jtCPNnnpUOHDkIulwsbGxvx8ccfK1Zhla5CE6Ly34V/O3LkiAAgvvzySxXfRSL1kwmhxin3RESkET169EBiYiKuX79eJe1PmTIFK1euRFJS0jMnuhNVJw4bERFJzOTJk9GmTRvY29vj0aNH2LRpE6Kjo7F27Vq1P9fJkydx/fp1rFixAu+//z4TF3olMHkhIpKY4uJizJw5EykpKZDJZHBzc8OGDRswYsQItT+Xl5cXDA0N0adPH8yZM0ft7RNVBIeNiIiISFK4VJqIiIgkhckLERERSQqTFyIiIpIUTth9hZSUlODevXswMTFRabt0IiJ6NQghkJmZCTs7O8WGgVUhLy/vmTuOq0pPT09xqxMpYfLyCrl3716ZOwgTEZH0JCUlldlhWV3y8vJgYGIJFOVUui0bGxskJCRILoFh8vIKKb13icmApZDpGmg4GqpqZ74eqOkQiEjNsjIz0ba58wvvnVVZBQUFQFEO5G4BgLZexRsqLkDKlUgUFBQweaGKKx0qkukaMHmpBUxMTTUdAhFVkWoZ+tfRh6wSyYuQSXfaK5MXIiIiKZIBqEySJOGpldJNu4iIiKhWYs8LERGRFMm0nhyVuV6imLwQERFJkUxWyWEj6Y4bMXkhIiKSolrc8yLdyImIiKhWYs8LERGRFHHYiIiIiKSlksNGEh58kW7kREREVCux54WIiEiKOGxEREREksLVRkRERETSwJ4XIiIiKeKwEREREUkKh42IiIiIpIE9L0RERFLEYSMiIiKSlFo8bMTkhYiISIpkskomL9LteZFu2kVERES1EpMXIiIiKdKSVf6ooPDwcMhkMoSEhCjKhBAICwuDnZ0dDAwM0LlzZ1y+fFnpuvz8fAQHB6Nu3bowMjJCv379cPfuXdVfeoUjJyIiIs0pnfNSmaMCYmNj8d1336Fly5ZK5QsWLMCiRYuwfPlyxMbGwsbGBt27d0dmZqaiTkhICKKiorBlyxYcPXoUWVlZ6NOnD4qLi1WKgckLERERlUtWVhb8/f2xZs0amJubK8qFEFiyZAmmT5+OQYMGoUWLFoiMjEROTg42b94MAEhPT8fatWvx9ddfw9fXF23atMHGjRsRHx+PAwcOqBQHkxciIiIpKl0qXZlDRRMmTMCbb74JX19fpfKEhASkpKSgR48eijK5XA4fHx8cP34cABAXF4fCwkKlOnZ2dmjRooWiTnlxtREREZEUqWmpdEZGhlKxXC6HXC4vU33Lli04e/YsYmNjy5xLSUkBAFhbWyuVW1tb4/bt24o6enp6Sj02pXVKry8v9rwQERHVYvb29jAzM1Mc4eHhZeokJSXhww8/xMaNG6Gvr//ctmRP9eYIIcqUPa08dZ7GnhciIiIpUtMOu0lJSTA1NVUUP6vXJS4uDqmpqfDw8FCUFRcX4/fff8fy5ctx7do1AE96V2xtbRV1UlNTFb0xNjY2KCgoQFpamlLvS2pqKry9vVUKnT0vREREUqSm1UampqZKx7OSl27duiE+Ph7nz59XHJ6envD398f58+fh7OwMGxsbREdHK64pKChATEyMIjHx8PCArq6uUp3k5GRcunRJ5eSFPS9ERET0QiYmJmjRooVSmZGRESwtLRXlISEhmDdvHlxcXODi4oJ58+bB0NAQw4cPBwCYmZkhKCgIU6ZMgaWlJSwsLBAaGgp3d/cyE4BfhskLERGRFL1iN2acOnUqcnNzMX78eKSlpaFDhw7Yv38/TExMFHUWL14MHR0dDBkyBLm5uejWrRsiIiKgra2tWuhCCKHW6KnCMjIyYGZmBtPB30Gma6DpcKiK/bliiKZDICI1y8zIQBOHekhPT1eaR6JOpT8r5N3mQqbz/MmzLyOK8pB/cHqVxlpV2PNCREQkRa9Yz0t14oRdIiIikhT2vBAREUlSJTepk3D/BZMXIiIiKeKwEREREZE0sOeFiIhIimSySt7bSLo9L0xeiIiIpEhNN2aUIulGTkRERLUSe16IiIikqBZP2GXyQkREJEUcNiIiIiKSBva8EBERSRGHjYiIiEhSavGwEZMXIiIiKarFPS/STbuIiIioVmLPCxERkQTJZDLIamnPC5MXIiIiCarNyQuHjYiIiEhS2PNCREQkRbL/PypzvUQxeSEiIpIgDhsRERERSQR7XoiIiCSoNve8MHkhIiKSICYvVEZYWBh27NiB8+fPazoUSQro6oKArk1gX9cIAHDt73Qs+iUehy7eU9RxsTXFZ0PbwsvVCloyGa79/Rhjv/0Dfz/KAQCM6NwYgzo6wb2hOUwM9NDkg63IyCnUyOuh8tv4yzFs/OU4/k55BABwaWiDSQE90LlDMwBAaPiP2L4vVuma1s0cELUypLpDpUp62Wf9b59+/RN+3HUSMyb0x6jBPtUdKtUwTF7wJHuNiorCgAEDFGWhoaEIDg7WXFASd+9RDub+dA4J/2QCAIa87oyID33QfeYeXPs7HY5Wxvjls574MeYmvvr5AjJyC9HEzgz5hcWKNgz0dHAo/h4Oxd/DZ0PaaOqlkIps6tXBJ2PfhGP9ugCA7fvOYOz0H/Drmilo4mQDAPBp3xRffTJMcY2urrZGYqXKKc9nDQD7/4jH+St3YF3XVFOh1kjseaEyjI2NYWxsrOkwJCv6/N9Kj7/cfgEBXZugbaO6uPZ3Oqa91RoHL/yNL346p6hz536W0jVr9v8JAPBual31AZPa+Ho3V3r88eje2PTLMZy7kqj4gaanq4N6lvxBJnXl+axT7j/GrKU/I/Kr9zHqP2s0EWbNVYuXSmt0tVHnzp0xadIkTJ06FRYWFrCxsUFYWJjifHp6OsaOHQsrKyuYmpqia9euuHDhglIbc+bMgZWVFUxMTDB69Gj85z//QevWrRXnY2Nj0b17d9StWxdmZmbw8fHB2bNnFecbNmwIABg4cCBkMpnicVhYmKKdffv2QV9fH48fP1Z67kmTJsHH53/dn8ePH0enTp1gYGAAe3t7TJo0CdnZ2ZV+n6ROSyZD/w6OMJTrIO7mA8hkgG+r+vgrJRM/hnbFpWVvY8/MXujVtoGmQyU1Ky4uwa6D55CbV4C2zRsqyk+evwnPATPRZUQ4/vPVVjxIy9RckKQWz/qsS0pKMHneZowd1kWpJ4bUo7TnpTKHVGl8qXRkZCSMjIxw6tQpLFiwAJ9//jmio6MhhMCbb76JlJQU7NmzB3FxcWjbti26deuGR4+ejK9u2rQJc+fOxfz58xEXFwcHBwesXLlSqf3MzEwEBATgjz/+wMmTJ+Hi4oLevXsjM/PJP5axsU/G3tetW4fk5GTF43/z9fVFnTp1sH37dkVZcXExfvrpJ/j7+wMA4uPj0bNnTwwaNAgXL17E1q1bcfToUUycOLFK3jcpaNqgDm6tHoo7a9/BgoAOGPVNDK7fS0ddU30YG+giuE9zHI6/h6FfHcSeuCT8EOwDL1crTYdNavDnX/fQvNd/4Np9KqYv+i9WffEeXBo++eHVuUNTLPlsBDYt+gDTx/fDxT+T4P/RSuQXFGk4aqqIF33Wq348BG1tLQS+9YaGo6SaRuPDRi1btsSsWbMAAC4uLli+fDkOHjwIbW1txMfHIzU1FXK5HACwcOFC7NixA9u2bcPYsWOxbNkyBAUF4b333gMAzJw5E/v370dW1v+GH7p27ar0fKtXr4a5uTliYmLQp08f1KtXDwBQp04d2Ng8+zcDbW1tDB06FJs3b0ZQUBAA4ODBg0hLS8PgwYMBAF999RWGDx+OkJAQxWv55ptv4OPjg5UrV0JfX79Mu/n5+cjPz1c8zsjIUPn9e5XdSs5Atxm7YWaohzfbOeCbMd4YGB6N9JwCAMDes0n4bt+ToaHLd9LQzqUe3u3aBCeupWoybFIDZ3sr7P5+CjKy8rD39wsIDf8RW5ZOgEtDG/Tp+r/5S67Otmjpao/Xh36BwyevoFenlhqMmirieZ91Xn4h1m37A7+umSzp3/BfZTIZKjnnRX2xVLdXInn5N1tbW6SmpiIuLg5ZWVmwtLRUOp+bm4tbt24BAK5du4bx48crnW/fvj0OHTqkeJyamoqZM2fi0KFD+Oeff1BcXIycnBzcuXNHpTj9/f3h5eWFe/fuwc7ODps2bULv3r1hbm4OAIiLi8PNmzexadMmxTVCCJSUlCAhIQHNmpWdfR8eHo7Zs2erFIeUFBaXIDH1SSJ5IfERWjtZYnSPppi+IRaFRSW4fi9dqf6Ne+lo36SeJkIlNdPT1UHDBk8+y5ZN7XHxzySs2/475k0ZUqaulaUp6lubI/Hu/eoOk9TgeZ91YwdrPHychdeGfKGoW1xSgrkrd+KHbb/j6NYZmgq5xpChskM/0s1eNJ686OrqKj2WyWQoKSlBSUkJbG1tceTIkTLX1KlTR6n+vwkhlB4HBgbi/v37WLJkCRwdHSGXy+Hl5YWCggKV4mzfvj0aNWqELVu24IMPPkBUVBTWrVunOF9SUoL3338fkyZNKnOtg4PDM9ucNm0aJk+erHickZEBe3t7leKSEhkAuY4WCotLcD7hIRrZKE/YdLYxwd0HnCNUEwkABQXFzzyXlp6Ne6mPOYG3hij9rAf28MRrHk2UzgVMXY2B3T3xtl97zQRHNYbGk5fnadu2LVJSUqCjo6OYRPs0V1dXnD59GiNHjlSUnTlzRqnOH3/8gRUrVqB3794AgKSkJDx48ECpjq6uLoqLn/0P678NHz4cmzZtQoMGDaClpYU333xTKd7Lly+jcePG5X2JkMvliiGxmmba261x6OLfuPcoB0b6uhjQwRHezazxzsInvWIrfruC1eNfx8lrqTh2NQVdW9qhR+sGGBQerWijnpk+rMwM0NDaBADQrEEdZOUV4e+H2XicrVrySdXnqzW74dOhGezq1UFWbh52HTqPk+dvImLBWGTn5GNJxD74+bSElYUp7qY8wlff74GFmRF6vuGu6dBJRS/6rM3NjGBuZqRUX0dbG/UsTNDIgXPb1IFLpV9Bvr6+8PLywoABAzB//ny4urri3r172LNnDwYMGABPT08EBwdjzJgx8PT0hLe3N7Zu3YqLFy/C2dlZ0U7jxo2xYcMGeHp6IiMjAx9//DEMDAyUnqthw4Y4ePAgXnvtNcjlcsVQ0NP8/f0xe/ZszJ07F2+//bbSPJZPPvkEHTt2xIQJEzBmzBgYGRnh6tWriI6OxrJly6rmTXqF1TPVx/Kxr8GqjgEycwtxJSkN7yw8hN8vpwAAfotLwicRpxHcpznmjPDEreQMBC37Hadv/G/oIKBLE4QO/N+w4i/TewIAPlxzHFuP/lW9L4jK7UFaJibP3YT7jzJgYmSAps62iFgwFm94uiIvvwDXEpIRtf8MMrJyUc/SFF6tG2PZrJEwNiw7L4xebS/6rKkaVPNS6ZUrV2LlypVITEwEADRv3hwzZ86En58fgCcjHZGRkUrXdOjQASdPnlQ8zs/PR2hoKH788Ufk5uaiW7duWLFiBRo0UG216SubvMhkMuzZswfTp0/HqFGjcP/+fdjY2KBTp06wtn6y74e/vz/++usvhIaGIi8vD0OGDEFgYCBOnz6taOeHH37A2LFj0aZNGzg4OGDevHkIDQ1Veq6vv/4akydPxpo1a1C/fn3FB/M0FxcXtGvXDrGxsViyZInSuZYtWyImJgbTp0/HG2+8ASEEGjVqhKFDh6r1fZGKyT+cfGmdH/+4hR//uPXc8wt3XMTCHRfVGRZVg/lThz33nL5cD+u/er8ao6Gq9KLP+lk4z0XaGjRogC+//FIxwhAZGYn+/fvj3LlzaN78yZ4/vXr1UppSoaenp9RGSEgIdu3ahS1btsDS0hJTpkxBnz59EBcXB23t8m9WKRNPTxKRuO7du8PGxgYbNmzQdCgqy8jIgJmZGUwHfweZrsHLLyBJ+3NF2cmrRCRtmRkZaOJQD+np6TA1rZp5XKU/K8zfWQstPcMKt1NSkIO0H4MqFauFhQW++uorBAUFITAwEI8fP8aOHTueWTc9PR316tXDhg0bFL/Y37t3D/b29tizZw969uxZ7ufV+D4vlZGTk4NFixbh8uXL+PPPPzFr1iwcOHAAAQEBmg6NiIioSmlyk7ri4mJs2bIF2dnZ8PLyUpQfOXIEVlZWaNKkCcaMGYPU1P9tfREXF4fCwkL06NFDUWZnZ4cWLVrg+PHjKj3/KztsVB6lQ0tz5sxBfn4+XF1dsX37dvj6+mo6NCIiIkl4eo+xFy0miY+Ph5eXF/Ly8mBsbIyoqCi4ubkBAPz8/DB48GA4OjoiISEBM2bMQNeuXREXFwe5XI6UlBTo6emVmVdqbW2NlJQUlWKWdPJiYGCAAwcOaDoMIiKialfZ3pPSa5/eomPWrFlKt+r5N1dXV5w/fx6PHz/G9u3bERAQgJiYGLi5uSnN8WzRogU8PT3h6OiI3bt3Y9CgQc+NQwih8uuQdPJCRERUa6lptVFSUpLSnJcXbeGhp6enmLDr6emJ2NhYLF26FKtXry5T19bWFo6Ojrhx4wYAwMbGBgUFBUhLS1PqfUlNTYW3t7dKoUt6zgsREVFtpa45L6ampkqHKvuPCSGUbnPzbw8fPkRSUhJsbW0BAB4eHtDV1UV09P/280pOTsalS5dUTl7Y80JEREQv9emnn8LPzw/29vbIzMzEli1bcOTIEezduxdZWVkICwvDW2+9BVtbWyQmJuLTTz9F3bp1MXDgQACAmZkZgoKCMGXKFFhaWsLCwgKhoaFwd3dXea4qkxciIiIJUtecl/L6559/MHLkSCQnJ8PMzAwtW7bE3r170b17d+Tm5iI+Ph7r16/H48ePYWtriy5dumDr1q0wMTFRtLF48WLo6OhgyJAhik3qIiIiVNrjBWDyQkREJEnVnbysXbv2uecMDAywb9++l7ahr6+PZcuWVXrnec55ISIiIklhzwsREZEEVXfPy6uEyQsREZEUVfONGV8lHDYiIiIiSWHPCxERkQRx2IiIiIgkpTYnLxw2IiIiIklhzwsREZEE1eaeFyYvREREUlSLVxsxeSEiIpKg2tzzwjkvREREJCnseSEiIpKg2tzzwuSFiIhIgmSoZPIi4UkvHDYiIiIiSWHPCxERkQRx2IiIiIikpRYvleawEREREUkKe16IiIgkiMNGREREJCm1OXnhsBERERFJCnteiIiIJEgme3JU5nqpYvJCREQkQU+Sl8oMG6kxmGrG5IWIiEiKKtnzwqXSRERERNWEPS9EREQSVJtXGzF5ISIikqDaPGGXw0ZEREQkKex5ISIikiAtLRm0tCrefSIqca2mMXkhIiKSIA4bEREREUkEe16IiIgkiKuNiIiISFI4bERERET0AitXrkTLli1hamoKU1NTeHl54bffflOcF0IgLCwMdnZ2MDAwQOfOnXH58mWlNvLz8xEcHIy6devCyMgI/fr1w927d1WOhckLERGRBJUOG1XmUEWDBg3w5Zdf4syZMzhz5gy6du2K/v37KxKUBQsWYNGiRVi+fDliY2NhY2OD7t27IzMzU9FGSEgIoqKisGXLFhw9ehRZWVno06cPiouLVYqFyQsREZEEVXfy0rdvX/Tu3RtNmjRBkyZNMHfuXBgbG+PkyZMQQmDJkiWYPn06Bg0ahBYtWiAyMhI5OTnYvHkzACA9PR1r167F119/DV9fX7Rp0wYbN25EfHw8Dhw4oFIsTF6IiIgkqHTOS2WOiiouLsaWLVuQnZ0NLy8vJCQkICUlBT169FDUkcvl8PHxwfHjxwEAcXFxKCwsVKpjZ2eHFi1aKOqUFyfsEhER1WIZGRlKj+VyOeRy+TPrxsfHw8vLC3l5eTA2NkZUVBTc3NwUyYe1tbVSfWtra9y+fRsAkJKSAj09PZibm5epk5KSolLM7HkhIiKSIBkqOWyEJ10v9vb2MDMzUxzh4eHPfU5XV1ecP38eJ0+exAcffICAgABcuXLlfzE91Z0jhHjp8FR56jyNPS9EREQSpK6l0klJSTA1NVWUP6/XBQD09PTQuHFjAICnpydiY2OxdOlSfPLJJwCe9K7Y2toq6qempip6Y2xsbFBQUIC0tDSl3pfU1FR4e3urFDt7XoiIiGqx0qXPpceLkpenCSGQn58PJycn2NjYIDo6WnGuoKAAMTExisTEw8MDurq6SnWSk5Nx6dIllZMX9rwQERFJUHXvsPvpp5/Cz88P9vb2yMzMxJYtW3DkyBHs3bsXMpkMISEhmDdvHlxcXODi4oJ58+bB0NAQw4cPBwCYmZkhKCgIU6ZMgaWlJSwsLBAaGgp3d3f4+vqqFAuTFyIiIgmq7h12//nnH4wcORLJyckwMzNDy5YtsXfvXnTv3h0AMHXqVOTm5mL8+PFIS0tDhw4dsH//fpiYmCjaWLx4MXR0dDBkyBDk5uaiW7duiIiIgLa2tmqxCyGEauFTVcnIyICZmRlMB38Hma6BpsOhKvbniiGaDoGI1CwzIwNNHOohPT1daR6JOpX+rGg9fRe09Y0q3E5xXjbOz+1bpbFWFfa8EBERSRBvzEhERESSwhszEhEREUkEe16IiIgkiMNG9Eq5sWqo5CZPkerM203UdAhUjdJil2s6BKoGWsV61fdklRw2gnRzFyYvREREUlSbe14454WIiIgkhT0vREREElSbVxsxeSEiIpIgDhsRERERSQR7XoiIiCSIw0ZEREQkKRw2IiIiIpII9rwQERFJUG3ueWHyQkREJEG1ec4Lh42IiIhIUtjzQkREJEEcNiIiIiJJqc3DRkxeiIiIJKg297xwzgsRERFJCnteiIiIJEiGSg4bqS2S6sfkhYiISIK0ZDJoVSJ7qcy1msZhIyIiIpIU9rwQERFJEFcbERERkaRwtRERERGRRLDnhYiISIK0ZE+OylwvVUxeiIiIpEhWyaEfCScvHDYiIiIiSWHPCxERkQRxtRERERFJiuz//6vM9VLF5IWIiEiCavOEXc55ISIiopcKDw9Hu3btYGJiAisrKwwYMADXrl1TqhMYGKjYf6b06Nixo1Kd/Px8BAcHo27dujAyMkK/fv1w9+5dlWJh8kJERCRBTycJFTlUERMTgwkTJuDkyZOIjo5GUVERevTogezsbKV6vXr1QnJysuLYs2eP0vmQkBBERUVhy5YtOHr0KLKystCnTx8UFxeXO5ZyDRt988035W5w0qRJ5a5LREREFVPdE3b37t2r9HjdunWwsrJCXFwcOnXqpCiXy+WwsbF5Zhvp6elYu3YtNmzYAF9fXwDAxo0bYW9vjwMHDqBnz57liqVcycvixYvL1ZhMJmPyQkREJCEZGRlKj+VyOeRy+UuvS09PBwBYWFgolR85cgRWVlaoU6cOfHx8MHfuXFhZWQEA4uLiUFhYiB49eijq29nZoUWLFjh+/Lh6k5eEhIRyNUZERETVQ0smg1Ylul5Kr7W3t1cqnzVrFsLCwl54rRACkydPxuuvv44WLVooyv38/DB48GA4OjoiISEBM2bMQNeuXREXFwe5XI6UlBTo6enB3NxcqT1ra2ukpKSUO/YKrzYqKChAQkICGjVqBB0dLloiIiKqTuoaNkpKSoKpqamivDy9LhMnTsTFixdx9OhRpfKhQ4cq/tyiRQt4enrC0dERu3fvxqBBg57bnhBCpTk4Kk/YzcnJQVBQEAwNDdG8eXPcuXMHwJO5Ll9++aWqzREREZEGmZqaKh0vS16Cg4Oxc+dOHD58GA0aNHhhXVtbWzg6OuLGjRsAABsbGxQUFCAtLU2pXmpqKqytrcsds8rJy7Rp03DhwgUcOXIE+vr6inJfX19s3bpV1eaIiIioAqp7tZEQAhMnTsTPP/+MQ4cOwcnJ6aXXPHz4EElJSbC1tQUAeHh4QFdXF9HR0Yo6ycnJuHTpEry9vcsdi8rjPTt27MDWrVvRsWNHpRfu5uaGW7duqdocERERVUB1rzaaMGECNm/ejF9++QUmJiaKOSpmZmYwMDBAVlYWwsLC8NZbb8HW1haJiYn49NNPUbduXQwcOFBRNygoCFOmTIGlpSUsLCwQGhoKd3d3xeqj8lA5ebl//75i1vC/ZWdnV+7ulkRERPTKWrlyJQCgc+fOSuXr1q1DYGAgtLW1ER8fj/Xr1+Px48ewtbVFly5dsHXrVpiYmCjqL168GDo6OhgyZAhyc3PRrVs3REREQFtbu9yxqJy8tGvXDrt370ZwcDCA/92Oe82aNfDy8lK1OSIiIqoAda02Ki8hxAvPGxgYYN++fS9tR19fH8uWLcOyZctUev5/Uzl5CQ8PR69evXDlyhUUFRVh6dKluHz5Mk6cOIGYmJgKB0JERETlJ/v/ozLXS5XKE3a9vb1x7Ngx5OTkoFGjRti/fz+sra1x4sQJeHh4VEWMRERE9JTqnrD7KqnQBi3u7u6IjIxUdyxEREREL1Wh5KW4uBhRUVG4evUqZDIZmjVrhv79+3OzOiIiomqiJXtyVOZ6qVI527h06RL69++PlJQUuLq6AgCuX7+OevXqYefOnXB3d1d7kERERKSsskM/Uh42UnnOy+jRo9G8eXPcvXsXZ8+exdmzZ5GUlISWLVti7NixVREjERERkYLKPS8XLlzAmTNnlG6qZG5ujrlz56Jdu3ZqDY6IiIieT8KdJ5Wics+Lq6sr/vnnnzLlqampaNy4sVqCIiIioherzauNypW8ZGRkKI558+Zh0qRJ2LZtG+7evYu7d+9i27ZtCAkJwfz586s6XiIiIqrlyjVsVKdOHaUMTQiBIUOGKMpKd93r27cviouLqyBMIiIi+jeuNnqJw4cPV3UcREREpILavNqoXMmLj49PVcdBREREKqjNtweo8K5yOTk5uHPnDgoKCpTKW7ZsWemgiIiIiJ5H5eTl/v37eO+99/Dbb7898zznvBAREVW96r6r9KtE5aXSISEhSEtLw8mTJ2FgYIC9e/ciMjISLi4u2LlzZ1XESERERE+RySp/SJXKPS+HDh3CL7/8gnbt2kFLSwuOjo7o3r07TE1NER4ejjfffLMq4iQiIiICUIGel+zsbFhZWQEALCwscP/+fQBP7jR99uxZ9UZHREREz8RN6lTg6uqKa9euAQBat26N1atX4++//8aqVatga2ur9gCpZvv+v7+jVf9ZsHktBJ1Hzsfxczc1HRJVwkeBPZAWuxzzJr+lKPtkTG+c+u9nuPv710g4uABR306ER3NHpesCBr6GXas+xO3DXyEtdjlMjQ2qO3RSM363q15tHjaq0JyX5ORkAMCsWbOwd+9eODg44JtvvsG8efPUHqCUNWzYEEuWLNF0GK+sn/fH4dNF2zHlvZ6I2fgfeLVuhCEfrkBSyiNNh0YV0MbNAQEDvHHp+l2l8lt3UjH1q//itXfmwW/MIty59wg/L58IyzrGijoG+ro4eOIKFkfsr+6wqQrwu01VTeXkxd/fH4GBgQCANm3aIDExEbGxsUhKSsLQoUPVHV+16ty5M0JCQjQdRq2xYvMhjOjvhXcHeMPVyQbhU95GfWtz/LDtD02HRioyMtDDd58H4sN5P+JxZq7SuW37ziDm9DXc/vsh/vwrBZ8t+RmmxgZo7mKnqLPqxyNYEhmN2PjEao6cqgK/29WjdLVRZQ6pUjl5eZqhoSHatm2LunXrqiOeV54QAkVFRZoOQ/IKCotw/s8kdO3QTKm8S4dmOH0xQUNRUUV9NXUo9h+7hJjT115YT1dHGwEDX0N6Zg4uXf+7mqKj6sTvdvWpzcNG5VptNHny5HI3uGjRogoH8yKdO3dGy5Ytoa+vj++//x56enoYN24cwsLCAADp6en4+OOPsWPHDuTl5cHT0xOLFy9Gq1atAACBgYF4/PgxduzYoWgzJCQE58+fx5EjRxAYGIiYmBjExMRg6dKlAICEhAQkJiaiS5cu2Lt3L6ZPn46LFy9i3759cHBwwOTJk3Hy5ElkZ2ejWbNmCA8Ph6+vb5W8/prm4eMsFBeXoJ6FiVJ5PUsTpD7M0FBUVBGDunugVVN7dA1Y8Nw6PV9vge/nvgdDfV2kPMjAwInL8Sg9uxqjpOrC7zZVh3IlL+fOnStXY1U9czkyMhKTJ0/GqVOncOLECQQGBuK1116Dr68v3nzzTVhYWGDPnj0wMzPD6tWr0a1bN1y/fh0WFhYvbXvp0qW4fv06WrRogc8//xwAUK9ePSQmJgIApk6dioULF8LZ2Rl16tTB3bt30bt3b8yZMwf6+vqIjIxE3759ce3aNTg4OJTr9eTn5yM/P1/xOCOj9n2xn/4rI4SQ9Az42qa+dR2ET3kLbwV/i/yC5/dI/nHmOjr5h8OyjjHeHeCNdfNGwfe9hXiQllWN0VJ14ne76vHeRi/xqtyYsWXLlpg1axYAwMXFBcuXL8fBgwehra2N+Ph4pKamQi6XAwAWLlyIHTt2YNu2bRg7duxL2zYzM4Oenh4MDQ1hY2NT5vznn3+O7t27Kx5bWloqenUAYM6cOYiKisLOnTsxceLEcr2e8PBwzJ49u1x1axrLOsbQ1tZC6sNMpfIHj7LK/MZGr65WTR1gZWmKw+unKsp0dLTh3aYRxgzuBOvXQlBSIpCTV4CEuw+QcPcBzlxKxJntMzGyvzcn6NZA/G5XHy1Ubu5HpeeNaFCF722kCU/fN8nW1hapqamIi4tDVlYWLC0tlc7n5ubi1q1banluT09PpcfZ2dmYPXs2fv31V9y7dw9FRUXIzc3FnTt3yt3mtGnTlIbkMjIyYG9vr5Z4X3V6ujpo3dQeh0/9iT5d/pcEHjn9J/w6uWswMlLF77HX4D1srlLZ8pkjcCPxHyxdH42SEvHM62QyGfR0JfXPD5UTv9vVhz0vEqGrq6v0WCaToaSkBCUlJbC1tcWRI0fKXFOnTh0AgJaWFoRQ/oe0sLCw3M9tZGSk9Pjjjz/Gvn37sHDhQjRu3BgGBgZ4++23y9yo8kXkcrmip6g2Gj+8K8bNWo82bg5o5+6EyKhjuJvyCO+99YamQ6NyysrJx9VbyUplObkFeJSejau3kmGor4cpo3rit9/j8c+DdJibGSHo7U6ws6qDXw7+b1NLK0sTWFmawtn+ycT/5o3tkJmTh7spaXickVOtr4kqj99tqmqSSl6ep23btkhJSYGOjg4aNmz4zDr16tXDpUuXlMrOnz+vlBDp6emV+8aSf/zxBwIDAzFw4EAAQFZWlmJ+DJXPoB4eeJSejQXf/4Z/HmSgWSNbbF0yHg62L5+jRNJQXFICl4bWGPZmB1jWMcKj9Bycu3Ibvccuxp9/pSjqvTfoDfxnbG/F4z1rPgIAjJ+9AT/+eqra46bK4Xe7eshkgFYlOk8k3PFSM5IXX19feHl5YcCAAZg/fz5cXV1x79497NmzBwMGDICnpye6du2Kr776CuvXr4eXlxc2btyIS5cuoU2bNop2GjZsiFOnTiExMRHGxsYvnOjbuHFj/Pzzz+jbty9kMhlmzJiBkpKS6ni5NcrowZ0wenAnTYdBatR33FLFn/MLivDu1O9fes38NXswf82eqgyLqhm/21VPq5LJS2Wu1TQpz9dRkMlk2LNnDzp16oRRo0ahSZMmGDZsGBITE2FtbQ0A6NmzJ2bMmIGpU6eiXbt2yMzMxLvvvqvUTmhoKLS1teHm5oZ69eq9cP7K4sWLYW5uDm9vb/Tt2xc9e/ZE27Ztq/R1EhERESATT08EKYcNGzZg1apVSEhIwIkTJ+Do6IglS5bAyckJ/fv3r4o4a4WMjAyYmZnhn4fpMDU11XQ4VMXM25VvVRrVDGmxyzUdAlWDjIwMWFuaIT296v4dL/1ZMWHLGcgNjV9+wXPk52Th22GeVRprVVG552XlypWYPHkyevfujcePHyvmiNSpU4f38SEiIqompcNGlTmkSuXkZdmyZVizZg2mT58ObW1tRbmnpyfi4+PVGhwRERHR01ROXhISEpQmuZaSy+XIzuZ230RERNWhuu9tFB4ejnbt2sHExARWVlYYMGAArl1Tvp+ZEAJhYWGws7ODgYEBOnfujMuXLyvVyc/PR3BwMOrWrQsjIyP069cPd+8q343+ZVROXpycnHD+/Pky5b/99hvc3NxUbY6IiIgqoLrvKh0TE4MJEybg5MmTiI6ORlFREXr06KHUcbFgwQIsWrQIy5cvR2xsLGxsbNC9e3dkZv5vx+WQkBBERUVhy5YtOHr0KLKystCnT59yb1UCVGCp9Mcff4wJEyYgLy8PQgicPn0aP/74I8LDw/H99y9fEklERETSs3fvXqXH69atg5WVFeLi4tCpUycIIbBkyRJMnz4dgwYNAvDknoTW1tbYvHkz3n//faSnp2Pt2rXYsGGD4kbGGzduhL29PQ4cOICePXuWKxaVk5f33nsPRUVFmDp1KnJycjB8+HDUr18fS5cuxbBhw1RtjoiIiCpAXfc2evqmwOXd/T09PR0AFHuiJSQkICUlBT169FBqy8fHB8ePH8f777+PuLg4FBYWKtWxs7NDixYtcPz48XInLxV63WPGjMHt27eRmpqKlJQUJCUlISgoqCJNERERUQWoa86Lvb09zMzMFEd4ePhLn1sIgcmTJ+P1119HixYtAAApKU92zS7dX62UtbW14lxKSgr09PRgbm7+3DrlUakdduvWrVuZy4mIiKiCtKD6vJWnrweApKQkpX1eytPrMnHiRFy8eBFHjx4tc+7pGz4KIV56E8jy1Pk3lZMXJyenFz7BX3/9pWqTREREpCGmpqYqbVIXHByMnTt34vfff0eDBg0U5TY2NgCe9K7Y2toqylNTUxW9MTY2NigoKEBaWppS70tqaiq8vb3LHYPKyUtISIjS48LCQpw7dw579+7Fxx9/rGpzREREVAEVWe789PWqEEIgODgYUVFROHLkCJycnJTOOzk5wcbGBtHR0YotVQoKChATE4P58+cDADw8PKCrq4vo6GgMGTIEAJCcnIxLly5hwYIF5Y5F5eTlww8/fGb5t99+izNnzqjaHBEREVVAdd+YccKECdi8eTN++eUXmJiYKOaomJmZwcDAADKZDCEhIZg3bx5cXFzg4uKCefPmwdDQEMOHD1fUDQoKwpQpU2BpaQkLCwuEhobC3d1dsfqoPNR2V2k/Pz9MmzYN69atU1eTRERE9IpYuXIlAKBz585K5evWrUNgYCAAYOrUqcjNzcX48eORlpaGDh06YP/+/TAxMVHUX7x4MXR0dDBkyBDk5uaiW7duiIiIUNq1/2XUlrxs27ZNsVyKiIiIqpZMhkpN2K3IsNHL25QhLCwMYWFhz62jr6+PZcuWYdmyZaoF8C8qJy9t2rRRmrArhEBKSgru37+PFStWVDgQIiIiKr/qnvPyKlE5eRkwYIDSYy0tLdSrVw+dO3dG06ZN1RUXERER0TOplLwUFRWhYcOG6Nmzp2JJFBEREVW/6p6w+ypRaYddHR0dfPDBB8jPz6+qeIiIiKgcZGr4T6pUvj1Ahw4dcO7cuaqIhYiIiOilVJ7zMn78eEyZMgV3796Fh4cHjIyMlM63bNlSbcERERHRs9XmYaNyJy+jRo3CkiVLMHToUADApEmTFOdkMpnivgTFxcXqj5KIiIiUMHkph8jISHz55ZdISEioyniIiIioHGQymUo3M3zW9VJV7uSldHMaR0fHKguGiIiI6GVUmvMi5SyNiIioJuGwUTk1adLkpQnMo0ePKhUQERERvRx32C2n2bNnw8zMrKpiISIiInoplZKXYcOGwcrKqqpiISIionLSkskqdWPGylyraeVOXjjfhYiI6NVRm+e8lHuH3fLcCpuIiIioqpW756WkpKQq4yAiIiJVVHLCroRvbaT67QGIiIhI87Qgg1YlMpDKXKtpKt+YkYiIiEiT2PNCREQkQdznhYiIiCSlNq82YvJCREQkQbV5nxfOeSEiIiJJYc8LERGRBHHOCxEREUmKFio5bMSl0kRERETVgz0vREREEsRhIyIiIpIULVRu+ETKQy9Sjp2IiIhqIfa8EBERSZBMJoOsEmM/lblW05i8EBERSZAMlbsxtHRTFw4bERERkcSw54WIiEiCeHsAIiIikhxZJQ5V/f777+jbty/s7Owgk8mwY8cOpfOBgYGKeTilR8eOHZXq5OfnIzg4GHXr1oWRkRH69euHu3fvqhwLkxciIiIJKt3npTKHKrKzs9GqVSssX778uXV69eqF5ORkxbFnzx6l8yEhIYiKisKWLVtw9OhRZGVloU+fPiguLlYpFg4bERER0Uv5+fnBz8/vhXXkcjlsbGyeeS49PR1r167Fhg0b4OvrCwDYuHEj7O3tceDAAfTs2bPcsbDnhYiISIKeHqKpyAEAGRkZSkd+fn6FYzpy5AisrKzQpEkTjBkzBqmpqYpzcXFxKCwsRI8ePRRldnZ2aNGiBY4fP67S8zB5ISIikiAtNRwAYG9vDzMzM8URHh5eoXj8/PywadMmHDp0CF9//TViY2PRtWtXRTKUkpICPT09mJubK11nbW2NlJQUlZ6Lw0ZERES1WFJSEkxNTRWP5XJ5hdoZOnSo4s8tWrSAp6cnHB0dsXv3bgwaNOi51wkhVN4wjz0vREREEqSuYSNTU1Olo6LJy9NsbW3h6OiIGzduAABsbGxQUFCAtLQ0pXqpqamwtrZWqW0mL0RERBJUmWXSld2dtzwePnyIpKQk2NraAgA8PDygq6uL6OhoRZ3k5GRcunQJ3t7eKrXNYSMiIiJ6qaysLNy8eVPxOCEhAefPn4eFhQUsLCwQFhaGt956C7a2tkhMTMSnn36KunXrYuDAgQAAMzMzBAUFYcqUKbC0tISFhQVCQ0Ph7u6uWH1UXkxeXkHFJQLFJULTYVAVu3/yG02HQNXIvNM0TYdA1UAUVXyljqqq+8aMZ86cQZcuXRSPJ0+eDAAICAjAypUrER8fj/Xr1+Px48ewtbVFly5dsHXrVpiYmCiuWbx4MXR0dDBkyBDk5uaiW7duiIiIgLa2tkqxMHkhIiKSoH+vGKro9aro3LkzhHj+L9b79u17aRv6+vpYtmwZli1bpuKzK+OcFyIiIpIU9rwQERFJUHUPG71KmLwQERFJUGVXDEk3dWHyQkREJEkVubni09dLFee8EBERkaSw54WIiEiCtCCDViUGfypzraYxeSEiIpIgDhsRERERSQR7XoiIiCRI9v//VeZ6qWLyQkREJEEcNiIiIiKSCPa8EBERSZCskquNOGxERERE1YrDRkREREQSwZ4XIiIiCarNPS9MXoiIiCSIS6WJiIhIUrRkT47KXC9VnPNCREREksKeFyIiIgnisBERERFJSm2esMthIyIiIpIU9rwQERFJkAyVG/qRcMcLkxciIiIp4mojIiIiIolgzwsREZEEcbURERERSQpXGxERERFJBHteiIiIJEiGyq0YknDHC5MXIiIiKdKCDFqVGPvRknD6wuSFiIhIgmpzzwvnvBAREZGksOeFiIhIimpx1wt7XoiIiCRIpob/VPH777+jb9++sLOzg0wmw44dO5TOCyEQFhYGOzs7GBgYoHPnzrh8+bJSnfz8fAQHB6Nu3bowMjJCv379cPfuXZVfO5MXIiIieqns7Gy0atUKy5cvf+b5BQsWYNGiRVi+fDliY2NhY2OD7t27IzMzU1EnJCQEUVFR2LJlC44ePYqsrCz06dMHxcXFKsXCYSMiIiIpquQmdaoOG/n5+cHPz++Z54QQWLJkCaZPn45BgwYBACIjI2FtbY3Nmzfj/fffR3p6OtauXYsNGzbA19cXALBx40bY29vjwIED6NmzZ7ljYc8LERGRBMnUcABARkaG0pGfn69yLAkJCUhJSUGPHj0UZXK5HD4+Pjh+/DgAIC4uDoWFhUp17Ozs0KJFC0Wd8mLyQkREVIvZ29vDzMxMcYSHh6vcRkpKCgDA2tpaqdza2lpxLiUlBXp6ejA3N39unfLisBEREZEUqWm1UVJSEkxNTRXFcrm84k0+NY4lhChT9rTy1Hkae16IiIgkSF2rjUxNTZWOiiQvNjY2AFCmByU1NVXRG2NjY4OCggKkpaU9t055MXkhIiKiSnFycoKNjQ2io6MVZQUFBYiJiYG3tzcAwMPDA7q6ukp1kpOTcenSJUWd8uKwERERkQTJKrnaSNVrs7KycPPmTcXjhIQEnD9/HhYWFnBwcEBISAjmzZsHFxcXuLi4YN68eTA0NMTw4cMBAGZmZggKCsKUKVNgaWkJCwsLhIaGwt3dXbH6qLyYvBAREUlQdW+we+bMGXTp0kXxePLkyQCAgIAAREREYOrUqcjNzcX48eORlpaGDh06YP/+/TAxMVFcs3jxYujo6GDIkCHIzc1Ft27dEBERAW1tbdViF0IIFeOnKpKRkQEzMzPcu/9YafIU1Uz86tUu9bpM13QIVA1EUT7yYxcjPT29yv4dL/1ZEROfBGOTij9HVmYGfNztqzTWqsI5L0RERCQpHDYiIiKSoIrcn+jp66WKyQsREZEEVfeE3VcJh42IiIhIUtjzQkREJEHVvdroVcLkhYiISIpqcfbCYSMiIiKSFPa8EBERSRBXGxEREZGkcLURERERkUSw54WIiEiCavF8XSYvpDnJqY8x+9tfcPD4FeTlF6KRgxWWTB+O1s0cNB0aVdLxczfx7caDuHAtCf88yEDk/NHo7dNScV4Iga++/w3rfzmO9MxctHVzxPyPB6Ops60GoyZVfeTvg5nv98LK/x7Dp8t+BQD06dQcgf3ao3WT+rCsY4Q3Rn2DSzeTla7btXQMXm/jrFT288ELCJq9pdpirxFqcfZS64aNjhw5AplMhsePH7+wXsOGDbFkyZJqiak2epyRg95jF0NXWxtbl3yAY1um4/MPB8LMxEDToZEa5OQWoLlLfXw5ZfAzzy/bcAArfzyML6cMxv4fpsDK0hRvT/oWWdl51RwpVVSbpg0Q0K99mcTESF8Pp+JvY/bqvS+8PmLnabgOmKs4PloYVZXh1kgyNfwnVbWu58Xb2xvJyckwMzMDAERERCAkJKRMMhMbGwsjIyMNRFg7fLMhGvWt6mDZzBGKMgc7Sw1GROrk6+0GX2+3Z54TQmD11hh8FNgDfbq0AgAsn+kPt96fYfv+OAQMfK06Q6UKMDLQw3czhuLDBT8j9N2uSue27j8HALC3qfPCNnLzC5H6KKuqQqQartb1vOjp6cHGxgayl0yzrlevHgwNDaspqtpn7++X0KqZA0ZNW4umvaahy8j5WL/jmKbDompw+95DpD7MQOcOTRVlcj1deLdphNPxCRqMjMrrq4/6Y/+JPxETd6vCbQzu3go3d36G45Eh+Hy8H4wN9NQYYe1QutqoModUvZLJS+fOnTFx4kRMnDgRderUgaWlJT777DMIIQAAaWlpePfdd2Fubg5DQ0P4+fnhxo0biutv376Nvn37wtzcHEZGRmjevDn27NkDQHnY6MiRI3jvvfeQnp4OmUwGmUyGsLAwAMrDRu+88w6GDRumFGNhYSHq1q2LdevWAXjy2+SCBQvg7OwMAwMDtGrVCtu2bavid0q6bt97gIifj8LZvh5+WjoeAQNfw6eLtmPrnlOaDo2qWOrDDACAlYWpUnk9C1PFOXp1DeraEq2a2OHz7/ZVuI3/Rp/H6Nlb0PfDNVgYeQj9fFpg/ZwRL7+QlMjUcEjVKztsFBkZiaCgIJw6dQpnzpzB2LFj4ejoiDFjxiAwMBA3btzAzp07YWpqik8++QS9e/fGlStXoKuriwkTJqCgoAC///47jIyMcOXKFRgbG5d5Dm9vbyxZsgQzZ87EtWvXAOCZ9fz9/TFkyBBkZWUpzu/btw/Z2dl46623AACfffYZfv75Z6xcuRIuLi74/fffMWLECNSrVw8+Pj7PfI35+fnIz89XPM7IqD3/cJeUCLRu5oDPxvcDALR0tce1hBSs234UQ3t30HB0VC2e+pdTCCHp3wRrg/pWZgif1AdvTfkB+QVFFW5n/a+xij9fTfgHt+4+wJHvg9GyiR0uXr+njlCphntlkxd7e3ssXrwYMpkMrq6uiI+Px+LFi9G5c2fs3LkTx44dg7e3NwBg06ZNsLe3x44dOzB48GDcuXMHb731Ftzd3QEAzs7Oz3wOPT09mJmZQSaTwcbG5rmx9OzZE0ZGRoiKisLIkSMBAJs3b0bfvn1hamqK7OxsLFq0CIcOHYKXl5fiOY8ePYrVq1c/N3kJDw/H7NmzK/weSZl1XVM0cVJ+z10aWmPX4fOaCYiqjZXlkx6X1IcZsKlrpih/kJaJek/1xtCrpVWT+rCyMMHhNRMVZTo62vBu1RBjBnaEte8MlJQIldu9cP0eCgqL0KiBJZMXVXC10aunY8eOSvNSvLy8cOPGDVy5cgU6Ojro0OF/v51bWlrC1dUVV69eBQBMmjQJc+bMwWuvvYZZs2bh4sWLlYpFV1cXgwcPxqZNmwAA2dnZ+OWXX+Dv7w8AuHLlCvLy8tC9e3cYGxsrjvXr1+PWreePCU+bNg3p6emKIykpqVJxSkn7ls64dfsfpbJbd1Jhb2OhoYioujjaWcLK0hQxp68pygoKi3D83C20d3fSYGT0Mr/H3YR3wBJ0ClqmOM5evYv/Rl9Ap6BlFUpcAKCZkzX0dHXwz8NMNUdcs3G1UQ3wpMv5yQcxevRo9OzZE7t378b+/fsRHh6Or7/+GsHBwRVu39/fHz4+PkhNTUV0dDT09fXh5+cHACgpKQEA7N69G/Xr11e6Ti6XP7dNuVz+wvM12bh3uqD36EVYHLEP/bu1xdkrt7Fhx3F8PW3Yyy+mV15WTj4S7t5XPL5z7yHir9+FuakhGthY4P2hPlgSGQ1n+3pwtq+HJZHRMNDXxVs9PDQYNb1MVm4BriYo/9KRk1eARxk5ivI6JgZoYF0HtnWf9KK5ONQFAKQ+ykTqoyw0tLPA4O6tEX3yGh6mZ6NpQ2t8MaE3Llz/Gyfjb1fvCyLJemWTl5MnT5Z57OLiAjc3NxQVFeHUqVOKYaOHDx/i+vXraNasmaK+vb09xo0bh3HjxmHatGlYs2bNM5MXPT09FBcXvzQeb29v2NvbY+vWrfjtt98wePBg6Ok9mR3v5uYGuVyOO3fuPHeIiJS1dXNE5IIxmLNiJxau3QsHO0vM+WgQBvdqp+nQSA0uXL2DAROWKR7PWPpkD4+hvdtj+cwRCB7pi7z8Qkz96r9Iz8xB2+aO+O/S8TA20tdUyKQmfq81w4pP/7e/zw9hwwEAX647gPnrDqKwqBg+Ho0w7u3XYGSgh79T07H/5J+Yv+5ghXtuaqvafG+jVzZ5SUpKwuTJk/H+++/j7NmzWLZsGb7++mu4uLigf//+GDNmDFavXg0TExP85z//Qf369dG/f38AQEhICPz8/NCkSROkpaXh0KFDSonNvzVs2BBZWVk4ePAgWrVqBUNDw2cukZbJZBg+fDhWrVqF69ev4/Dhw4pzJiYmCA0NxUcffYSSkhK8/vrryMjIwPHjx2FsbIyAgICqeZMkrufrLdDz9RaaDoOqwGseLrh/8pvnnpfJZJg6pjemjuldjVFRVej74Rqlxz/uPYsf9559bv2/U9PRZ9Ka556n8qvFU15e3Tkv7777LnJzc9G+fXtMmDABwcHBGDt2LABg3bp18PDwQJ8+feDl5QUhBPbs2QNdXV0AQHFxMSZMmIBmzZqhV69ecHV1xYoVK575PN7e3hg3bhyGDh2KevXqYcGCBc+Nyd/fH1euXEH9+vXx2mvKG2l98cUXmDlzJsLDw9GsWTP07NkTu3btgpMTx/CJiIjUSSZKN095hXTu3BmtW7euddvzZ2RkwMzMDPfuP4apKVdd1HSv4FePqlC9LtM1HQJVA1GUj/zYxUhPT6+yf8dLf1bE3UiGsUnFnyMrMwMeLrZVGmtVeWWHjYiIiOj5KrtiiKuNiIiIqHpVdot/6eYur2bycuTIEU2HQERERK+oVzJ5ISIioherzauNmLwQERFJUS3OXl7ZpdJEREREz8KeFyIiIgniaiMiIiKSlNp8ewAOGxEREdFLhYWFQSaTKR02NjaK80IIhIWFwc7ODgYGBujcuTMuX75cJbEweSEiIpIgmRoOVTVv3hzJycmKIz4+XnFuwYIFWLRoEZYvX47Y2FjY2Nige/fuyMzMrPiLfA4OGxEREUmRBlYb6ejoKPW2lBJCYMmSJZg+fToGDRoEAIiMjIS1tTU2b96M999/vxKBlsWeFyIiolosIyND6cjPz39u3Rs3bsDOzg5OTk4YNmwY/vrrLwBAQkICUlJS0KNHD0VduVwOHx8fHD9+XO0xM3khIiKSIJka/gMAe3t7mJmZKY7w8PBnPl+HDh2wfv167Nu3D2vWrEFKSgq8vb3x8OFDpKSkAACsra2VrrG2tlacUycOGxEREUmQDJVcbfT//09KSlK6q7RcLn9mfT8/P8Wf3d3d4eXlhUaNGiEyMhIdO3Z80uZTAQkhypSpA3teiIiIJEhdE3ZNTU2VjuclL08zMjKCu7s7bty4oZgH83QvS2pqapneGHVg8kJEREQqy8/Px9WrV2FrawsnJyfY2NggOjpacb6goAAxMTHw9vZW+3Nz2IiIiEiCqnuTutDQUPTt2xcODg5ITU3FnDlzkJGRgYCAAMhkMoSEhGDevHlwcXGBi4sL5s2bB0NDQwwfPrziQT4HkxciIiJJqt610nfv3sU777yDBw8eoF69eujYsSNOnjwJR0dHAMDUqVORm5uL8ePHIy0tDR06dMD+/fthYmJSiRifjckLERERvdSWLVteeF4mkyEsLAxhYWFVHguTFyIiIgmqzfc2YvJCREQkQRrYYPeVwdVGREREJCnseSEiIpIgDhsRERGRpPx7i/+KXi9VHDYiIiIiSWHPCxERkRTV4hm7TF6IiIgkqBbnLkxeiIiIpKg2T9jlnBciIiKSFPa8EBERSVBtXm3E5IWIiEiKavGkFw4bERERkaSw54WIiEiCanHHC5MXIiIiKeJqIyIiIiKJYM8LERGRJFVutZGUB46YvBAREUkQh42IiIiIJILJCxEREUkKh42IiIgkqDYPGzF5ISIikqDafHsADhsRERGRpLDnhYiISII4bERERESSUptvD8BhIyIiIpIU9rwQERFJUS3uemHyQkREJEFcbUREREQkEex5ISIikiCuNiIiIiJJqcVTXjhsREREROW3YsUKODk5QV9fHx4eHvjjjz+qPQYmL0RERFIkU8Ohoq1btyIkJATTp0/HuXPn8MYbb8DPzw937typ/OtRAZMXIiIiCZKp4T9VLVq0CEFBQRg9ejSaNWuGJUuWwN7eHitXrqyCV/h8TF6IiIgkqHTCbmUOVRQUFCAuLg49evRQKu/RoweOHz+uxlf2cpyw+woRQgAAMjMzNBwJVYfSz5tqB1GUr+kQqBqI4iefc3V8vzMyKvezovT6p9uRy+WQy+Vl6j948ADFxcWwtrZWKre2tkZKSkqlYlEVk5dXSGZmJgDA1dlBw5EQEVFlZGZmwszMrEra1tPTg42NDVyc7CvdlrGxMeztlduZNWsWwsLCnnuN7KkuGyFEmbKqxuTlFWJnZ4ekpCSYmJhU+18ETcrIyIC9vT2SkpJgamqq6XCoCvGzrj1q62cthEBmZibs7Oyq7Dn09fWRkJCAgoKCSrf1rMTjWb0uAFC3bl1oa2uX6WVJTU0t0xtT1Zi8vEK0tLTQoEEDTYehMaamprXqH7najJ917VEbP+uq6nH5N319fejr61f58/ybnp4ePDw8EB0djYEDByrKo6Oj0b9//2qNhckLERERlcvkyZMxcuRIeHp6wsvLC9999x3u3LmDcePGVWscTF6IiIioXIYOHYqHDx/i888/R3JyMlq0aIE9e/bA0dGxWuNg8kIaJ5fLMWvWrOeOs1LNwc+69uBnXXONHz8e48eP12gMMsH1mkRERCQh3KSOiIiIJIXJCxEREUkKkxciIiKSFCYvREREJClMXoiIiEhSmLwQERGRpHCfF9KogoICJCQkoFGjRtDR4V/HmuKbb74pd91JkyZVYSRU3f744w+sXr0at27dwrZt21C/fn1s2LABTk5OeP311zUdHtUQ/GlBGpGTk4Pg4GBERkYCAK5fvw5nZ2dMmjQJdnZ2+M9//qPhCKkyFi9eXK56MpmMyUsNsn37dowcORL+/v44d+4c8vPzATy5w/K8efOwZ88eDUdINQU3qSON+PDDD3Hs2DEsWbIEvXr1wsWLF+Hs7IydO3di1qxZOHfunKZDJCIVtWnTBh999BHeffddmJiY4MKFC3B2dsb58+fRq1evMncjJqoo9ryQRuzYsQNbt25Fx44dlW7H7ubmhlu3bmkwMiKqqGvXrqFTp05lyk1NTfH48ePqD4hqLCYvpBH379+HlZVVmfLs7GylZIZqhrt372Lnzp24c+cOCgoKlM4tWrRIQ1GRutna2uLmzZto2LChUvnRo0fh7OysmaCoRmLyQhrRrl077N69G8HBwQCgSFjWrFkDLy8vTYZGanbw4EH069cPTk5OuHbtGlq0aIHExEQIIdC2bVtNh0dq9P777+PDDz/EDz/8AJlMhnv37uHEiRMIDQ3FzJkzNR0e1SBMXkgjwsPD0atXL1y5cgVFRUVYunQpLl++jBMnTiAmJkbT4ZEaTZs2DVOmTMHnn38OExMTbN++HVZWVvD390evXr00HR6p0dSpU5Geno4uXbogLy8PnTp1glwuR2hoKCZOnKjp8KgG4YRd0pj4+HgsXLgQcXFxKCkpQdu2bfHJJ5/A3d1d06GRGpmYmOD8+fNo1KgRzM3NcfToUTRv3hwXLlxA//79kZiYqOkQSc1ycnJw5coVlJSUwM3NDcbGxpoOiWoY9ryQxri7uyuWSlPNZWRkpFgya2dnh1u3bqF58+YAgAcPHmgyNFKzyMhIvP322zAyMoKnp6emw6EajDvskkZ06dIFa9euRXp6uqZDoSrWsWNHHDt2DADw5ptvYsqUKZg7dy5GjRqFjh07ajg6UqfQ0FBYWVlh2LBh+PXXX1FUVKTpkKiGYvJCGuHu7o7PPvsMNjY2eOutt7Bjx44yq1CoZli0aBE6dOgAAAgLC0P37t2xdetWODo6Yu3atRqOjtQpOTkZW7duhba2NoYNGwZbW1uMHz8ex48f13RoVMNwzgtpTElJCQ4cOIDNmzcjKioK2traePvtt+Hv7w8fHx9Nh0dqUFxcjKNHj6Jly5YwNzfXdDhUjXJychAVFYXNmzfjwIEDaNCgAfdwIrVh8kKvhLy8POzatQtz585FfHw8iouLNR0SqYm+vj6uXr0KJycnTYdC1ezBgwfYsmULVq1ahatXr/J7TWrDYSPSuJSUFKxatQrz58/HxYsXOdGvhnF3d8dff/2l6TComuTk5GDTpk3o3bs37OzssHjxYgwYMACXLl3SdGhUg7DnhTQiIyMD27dvx+bNm3HkyBE4Oztj+PDh8Pf3R+PGjTUdHqnR/v378cknn+CLL76Ah4cHjIyMlM6bmppqKDJSt3feeQe7du2CoaEhBg8eDH9/f3h7e2s6LKqBmLyQRhgYGMDc3BxDhgyBv78/2rVrp+mQqIpoaf2vg/fft34QQkAmk3EooQYp/QWkZ8+e0NHhThxUdZi8kEbs378fvr6+Sj/YqGZ62Y7JnJxNRKpi8kJEVerOnTuwt7cvc8NNIQSSkpLg4OCgochIHb755huMHTsW+vr6+Oabb15Yd9KkSdUUFdV0TF6o2rRt2xYHDx6Eubk52rRp88K7R589e7YaI6OqpK2tjeTk5DJ3EX/48CGsrKw4bCRxTk5OOHPmDCwtLV+4okwmk3HiNqkNByWp2vTv3x9yuVzx5xclL1RzlM5teVpWVhb09fU1EBGpU0JCwjP/TFSV2PNCRFVi8uTJAIClS5dizJgxMDQ0VJwrLi7GqVOnoK2trbh1AEnf559/jtDQUKXPGgByc3Px1VdfYebMmRqKjGoaJi+kEc7OzoiNjYWlpaVS+ePHj9G2bVt2L9cAXbp0AfBkwq6Xlxf09PQU5/T09NCwYUOEhobCxcVFUyGSmnGIkKoLh41IIxITE5/5D1l+fj7u3r2rgYhI3Q4fPgwAeO+997B06VLu51ILPG+I8MKFC7CwsNBARFRTMXmharVz507Fn/ft2wczMzPF4+LiYhw8eJDbyNcw69at03QIVMXMzc0hk8kgk8nQpEkTpQSmuLgYWVlZGDdunAYjpJqGw0ZUrUr3dZHJZHj6r56uri4aNmyIr7/+Gn369NFEeFQFunbt+sLzhw4dqqZIqKpERkZCCIFRo0ZhyZIlSr+UlA4Renl5aTBCqmnY80LVqqSkBMCT5ZWxsbGoW7euhiOiqtaqVSulx4WFhTh//jwuXbqEgIAADUVF6lT6OTo5OcHb2xu6uroajohqOva8EJFGhIWFISsrCwsXLtR0KFQJGRkZivlMGRkZL6zLeU+kLkxeSGOys7MRExODO3fuoKCgQOkcd+Ks+W7evIn27dvj0aNHmg6FKuHfK4y0tLSeOWGX97EideOwEWnEuXPn0Lt3b+Tk5CA7OxsWFhZ48OABDA0NYWVlxeSlFjhx4gQ3qasBDh06pFhJVLrCjKiqseeFNKJz585o0qQJVq5ciTp16uDChQvQ1dXFiBEj8OGHH2LQoEGaDpHU5OnPUgiB5ORknDlzBjNmzMCsWbM0FBkRSRVv6Usacf78eUyZMgXa2trQ1tZGfn4+7O3tsWDBAnz66aeaDo/UyMzMTOmwsLBA586dsWfPHiYuNczevXtx9OhRxeNvv/0WrVu3xvDhw5GWlqbByKim4bARaYSurq5ibNza2hp37txBs2bNYGZmhjt37mg4OlIn7vNSe3z88ceYP38+ACA+Ph6TJ0/GlClTcOjQIUyePJl/F0htmLyQRrRp0wZnzpxBkyZN0KVLF8ycORMPHjzAhg0b4O7urunwSM0eP36Mbdu24datW/j4449hYWGBs2fPwtraGvXr19d0eKQmCQkJcHNzAwBs374dffv2xbx583D27Fn07t1bw9FRTcJhI9KIefPmwdbWFgDwxRdfwNLSEh988AFSU1Px3XffaTg6UqeLFy/CxcUF8+fPx8KFC/H48WMAQFRUFKZNm6bZ4Eit9PT0kJOTAwA4cOAAevToAQCwsLB46TJqIlVwwi4RVSlfX1+0bdsWCxYsgImJCS5cuABnZ2ccP34cw4cPR2JioqZDJDXp168fCgoK8Nprr+GLL75AQkIC6tevj/3792PixIm4fv26pkOkGoI9L0RUpWJjY/H++++XKa9fvz5SUlI0EBFVleXLl0NHRwfbtm3DypUrFUOCv/32G3r16qXh6Kgm4ZwX0og2bdo8czMrmUwGfX19NG7cGIGBgejSpYsGoiN10tfXf+aQwbVr11CvXj0NRERVxcHBAb/++muZ8sWLF2sgGqrJ2PNCGtGrVy/89ddfMDIyQpcuXdC5c2cYGxvj1q1baNeuHZKTk+Hr64tffvlF06FSJfXv3x+ff/45CgsLATxJUO/cuYP//Oc/eOuttzQcHalbcXExtm/fjjlz5mDu3Ln4+eefubMuqR3nvJBGjBkzBg4ODpgxY4ZS+Zw5c3D79m2sWbMGs2bNwu7du3HmzBkNRUnqkJGRgd69e+Py5cvIzMyEnZ0dUlJS0LFjR/z2228wMjLSdIikJjdv3kTv3r3x999/w9XVFUIIXL9+Hfb29ti9ezcaNWqk6RCphmDyQhphZmaGuLg4NG7cWKn85s2b8PDwQHp6Ov7880+0a9cOmZmZGoqS1Onw4cOIi4tDSUkJ2rZtC19fX02HRGrWu3dvCCGwadMmxS0DHj58iBEjRkBLSwu7d+/WcIRUU3DOC2mEvr4+jh8/XiZ5OX78uOJ+NyUlJZDL5ZoIj9Ts4MGDOHjwIFJTU1FSUoI///wTmzdvBgD88MMPGo6O1CUmJgYnT55UJC4AYGlpiS+//BKvvfaaBiOjmobJC2lEcHAwxo0bh7i4OLRr1w4ymQynT5/G999/r7g9wL59+9CmTRsNR0qVNXv2bHz++efw9PSEra3tMydqU80gl8uf2VOalZUFPT09DURENRWHjUhjNm3ahOXLl+PatWsAAFdXVwQHB2P48OEAgNzcXMXqI5IuW1tbLFiwACNHjtR0KFTF3n33XZw9exZr165F+/btAQCnTp3CmDFj4OHhgYiICM0GSDUGkxciqlKWlpY4ffo0J2vWAo8fP0ZAQAB27doFXV1dAEBhYSH69++PiIgImJmZaThCqimYvJDGlN7v5q+//kJoaCjvd1NDffLJJzA2Ni6zsoxqrps3b+LKlSsAADc3tzJz24gqi3NeSCMuXrwIX19fmJmZITExEaNHj4aFhQWioqJw+/ZtrF+/XtMhkprk5eXhu+++w4EDB9CyZUvFb+SlFi1apKHIqCqsXbsWixcvxo0bNwAALi4uCAkJwejRozUcGdUkTF5IIyZPnozAwEDF/W5K+fn5Kea8UM1w8eJFtG7dGgBw6dIlpXOcvFuzzJgxA4sXL0ZwcDC8vLwAACdOnMBHH32ExMREzJkzR8MRUk3BYSPSCDMzM5w9exaNGjVSulnf7du34erqiry8PE2HSEQqqlu3LpYtW4Z33nlHqfzHH39EcHAwHjx4oKHIqKbh7QFII3i/G6Kap7i4GJ6enmXKPTw8UFRUpIGIqKZi8kIawfvdENU8I0aMwMqVK8uUf/fdd/D399dARFRTcdiINIL3uyGqeYKDg7F+/XrY29ujY8eOAICTJ08iKSkJ7777rtJkbU7Upspg8kIaxfvdENUcXbp0KVc9mUyGQ4cOVXE0VJMxeSGNefp+N//G+90QEdHzcKk0aQTvd0NERBXFnhfSCN7vhoiIKoqrjUgjCgoK4O3trekwiIhIgpi8kEaMHj0amzdv1nQYREQkQZzzQhrB+90QEVFFcc4LacSLllRyGSUREb0IkxciIiKSFM55ISIiIklh8kJERESSwuSFiIiIJIXJCxEpCQsLQ+vWrRWPAwMDMWDAgGqPIzExETKZDOfPn39unYYNG2LJkiXlbjMiIgJ16tSpdGwymQw7duyodDtEVDFMXogkIDAwEDKZDDKZDLq6unB2dkZoaCiys7Or/LmXLl2KiIiIctUtT8JBRFRZ3OeFSCJ69eqFdevWobCwEH/88QdGjx6N7OxsrFy5skzdwsLCMnvnVJSZmZla2iEiUhf2vBBJhFwuh42NDezt7TF8+HD4+/srhi5Kh3p++OEHODs7Qy6XQwiB9PR0jB07FlZWVjA1NUXXrl1x4cIFpXa//PJLWFtbw8TEBEFBQcjLy1M6//SwUUlJCebPn4/GjRtDLpfDwcEBc+fOBQA4OTkBANq0aQOZTIbOnTsrrlu3bh2aNWsGfX19NG3aFCtWrFB6ntOnT6NNmzbQ19eHp6cnzp07p/J7tGjRIri7u8PIyAj29vYYP348srKyytTbsWMHmjRpAn19fXTv3h1JSUlK53ft2gUPDw/o6+vD2dkZs2fPRlFRkcrxEFHVYPJCJFEGBgYoLCxUPL558yZ++uknbN++XTFs8+abbyIlJQV79uxBXFwc2rZti27duuHRo0cAgJ9++gmzZs3C3LlzcebMGdja2pZJKp42bdo0zJ8/HzNmzMCVK1ewefNmWFtbA3iSgADAgQMHkJycjJ9//hkAsGbNGkyfPh1z587F1atXMW/ePMyYMQORkZEAgOzsbPTp0weurq6Ii4tDWFgYQkNDVX5PtLS08M033+DSpUuIjIzEoUOHMHXqVKU6OTk5mDt3LiIjI3Hs2DFkZGRg2LBhivP79u3DiBEjMGnSJFy5cgWrV69GRESEIkEjoleAIKJXXkBAgOjfv7/i8alTp4SlpaUYMmSIEEKIWbNmCV1dXZGamqqoc/DgQWFqairy8vKU2mrUqJFYvXq1EEIILy8vMW7cOKXzHTp0EK1atXrmc2dkZAi5XC7WrFnzzDgTEhIEAHHu3Dmlcnt7e7F582alsi+++EJ4eXkJIYRYvXq1sLCwENnZ2YrzK1eufGZb/+bo6CgWL1783PM//fSTsLS0VDxet26dACBOnjypKLt69aoAIE6dOiWEEOKNN94Q8+bNU2pnw4YNwtbWVvEYgIiKinru8xJR1eKcFyKJ+PXXX2FsbIyioiIUFhaif//+WLZsmeK8o6Mj6tWrp3gcFxeHrKwsWFpaKrWTm5uLW7duAQCuXr2KcePGKZ338vLC4cOHnxnD1atXkZ+fj27dupU77vv37yMpKQlBQUEYM2aMoryoqEgxn+bq1ato1aoVDA0NleJQ1eHDhzFv3jxcuXIFGRkZKCoqQl5eHrKzs2FkZAQA0NHRgaenp+Kapk2bok6dOrh69Srat2+PuLg4xMbGKvW0FBcXIy8vDzk5OUoxEpFmMHkhkoguXbpg5cqV0NXVhZ2dXZkJuaU/nEuVlJTA1tYWR44cKdNWRZcLGxgYqHxNSUkJgCdDRx06dFA6p62tDQAQarhLye3bt9G7d2+MGzcOX3zxBSwsLHD06FEEBQUpDa8BT5Y6P620rKSkBLNnz8agQYPK1NHX1690nERUeUxeiCTCyMgIjRs3Lnf9tm3bIiUlBTo6OmjYsOEz6zRr1gwnT57Eu+++qyg7efLkc9t0cXGBgYEBDh48iNGjR5c5r6enB+BJT0Upa2tr1K9fH3/99Rf8/f2f2a6bmxs2bNiA3NxcRYL0ojie5cyZMygqKsLXX38NLa0n0/l++umnMvWKiopw5swZtG/fHgBw7do1PH78GE2bNgXw5H27du2aSu81EVUvJi9ENZSvry+8vLwwYMAAzJ8/H66urrh37x727NmDAQMGwNPTEx9++CECAgLg6emJ119/HZs2bcLly5fh7Oz8zDb19fXxySefYOrUqdDT08Nrr72G+/fv4/LlywgKCoKVlRUMDAywd+9eNGjQAPr6+jAzM0NYWBgmTZoEU1NT+Pn5IT8/H2fOnEFaWhomT56M4cOHY/r06QgKCsJnn32GxMRELFy4UKXX26hRIxQVFWHZsmXo27cvjh07hlWrVpWpp6uri+DgYHzzzTfQ1dXFxIkT0bFjR0UyM3PmTPTp0wf29vYYPHgwtLS0cPHiRcTHx2POnDmqfxBEpHZcbURUQ8lkMuzZswedOnXCqFGj0KRJEwwbNgyJiYmK1UFDhw7FzJkz8cknn8DDwwO3b9/GBx988MJ2Z8yYgSlTpmDmzJlo1qwZhg4ditTUVABP5pN88803WL16Nezs7NC/f38AwOjRo/H9998jIiIC7u7u8PHxQUREhGJptbGxMXbt2oUrV66gTZs2mD59OubPn6/S623dujUWLVqE+fPno0WLFti0aRPCw8PL1DM0NMQnn3yC4cOHw8vLCwYGBtiyZYvifM+ePfHrr78iOjoa7dq1Q8eOHbFo0SI4OjqqFA8RVR2ZUMdgMxEREVE1Yc8LERERSQqTFyIiIpIUJi9EREQkKUxeiIiISFKYvBAREZGkMHkhIiIiSWHyQkRERJLC5IWIiIgkhckLERERSQqTFyIiIpIUJi9EREQkKUxeiIiISFL+D0hZjqdpchhiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 0. Environment Setup\n",
    "# -------------------------------\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"F:\\Context-Resonance Transformer\\Cricket\\Cricket - Sheet1.csv\")  # Replace with your dataset path\n",
    "df = df[['Text', 'Polarity']]  # Focus on only one task: Category classification\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(f\"Initial Data Shape: {df.shape}\")\n",
    "\n",
    "# Initialize Bengali stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Bengali stopwords\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words('bengali'))\n",
    "except LookupError:\n",
    "    print(\"Bengali stopwords not found. Skipping stopword removal.\")\n",
    "    stop_words = set()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Remove non-Bengali characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = text.split()\n",
    "    if stop_words:\n",
    "        words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "print(\"DataFrame after text cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Upsampling to Balance Classes\n",
    "# -------------------------------\n",
    "\n",
    "def upsample(df, target_column):\n",
    "    max_count = df[target_column].value_counts().max()\n",
    "    upsampled_dfs = []\n",
    "    for label in df[target_column].unique():\n",
    "        df_label = df[df[target_column] == label]\n",
    "        df_upsampled = resample(\n",
    "            df_label,\n",
    "            replace=True,\n",
    "            n_samples=max_count,\n",
    "            random_state=42\n",
    "        )\n",
    "        upsampled_dfs.append(df_upsampled)\n",
    "    return pd.concat(upsampled_dfs)\n",
    "\n",
    "df_upsampled = upsample(df, 'Polarity')\n",
    "\n",
    "# Encode labels\n",
    "category_encoder = LabelEncoder()\n",
    "df_upsampled['Category_encoded'] = category_encoder.fit_transform(df_upsampled['Polarity'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Tokenization using BERT\n",
    "# -------------------------------\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_len=20, batch_size=32):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            list(batch),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    input_ids = tf.concat(input_ids, axis=0).numpy()\n",
    "    attention_masks = tf.concat(attention_masks, axis=0).numpy()\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize the data\n",
    "input_ids, attention_masks = tokenize_sentences(df_upsampled['Text'].values, tokenizer, max_len=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Create window-based adjacency matrices\n",
    "def window_based_adjacency(sentences, window_size=2, max_len=20):\n",
    "    adjacency_matrices = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()[:max_len]\n",
    "        num_tokens = len(tokens)\n",
    "        adj = np.zeros((max_len, max_len), dtype=np.float32)\n",
    "        for i in range(num_tokens):\n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, num_tokens)):\n",
    "                if i != j:\n",
    "                    adj[i, j] = 1.0\n",
    "        adjacency_matrices.append(adj)\n",
    "    return np.array(adjacency_matrices, dtype=np.float32)\n",
    "\n",
    "adjacency_matrices = window_based_adjacency(df_upsampled['Text'].values, window_size=2, max_len=20)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Data Splitting\n",
    "# -------------------------------\n",
    "\n",
    "# Split the data\n",
    "X_train_ids, X_test_ids, X_train_masks, X_test_masks, adjacency_train, adjacency_test, y_train_category, y_test_category = train_test_split(\n",
    "    input_ids, attention_masks, adjacency_matrices,  df_upsampled['Category_encoded'].values,\n",
    "    test_size=0.2, random_state=42, stratify=df_upsampled['Category_encoded'].values\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Concatenate, Embedding, Flatten, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers import GATConv\n",
    "from transformers import TFBertModel\n",
    "import numpy as np\n",
    "\n",
    "# Squash function for Capsule Networks\n",
    "def squash(vectors):\n",
    "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=-1, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm)\n",
    "    unit_vectors = vectors / tf.sqrt(s_squared_norm + 1e-9)\n",
    "    return scale * unit_vectors\n",
    "\n",
    "# Custom Multi-Head Attention Layer\n",
    "class CustomMultiHeadAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim, max_len, **kwargs):\n",
    "        super(CustomMultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.depth = key_dim // num_heads\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list) and len(input_shape) == 3:\n",
    "            q_shape, k_shape, v_shape = input_shape\n",
    "        else:\n",
    "            q_shape = input_shape\n",
    "            k_shape = input_shape\n",
    "            v_shape = input_shape\n",
    "        self.wq = self.add_weight(shape=(q_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wk = self.add_weight(shape=(k_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        self.wv = self.add_weight(shape=(v_shape[-1], self.key_dim), initializer='random_normal', trainable=True)\n",
    "        super(CustomMultiHeadAttention, self).build(input_shape)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.reshape(x, (batch_size, self.max_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list) and len(inputs) == 3:\n",
    "            q, k, v = inputs\n",
    "        else:\n",
    "            q = inputs\n",
    "            k = inputs\n",
    "            v = inputs\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = tf.matmul(q, self.wq)\n",
    "        k = tf.matmul(k, self.wk)\n",
    "        v = tf.matmul(v, self.wv)\n",
    "\n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(self.depth, tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(output, (batch_size, self.max_len, self.key_dim))\n",
    "\n",
    "        # Set shapes for Keras\n",
    "        concat_attention.set_shape((None, self.max_len, self.key_dim))\n",
    "        attention_weights.set_shape((None, self.num_heads, self.max_len, self.max_len))\n",
    "\n",
    "        return concat_attention, attention_weights\n",
    "\n",
    "# GNNContextResonance Layer\n",
    "class GNNContextResonance(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads=8, max_len=20, dropout_rate=0.2, **kwargs):\n",
    "        super(GNNContextResonance, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.max_len = max_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.position_embedding = Embedding(input_dim=max_len, output_dim=hidden_size)\n",
    "\n",
    "        # Multi-Head GAT Layers\n",
    "        self.gat_layers = [GATConv(hidden_size // num_heads, activation='elu') for _ in range(num_heads)]\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        self.transform_gate = Dense(hidden_size, activation='sigmoid')\n",
    "        self.carry_gate = Dense(hidden_size, activation='sigmoid')\n",
    "\n",
    "        # Dropout and Layer Norm\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dense layer for resonance scores\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, adjacency, edge_features=None, training=False):\n",
    "        position_indices = tf.range(self.max_len)[tf.newaxis, :]\n",
    "        position_embeddings = self.position_embedding(position_indices)\n",
    "        inputs = inputs + position_embeddings\n",
    "\n",
    "        gat_outputs = []\n",
    "        for gat_layer in self.gat_layers:\n",
    "            x = gat_layer([inputs, adjacency])\n",
    "            gat_outputs.append(x)\n",
    "        x = self.concat(gat_outputs)\n",
    "\n",
    "        # Residual Connection\n",
    "        x = x + inputs\n",
    "\n",
    "        # Highway Network for Modulation\n",
    "        transform = self.transform_gate(x)\n",
    "        carry = self.carry_gate(inputs)\n",
    "        outputs = transform * x + (1 - transform) * carry\n",
    "\n",
    "        # Apply dropout and layer normalization\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        outputs = self.layer_norm(outputs)\n",
    "\n",
    "        resonance_scores = self.dense(outputs)\n",
    "\n",
    "        return outputs, resonance_scores\n",
    "\n",
    "# Building the Model with BERT and GNN for Single Task (Category)\n",
    "def build_model_with_gnn(bert_model, hidden_size, max_len=20):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_masks = Input(shape=(max_len,), dtype=tf.int32, name='attention_masks')\n",
    "    adjacency = Input(shape=(max_len, max_len), dtype=tf.float32, name='adjacency')\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    bert_outputs = bert_model([input_ids, attention_masks])\n",
    "    sequence_output = bert_outputs.last_hidden_state  # BERT output\n",
    "\n",
    "    # Apply GNN-Based Context Resonance\n",
    "    gnn_resonance_layer = GNNContextResonance(hidden_size, num_heads=8, max_len=max_len)\n",
    "    gnn_output, resonance_scores = gnn_resonance_layer(sequence_output, adjacency)\n",
    "\n",
    "    # Implement Dual Attention Mechanism (Self-attention and Cross-attention)\n",
    "    self_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    self_attention_output, self_attention_scores = self_attention_layer([gnn_output, gnn_output, gnn_output])\n",
    "\n",
    "    cross_attention_layer = CustomMultiHeadAttention(num_heads=8, key_dim=hidden_size, max_len=max_len)\n",
    "    cross_attention_output, cross_attention_scores = cross_attention_layer([sequence_output, gnn_output, gnn_output])\n",
    "\n",
    "    # Combine outputs\n",
    "    combined_output = Concatenate(axis=-1)([self_attention_output, cross_attention_output])\n",
    "\n",
    "    # Capsule Networks Layer\n",
    "    caps_num_capsules = 10  # Number of capsules\n",
    "    caps_dim_capsules = 16  # Dimension of each capsule\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Conv1D(\n",
    "        filters=caps_num_capsules * caps_dim_capsules,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid'\n",
    "    )(combined_output)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Reshape(\n",
    "        target_shape=(max_len, caps_num_capsules, caps_dim_capsules)\n",
    "    )(primary_capsules)\n",
    "\n",
    "    primary_capsules = tf.keras.layers.Lambda(squash, name='primary_caps_squash')(primary_capsules)\n",
    "\n",
    "    flat_capsules = Flatten()(primary_capsules)\n",
    "\n",
    "    dropout = Dropout(0.3)(flat_capsules)\n",
    "\n",
    "    # Category Output\n",
    "    category_output = Dense(len(category_encoder.classes_), activation='softmax', name='category_output')(dropout)\n",
    "\n",
    "    # Model will only output Category and resonance scores\n",
    "    model = Model(\n",
    "        inputs=[input_ids, attention_masks, adjacency],\n",
    "        outputs=[category_output, resonance_scores]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load pre-trained multilingual BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "hidden_size = bert_model.config.hidden_size  # Typically 768\n",
    "\n",
    "# Build the model\n",
    "model = build_model_with_gnn(bert_model, hidden_size, max_len=20)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Defining Custom Loss Functions and Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "\n",
    "# Define the standard loss function for category classification without class weights\n",
    "loss_fn_category = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "# Define metrics\n",
    "train_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_category')\n",
    "val_accuracy_category = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy_category')\n",
    "\n",
    "# Define the supervised contrastive loss function\n",
    "def supervised_contrastive_loss(labels, features, temperature=0.1):\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    label_mask = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    features = tf.math.l2_normalize(features, axis=1)\n",
    "    similarity_matrix = tf.matmul(features, features, transpose_b=True) / temperature\n",
    "    logits_max = tf.reduce_max(similarity_matrix, axis=1, keepdims=True)\n",
    "    logits = similarity_matrix - logits_max\n",
    "    exp_logits = tf.exp(logits) * tf.cast(label_mask, tf.float32)\n",
    "    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True) + 1e-8)\n",
    "    mean_log_prob_pos = tf.reduce_sum(log_prob * tf.cast(label_mask, tf.float32), axis=1) / tf.reduce_sum(tf.cast(label_mask, tf.float32), axis=1)\n",
    "    loss = -tf.reduce_mean(mean_log_prob_pos)\n",
    "    return loss\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Custom Training Loop\n",
    "# -------------------------------\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = model([input_ids, attention_masks, adjacency], training=True)\n",
    "        predictions_category = predictions[0]\n",
    "        resonance_scores = predictions[1]  # Resonance scores (if needed for other tasks)\n",
    "\n",
    "        # Compute per-sample standard loss for category\n",
    "        cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "        # Compute smoothness loss (if required by your architecture)\n",
    "        resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)  # (batch_size, seq_length)\n",
    "        resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "        squared_diff = tf.square(resonance_diff)\n",
    "        smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])  # (batch_size,)\n",
    "        smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "        # Remove contrastive loss (since features aren't being returned)\n",
    "        total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(input_ids, attention_masks, adjacency, labels_category):\n",
    "    # Forward pass\n",
    "    predictions = model([input_ids, attention_masks, adjacency], training=False)\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    # Compute per-sample standard loss for category\n",
    "    cce_loss_category = loss_fn_category(labels_category, predictions_category)\n",
    "\n",
    "    # Compute smoothness loss (if required by your architecture)\n",
    "    resonance_scores_squeezed = tf.squeeze(resonance_scores, axis=-1)\n",
    "    resonance_diff = resonance_scores_squeezed[:, :, tf.newaxis] - resonance_scores_squeezed[:, tf.newaxis, :]\n",
    "    squared_diff = tf.square(resonance_diff)\n",
    "    smoothness_loss = tf.reduce_sum(adjacency * squared_diff, axis=[1, 2])\n",
    "    smoothness_loss = tf.reduce_mean(smoothness_loss)\n",
    "\n",
    "    # Remove contrastive loss (since features aren't being returned)\n",
    "    total_loss = tf.reduce_mean(cce_loss_category) + smoothness_loss\n",
    "\n",
    "    # Update metrics\n",
    "    val_accuracy_category.update_state(labels_category, predictions_category)\n",
    "\n",
    "    return total_loss, cce_loss_category, smoothness_loss\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training the Model\n",
    "# -------------------------------\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_train_ids,\n",
    "    'attention_masks': X_train_masks,\n",
    "    'adjacency': adjacency_train\n",
    "}, y_train_category)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': X_test_ids,\n",
    "    'attention_masks': X_test_masks,\n",
    "    'adjacency': adjacency_test\n",
    "}, y_test_category)).batch(batch_size)\n",
    "\n",
    "# Initialize history dictionaries\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_cce_loss_category': [],\n",
    "    'train_smoothness_loss': [],\n",
    "    'train_accuracy_category': [],\n",
    "    'val_loss': [],\n",
    "    'val_cce_loss_category': [],\n",
    "    'val_smoothness_loss': [],\n",
    "    'val_accuracy_category': [],\n",
    "    'epoch_time': []  # Added to record time per epoch\n",
    "}\n",
    "\n",
    "# Start time of training\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch + 1}\")\n",
    "    epoch_start_time = time.time()  # Record start time of the epoch\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_accuracy_category.reset_states()\n",
    "    val_accuracy_category.reset_states()\n",
    "\n",
    "    # Training\n",
    "    total_loss_avg = tf.keras.metrics.Mean()\n",
    "    cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for step, (batch_inputs, batch_labels_category) in enumerate(train_dataset):\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the train_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = train_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        total_loss_avg.update_state(total_loss)\n",
    "        cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        smoothness_loss_avg.update_state(smoothness_loss)\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Total Loss = {total_loss_avg.result():.4f}, \"\n",
    "                  f\"CCE Loss Category = {cce_loss_category_avg.result():.4f}, \"\n",
    "                  f\"Smoothness Loss = {smoothness_loss_avg.result():.4f}, \"\n",
    "                  f\"Train Accuracy Category = {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Record training metrics\n",
    "    history['train_loss'].append(total_loss_avg.result().numpy())\n",
    "    history['train_cce_loss_category'].append(cce_loss_category_avg.result().numpy())\n",
    "    history['train_smoothness_loss'].append(smoothness_loss_avg.result().numpy())\n",
    "    history['train_accuracy_category'].append(train_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training CCE Loss Category: {cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Smoothness Loss: {smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Training Accuracy Category: {train_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    val_loss_avg = tf.keras.metrics.Mean()\n",
    "    val_cce_loss_category_avg = tf.keras.metrics.Mean()\n",
    "    val_smoothness_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for batch_inputs, batch_labels_category in test_dataset:\n",
    "        input_ids = batch_inputs['input_ids']\n",
    "        attention_masks = batch_inputs['attention_masks']\n",
    "        adjacency = batch_inputs['adjacency']\n",
    "        labels_category = batch_labels_category\n",
    "    \n",
    "        # Unpack only 3 values, since the test_step now returns 3 values\n",
    "        total_loss, cce_loss_cat, smoothness_loss = test_step(\n",
    "            input_ids, attention_masks, adjacency, labels_category)\n",
    "    \n",
    "        val_loss_avg.update_state(total_loss)\n",
    "        val_cce_loss_category_avg.update_state(cce_loss_cat)\n",
    "        val_smoothness_loss_avg.update_state(smoothness_loss)\n",
    "\n",
    "    # Record validation metrics\n",
    "    history['val_loss'].append(val_loss_avg.result().numpy())\n",
    "    history['val_cce_loss_category'].append(val_cce_loss_category_avg.result().numpy())\n",
    "    history['val_smoothness_loss'].append(val_smoothness_loss_avg.result().numpy())\n",
    "    history['val_accuracy_category'].append(val_accuracy_category.result().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {val_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation CCE Loss Category: {val_cce_loss_category_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Smoothness Loss: {val_smoothness_loss_avg.result():.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Validation Accuracy Category: {val_accuracy_category.result():.4f}\")\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    history['epoch_time'].append(epoch_duration)\n",
    "    print(f\"Epoch {epoch+1} Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "# Total training time\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "print(f\"\\nTotal Training Time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def compute_macro_precision(y_true, y_pred, num_classes):\n",
    "    # Calculate precision for each class\n",
    "    precision_per_class = tf.keras.metrics.Precision(class_id=None, num_classes=num_classes)\n",
    "    precision_per_class.update_state(y_true, y_pred)\n",
    "    precision = precision_per_class.result().numpy()\n",
    "    return precision\n",
    "\n",
    "def compute_macro_recall(y_true, y_pred, num_classes):\n",
    "    # Calculate recall for each class\n",
    "    recall_per_class = tf.keras.metrics.Recall(class_id=None, num_classes=num_classes)\n",
    "    recall_per_class.update_state(y_true, y_pred)\n",
    "    recall = recall_per_class.result().numpy()\n",
    "    return recall\n",
    "\n",
    "def compute_macro_f1(y_true, y_pred, num_classes):\n",
    "    # Calculate F1 score for each class\n",
    "    precision = compute_macro_precision(y_true, y_pred, num_classes)\n",
    "    recall = compute_macro_recall(y_true, y_pred, num_classes)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Evaluation and Visualization\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on the test set\n",
    "all_predictions_category = []\n",
    "all_labels_category = []\n",
    "all_resonance_scores = []\n",
    "\n",
    "for batch_inputs, batch_labels_category in test_dataset:\n",
    "    input_ids = batch_inputs['input_ids']\n",
    "    attention_masks = batch_inputs['attention_masks']\n",
    "    adjacency = batch_inputs['adjacency']\n",
    "\n",
    "    predictions = model.predict([input_ids, attention_masks, adjacency])\n",
    "    predictions_category = predictions[0]\n",
    "    resonance_scores = predictions[1]\n",
    "\n",
    "    predicted_labels_category = np.argmax(predictions_category, axis=1)\n",
    "\n",
    "    all_predictions_category.extend(predicted_labels_category)\n",
    "    all_labels_category.extend(batch_labels_category.numpy())\n",
    "    all_resonance_scores.extend(resonance_scores)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels_category = np.array(all_labels_category)\n",
    "all_predictions_category = np.array(all_predictions_category)\n",
    "\n",
    "# Calculate metrics for Category\n",
    "accuracy_category = accuracy_score(all_labels_category, all_predictions_category)\n",
    "f1_category = f1_score(all_labels_category, all_predictions_category, average='macro')\n",
    "precision_category = precision_score(all_labels_category, all_predictions_category, average='macro')\n",
    "recall_category = recall_score(all_labels_category, all_predictions_category, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy (Category): {accuracy_category:.4f}\")\n",
    "print(f\"Test Macro F1 Score (Category): {f1_category:.4f}\")\n",
    "print(f\"Test Macro Precision (Category): {precision_category:.4f}\")\n",
    "print(f\"Test Macro Recall (Category): {recall_category:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Category\n",
    "plt.figure(figsize=(4, 4))\n",
    "cm_category = confusion_matrix(all_labels_category, all_predictions_category)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_category, display_labels=category_encoder.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=90)\n",
    "plt.title('Confusion Matrix - Category')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
